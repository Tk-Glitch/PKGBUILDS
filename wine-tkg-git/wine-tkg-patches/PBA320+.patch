From 6ade8b34322bcfe9df0de6e8fff1bdb7e457832f Mon Sep 17 00:00:00 2001
From: Tk-Glitch <ti3nou@gmail.com>
Date: Wed, 31 Oct 2018 13:57:57 +0100
Subject: PBA 3.20+ rebase for wine-tkg-git - Thanks to Rob Walker <bob.mt.wya@gmail.com>


diff --git a/patches/0001-wined3d-Initial-implementation-of-a-persistent-mappe.patch b/patches/0001-wined3d-Initial-implementation-of-a-persistent-mappe.patch
new file mode 100644
index 000000000..3415ac93d
--- /dev/null
+++ b/patches/0001-wined3d-Initial-implementation-of-a-persistent-mappe.patch
@@ -0,0 +1,3379 @@
+From 83ee1b4128653cbaead9db0b9013fa89134c02ea Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Mon, 5 Mar 2018 15:38:35 -0800
+Subject: [PATCH 01/11] wined3d: Initial implementation of a persistent mapped
+ buffer allocator.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/Makefile.in       |    1 +
+ dlls/wined3d/buffer_heap.c     |  508 ++++++
+ dlls/wined3d/cs.c              |    9 +
+ dlls/wined3d/device.c          |   52 +
+ dlls/wined3d/directx.c         | 2649 ++++++++++++++++++++++++++++++++
+ dlls/wined3d/query.c           |    2 +-
+ dlls/wined3d/wined3d_private.h |   68 +-
+ 7 files changed, 3285 insertions(+), 4 deletions(-)
+ create mode 100644 dlls/wined3d/buffer_heap.c
+
+diff --git a/dlls/wined3d/Makefile.in b/dlls/wined3d/Makefile.in
+index 39fed381d97..0837e5cdd80 100644
+--- a/dlls/wined3d/Makefile.in
++++ b/dlls/wined3d/Makefile.in
+@@ -9,2 +9,3 @@ C_SRCS = \
+ 	buffer.c \
++	buffer_heap.c \
+ 	context.c \
+diff --git a/dlls/wined3d/buffer_heap.c b/dlls/wined3d/buffer_heap.c
+new file mode 100644
+index 00000000000..b133bd68933
+--- /dev/null
++++ b/dlls/wined3d/buffer_heap.c
+@@ -0,0 +1,508 @@
++/*
++ * Copyright 2018 Andrew Comminos
++ *
++ * This library is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU Lesser General Public
++ * License as published by the Free Software Foundation; either
++ * version 2.1 of the License, or (at your option) any later version.
++ *
++ * This library is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
++ * Lesser General Public License for more details.
++ *
++ * You should have received a copy of the GNU Lesser General Public
++ * License along with this library; if not, write to the Free Software
++ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
++ *
++ */
++
++#include "config.h"
++#include "wine/port.h"
++#include "wine/rbtree.h"
++#include "wined3d_private.h"
++
++WINE_DEFAULT_DEBUG_CHANNEL(d3d);
++WINE_DECLARE_DEBUG_CHANNEL(d3d_perf);
++
++struct wined3d_buffer_heap_element
++{
++    struct wined3d_map_range range;
++
++    // rbtree data
++    struct wine_rb_entry entry;
++
++    // Binned free list positions
++    struct wined3d_buffer_heap_element *next;
++    struct wined3d_buffer_heap_element *prev;
++};
++
++struct wined3d_buffer_heap_fenced_element
++{
++    struct wined3d_buffer_heap_bin_set free_list;
++    struct wined3d_fence *fence;
++
++    struct wined3d_buffer_heap_fenced_element *next;
++};
++
++static struct wined3d_buffer_heap_element* element_new(GLsizei offset, GLsizei size)
++{
++    struct wined3d_buffer_heap_element* elem;
++    elem = HeapAlloc(GetProcessHeap(), HEAP_ZERO_MEMORY, sizeof(struct wined3d_buffer_heap_element));
++    if (!elem)
++        return NULL;
++    elem->range.offset = offset;
++    elem->range.size = size;
++    return elem;
++}
++
++static inline int bitwise_log2_floor(GLsizei size)
++{
++    // XXX(acomminos): I hope this gets unrolled.
++    for (int i = 8 * sizeof(GLsizei) - 1; i >= 0; i--)
++    {
++        if ((size >> i) & 1) {
++            return i;
++        }
++    }
++    return 0;
++}
++
++static inline int bitwise_log2_ceil(GLsizei size)
++{
++    // Add one to the floor of size if size isn't a power of two.
++    return bitwise_log2_floor(size) + !!(size & (size - 1));
++}
++
++static int element_bin(struct wined3d_buffer_heap_element *elem)
++{
++    return min(WINED3D_BUFFER_HEAP_BINS - 1, bitwise_log2_floor(elem->range.size));
++}
++
++// Inserts an element into the appropriate free list bin.
++static void element_insert_free_bin(struct wined3d_buffer_heap *heap, struct wined3d_buffer_heap_element *elem)
++{
++    int bin = element_bin(elem);
++
++    elem->prev = NULL;
++    elem->next = heap->free_list.bins[bin].head;
++    if (heap->free_list.bins[bin].head)
++        heap->free_list.bins[bin].head->prev = elem;
++    heap->free_list.bins[bin].head = elem;
++
++    if (!heap->free_list.bins[bin].tail)
++        heap->free_list.bins[bin].tail = elem;
++
++    TRACE("Inserted allocation at %p of size %lld into bin %d\n", elem->range.offset, elem->range.size, bin);
++}
++
++// Removes an element from the free tree, its bin, and the coalesce list.
++static void element_remove_free(struct wined3d_buffer_heap *heap, struct wined3d_buffer_heap_element *elem)
++{
++    int bin = element_bin(elem);
++
++    if (elem->prev)
++        elem->prev->next = elem->next;
++
++    if (elem->next)
++        elem->next->prev = elem->prev;
++
++    if (elem == heap->free_list.bins[bin].head)
++        heap->free_list.bins[bin].head = elem->next;
++
++    if (elem == heap->free_list.bins[bin].tail)
++        heap->free_list.bins[bin].tail = elem->prev;
++
++    elem->prev = NULL;
++    elem->next = NULL;
++
++    TRACE("Freed allocation at %p of size %lld from bin %d\n", elem->range.offset, elem->range.size, bin);
++}
++
++static struct wined3d_buffer_heap_fenced_element* fenced_element_new(struct wined3d_buffer_heap_bin_set bins, struct wined3d_fence* fence)
++{
++    struct wined3d_buffer_heap_fenced_element* elem;
++    elem = HeapAlloc(GetProcessHeap(), HEAP_ZERO_MEMORY, sizeof(struct wined3d_buffer_heap_fenced_element));
++    if (!elem)
++        return NULL;
++    elem->free_list = bins;
++    elem->fence = fence;
++    elem->next = NULL;
++    return elem;
++}
++
++static int free_tree_compare(const void *key, const struct wine_rb_entry *entry)
++{
++    const GLsizei offset = *(const GLsizei*) key;
++    struct wined3d_buffer_heap_element *elem = WINE_RB_ENTRY_VALUE(entry, struct wined3d_buffer_heap_element, entry);
++
++    if (offset < elem->range.offset)
++        return -1;
++    if (offset > elem->range.offset)
++        return 1;
++    return 0;
++}
++
++/* Context activation is done by the caller. */
++HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr size, GLsizeiptr alignment, BOOL write_only, struct wined3d_buffer_heap **buffer_heap)
++{
++    const struct wined3d_gl_info *gl_info = context->gl_info;
++    const GLenum buffer_target = GL_ARRAY_BUFFER;
++    GLbitfield access_flags;
++    GLbitfield storage_flags;
++    struct wined3d_buffer_heap_element *initial_elem;
++
++    struct wined3d_buffer_heap *object;
++
++    if ((alignment & (alignment - 1)) != 0)
++    {
++        return E_FAIL;
++    }
++
++    if (!(object = HeapAlloc(GetProcessHeap(), HEAP_ZERO_MEMORY, sizeof(*object))))
++    {
++        return E_OUTOFMEMORY;
++    }
++
++    access_flags = GL_MAP_PERSISTENT_BIT | GL_MAP_COHERENT_BIT | GL_MAP_WRITE_BIT;
++    if (!write_only)
++    {
++        access_flags |= GL_MAP_READ_BIT;
++    }
++    storage_flags = access_flags;
++
++    // TODO(acomminos): where should we be checking for errors here?
++    GL_EXTCALL(glGenBuffers(1, &object->buffer_object));
++
++    context_bind_bo(context, buffer_target, object->buffer_object);
++
++    // TODO(acomminos): assert glBufferStorage supported?
++    GL_EXTCALL(glBufferStorage(buffer_target, size, NULL, storage_flags));
++
++    if (!(object->map_ptr = GL_EXTCALL(glMapBufferRange(buffer_target, 0, size, access_flags))))
++    {
++        ERR("Couldn't map persistent buffer.\n");
++        return -1; // FIXME(acomminos): proper error code, cleanup
++    }
++    context_bind_bo(context, buffer_target, 0);
++
++    object->fenced_head = object->fenced_tail = NULL;
++    object->alignment = alignment;
++    InitializeCriticalSection(&object->temp_lock);
++
++    initial_elem = element_new(0, size);
++    // Don't bother adding the initial allocation to the coalescing tree.
++    element_insert_free_bin(object, initial_elem);
++
++    *buffer_heap = object;
++
++    return WINED3D_OK;
++}
++
++/* Context activation is done by the caller. */
++HRESULT wined3d_buffer_heap_destroy(struct wined3d_buffer_heap *heap, struct wined3d_context *context)
++{
++    FIXME("Unimplemented, leaking buffer");
++    return WINED3D_OK;
++}
++
++HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr size, struct wined3d_map_range *out_range)
++{
++    int initial_bin;
++    int initial_size = size;
++
++    EnterCriticalSection(&heap->temp_lock);
++
++    // After alignment, reduce fragmentation by rounding to next power of two.
++    // If the alignment is a power of two (which it should be), this should be
++    // no problem.
++    size = 1 << bitwise_log2_ceil(size);
++
++    // Align size values where possible.
++    if (heap->alignment && (size % heap->alignment != 0))
++        size += heap->alignment - (size % heap->alignment);
++
++    initial_bin = min(WINED3D_BUFFER_HEAP_BINS - 1, bitwise_log2_ceil(size));
++
++    for (int i = initial_bin; i < WINED3D_BUFFER_HEAP_BINS; i++)
++    {
++        struct wined3d_buffer_heap_element *elem = heap->free_list.bins[i].head;
++        if (elem)
++        {
++            struct wined3d_map_range remaining_range;
++            remaining_range.offset = elem->range.offset + size;
++            remaining_range.size = elem->range.size - size;
++
++            out_range->offset = elem->range.offset;
++            out_range->size = size;
++
++            TRACE_(d3d_perf)("Allocated %d (requested %d) at %p from bin %d (initial %d)\n", size, initial_size, elem->range.offset, i, initial_bin);
++
++            // Remove the element from its current free bin to move it to the correct list.
++            element_remove_free(heap, elem);
++
++            if (remaining_range.size > 0)
++            {
++                TRACE_(d3d_perf)("Imperfect fit allocated, fragmenting remainder of %lld at %p.\n", remaining_range.size, remaining_range.offset);
++
++                elem->range = remaining_range;
++                element_insert_free_bin(heap, elem);
++            }
++            else
++            {
++                HeapFree(GetProcessHeap(), 0, elem);
++            }
++
++            LeaveCriticalSection(&heap->temp_lock);
++            return WINED3D_OK;
++        }
++    }
++
++    LeaveCriticalSection(&heap->temp_lock);
++
++    FIXME_(d3d_perf)("Forcing coalesce, not enough free space in buffer heap.\n");
++    int num_coalesced;
++    if (SUCCEEDED(wined3d_buffer_heap_deferred_coalesce(heap, &num_coalesced)))
++    {
++        if (num_coalesced > 0)
++            return wined3d_buffer_heap_alloc(heap, size, out_range);
++    }
++
++    FIXME_(d3d_perf)("Coalescing did not create new blocks, failing.\n");
++
++    return WINED3DERR_OUTOFVIDEOMEMORY;
++}
++
++HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3d_map_range range)
++{
++    struct wined3d_buffer_heap_element *elem = element_new(range.offset, range.size);
++
++    if (!elem)
++        return E_OUTOFMEMORY;
++
++    EnterCriticalSection(&heap->temp_lock);
++
++    // Only insert the element into a free bin, coalescing will occur later.
++    element_insert_free_bin(heap, elem);
++
++    LeaveCriticalSection(&heap->temp_lock);
++
++    return WINED3D_OK;
++}
++
++HRESULT wined3d_buffer_heap_free_fenced(struct wined3d_buffer_heap *heap, struct wined3d_device *device, struct wined3d_map_range range)
++{
++    struct wined3d_buffer_heap_element *elem = element_new(range.offset, range.size);
++    int bin_index = element_bin(elem);
++    struct wined3d_buffer_heap_bin *bin = &heap->pending_fenced_bins.bins[bin_index];
++
++    if (bin->tail)
++    {
++        bin->tail->next = elem;
++        elem->prev = bin->tail;
++        bin->tail = elem;
++    }
++    else
++    {
++        bin->head = elem;
++        bin->tail = elem;
++    }
++
++    return WINED3D_OK;
++}
++
++HRESULT wined3d_buffer_heap_cs_fence_issue(struct wined3d_buffer_heap *heap, struct wined3d_device *device)
++{
++    struct wined3d_buffer_heap_fenced_element *fenced_elem;
++    struct wined3d_fence *fence;
++    HRESULT hr;
++
++    if (heap->fenced_head)
++    {
++        // XXX(acomminos): double or triple buffer this?
++        wined3d_buffer_heap_cs_fence_wait(heap, device);
++    }
++
++    if (FAILED(hr = wined3d_fence_create(device, &fence)))
++    {
++        ERR("Failed to create fence.\n");
++        return hr;
++    }
++
++    fenced_elem = fenced_element_new(heap->pending_fenced_bins, fence);
++    if (!fenced_elem)
++        return E_OUTOFMEMORY;
++
++    TRACE_(d3d_perf)("Dispatching fenced buffer set.\n");
++    memset(&heap->pending_fenced_bins, 0, sizeof(heap->pending_fenced_bins));
++
++    // Append to end of fenced list, which works well if you assume that buffers
++    // are freed in some ascending draw call ordering.
++    if (!heap->fenced_head)
++    {
++        heap->fenced_head = fenced_elem;
++        heap->fenced_tail = fenced_elem;
++    }
++    else
++    {
++        heap->fenced_tail->next = fenced_elem;
++        heap->fenced_tail = fenced_elem;
++    }
++
++    wined3d_fence_issue(fence, device);
++    return WINED3D_OK;
++}
++
++HRESULT wined3d_buffer_heap_cs_fence_wait(struct wined3d_buffer_heap *heap, struct wined3d_device *device)
++{
++    enum wined3d_fence_result res;
++    struct wined3d_buffer_heap_fenced_element *elem = heap->fenced_head;
++    if (!elem)
++        return WINED3D_OK;
++
++    res = wined3d_fence_wait(elem->fence, device);
++    switch (res)
++    {
++        case WINED3D_FENCE_OK:
++        case WINED3D_FENCE_NOT_STARTED:
++            {
++                TRACE_(d3d_perf)("Freed fence group.\n");
++
++                EnterCriticalSection(&heap->temp_lock);
++                for (int i = 0; i < WINED3D_BUFFER_HEAP_BINS; i++)
++                {
++                    struct wined3d_buffer_heap_bin *elem_bin = &elem->free_list.bins[i];
++                    if (!elem_bin->tail)
++                        continue;
++
++                    struct wined3d_buffer_heap_bin *heap_bin = &heap->free_list.bins[i];
++                    if (heap_bin->head)
++                    {
++                        // Insert to front.
++                        elem_bin->tail->next = heap_bin->head;
++                        heap_bin->head->prev = elem_bin->tail;
++
++                        elem_bin->head->prev = NULL;
++                        heap_bin->head = elem_bin->head;
++                    }
++                    else
++                    {
++                        elem_bin->head->prev = NULL;
++                        heap_bin->head = elem_bin->head;
++                        elem_bin->tail->next = NULL;
++                        heap_bin->tail = elem_bin->tail;
++                    }
++                }
++                LeaveCriticalSection(&heap->temp_lock);
++
++                wined3d_fence_destroy(elem->fence);
++
++                heap->fenced_head = elem->next;
++                HeapFree(GetProcessHeap(), 0, elem);
++                // TODO(acomminos): bother to null out fenced_tail?
++                break;
++            }
++        default:
++            return WINED3D_OK;
++    }
++
++    return WINED3D_OK;
++}
++
++HRESULT wined3d_buffer_heap_deferred_coalesce(struct wined3d_buffer_heap *heap, int *coalesced_count)
++{
++    struct wined3d_buffer_heap_element *elem = NULL;
++    struct wined3d_buffer_heap_element *next = NULL;
++    struct wine_rb_entry *entry;
++    struct wined3d_map_range coalesced_range;
++
++    struct wine_rb_tree free_tree;
++    int num_coalesced = 0;
++
++    wine_rb_init(&free_tree, free_tree_compare);
++
++    EnterCriticalSection(&heap->temp_lock);
++
++    // TODO(acomminos): on one hand, if there's a lot of elements in the list,
++    // it's highly fragmented. on the other, we can potentially waste a decent
++    // sum of time checking for uncoalesced bins.
++    for (int i = 0; i < WINED3D_BUFFER_HEAP_BINS; i++)
++    {
++        elem = heap->free_list.bins[i].head;
++        while (elem)
++        {
++            // Insert a sentry. FIXME(acomminos): can skip this with traversal.
++            if (wine_rb_put(&free_tree, &elem->range.offset, &elem->entry) == -1)
++            {
++                ERR("Failed to insert key %x in tree.\n", elem->range.offset);
++                elem = elem->next;
++                continue;
++            }
++
++            coalesced_range = elem->range;
++
++            // Coalesce right.
++            entry = wine_rb_next(&elem->entry);
++            if (entry)
++            {
++                TRACE("Coalesced right.\n");
++                struct wined3d_buffer_heap_element *right_elem = WINE_RB_ENTRY_VALUE(entry, struct wined3d_buffer_heap_element, entry);
++                if (elem->range.offset + elem->range.size == right_elem->range.offset)
++                {
++                    coalesced_range.size += right_elem->range.size;
++
++                    wine_rb_remove(&free_tree, entry);
++                    element_remove_free(heap, right_elem);
++                    HeapFree(GetProcessHeap(), 0, right_elem);
++
++                    num_coalesced++;
++                }
++            }
++
++            // Coalesce left.
++            entry = wine_rb_prev(&elem->entry);
++            if (entry)
++            {
++                TRACE("Coalesced left.\n");
++                struct wined3d_buffer_heap_element *left_elem = WINE_RB_ENTRY_VALUE(entry, struct wined3d_buffer_heap_element, entry);
++                if (left_elem->range.offset + left_elem->range.size == coalesced_range.offset)
++                {
++                    coalesced_range.offset = left_elem->range.offset;
++                    coalesced_range.size += left_elem->range.size;
++
++                    wine_rb_remove(&free_tree, entry);
++                    element_remove_free(heap, left_elem);
++                    HeapFree(GetProcessHeap(), 0, left_elem);
++
++                    num_coalesced++;
++                }
++            }
++
++            next = elem->next;
++
++            if (elem->range.size != coalesced_range.size)
++            {
++                FIXME_(d3d_perf)("Coalesced range from (%p, %ld) to (%p, %ld)\n", elem->range.offset, elem->range.size, coalesced_range.offset, coalesced_range.size);
++
++                wine_rb_remove(&free_tree, &elem->entry);
++
++                // Move to the correct free bin.
++                element_remove_free(heap, elem);
++                elem->range = coalesced_range;
++                element_insert_free_bin(heap, elem);
++
++                wine_rb_put(&free_tree, &elem->range.offset, &elem->entry);
++            }
++
++            elem = next;
++        }
++    }
++
++    LeaveCriticalSection(&heap->temp_lock);
++
++    FIXME_(d3d_perf)("Performed %d coalesces.\n", num_coalesced);
++    if (coalesced_count)
++        *coalesced_count = num_coalesced;
++
++    return WINED3D_OK;
++}
+diff --git a/dlls/wined3d/cs.c b/dlls/wined3d/cs.c
+index fc3e47e3298..ac9adb03fa9 100644
+--- a/dlls/wined3d/cs.c
++++ b/dlls/wined3d/cs.c
+@@ -528,2 +528,11 @@ static void wined3d_cs_exec_present(struct wined3d_cs *cs, const void *data)
+     InterlockedDecrement(&cs->pending_presents);
++
++    // FIXME(acomminos): is this the right place to put double-buffered frame
++    //                   timing based logic?
++    // FIXME(acomminos): this conditional sucks, replace with fancier feature check
++    if (cs->device->wo_buffer_heap && cs->device->cb_buffer_heap)
++    {
++        wined3d_buffer_heap_cs_fence_issue(cs->device->wo_buffer_heap, cs->device);
++        wined3d_buffer_heap_cs_fence_issue(cs->device->cb_buffer_heap, cs->device);
++    }
+ }
+diff --git a/dlls/wined3d/device.c b/dlls/wined3d/device.c
+index 8b202fce0cf..302f4868ca8 100644
+--- a/dlls/wined3d/device.c
++++ b/dlls/wined3d/device.c
+@@ -841,2 +841,49 @@ static void destroy_default_samplers(struct wined3d_device *device, struct wined
+ 
++/* Context activation is done by the caller. */
++static void create_buffer_heap(struct wined3d_device *device, struct wined3d_context *context)
++{
++    const struct wined3d_gl_info *gl_info = &device->adapter->gl_info;
++    // TODO(acomminos): kill this magic number. perhaps base on vram.
++    GLsizeiptr geo_heap_size = 512 * 1024 * 1024;
++    // We choose a constant buffer size of 128MB, the same as NVIDIA claims to
++    // use in their Direct3D driver for discarded constant buffers.
++    GLsizeiptr cb_heap_size = 128 * 1024 * 1024;
++    GLint ub_alignment;
++    HRESULT hr;
++
++    if (gl_info->supported[ARB_BUFFER_STORAGE])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_UNIFORM_BUFFER_OFFSET_ALIGNMENT, &ub_alignment);
++
++        // Align constant buffer heap size, in case GL_UNIFORM_BUFFER_OFFSET_ALIGNMENT isn't a power of two (for some reason).
++        cb_heap_size -= cb_heap_size % ub_alignment;
++
++        if (FAILED(hr = wined3d_buffer_heap_create(context, geo_heap_size, 0, TRUE, &device->wo_buffer_heap)))
++        {
++            ERR("Failed to create write-only persistent buffer heap, hr %#x.\n", hr);
++        }
++
++        if (FAILED(hr = wined3d_buffer_heap_create(context, cb_heap_size, ub_alignment, TRUE, &device->cb_buffer_heap)))
++        {
++            ERR("Failed to create persistent buffer heap for constant buffers, hr %#x.\n", hr);
++        }
++
++        FIXME("Initialized PBA (geo_heap_size: %ld, cb_heap_size: %ld, ub_align: %d)\n", geo_heap_size, cb_heap_size, ub_alignment);
++    }
++    else
++    {
++        FIXME("Not using PBA, ARB_buffer_storage unsupported.\n");
++    }
++}
++
++/* Context activation is done by the caller. */
++static void destroy_buffer_heap(struct wined3d_device *device, struct wined3d_context *context)
++{
++    if (device->wo_buffer_heap)
++        wined3d_buffer_heap_destroy(device->wo_buffer_heap, context);
++
++    if (device->cb_buffer_heap)
++        wined3d_buffer_heap_destroy(device->cb_buffer_heap, context);
++}
++
+ static LONG fullscreen_style(LONG style)
+@@ -1005,2 +1052,4 @@ static void wined3d_device_delete_opengl_contexts_cs(void *object)
+     destroy_default_samplers(device, context);
++    destroy_buffer_heap(device, context);
++
+     context_release(context);
+@@ -1054,2 +1103,5 @@ static void wined3d_device_create_primary_opengl_context_cs(void *object)
+     create_default_samplers(device, context);
++
++    create_buffer_heap(device, context);
++
+     context_release(context);
+diff --git a/dlls/wined3d/directx.c b/dlls/wined3d/directx.c
+index e65db79decd..56aeb3171f9 100644
+--- a/dlls/wined3d/directx.c
++++ b/dlls/wined3d/directx.c
+@@ -45,2 +45,3 @@ static const GUID IID_D3DDEVICE_D3DUID = { 0xaeb2cdd4, 0x6e41, 0x43ea, { 0x94,0x
+ 
++
+ /**********************************************************
+@@ -582,2 +583,2650 @@ void wined3d_driver_info_init(struct wined3d_driver_info *driver_info,
+     if (driver_model < DRIVER_MODEL_NT6X && driver_info->vram_bytes > LONG_MAX)
++<<<<<<< HEAD
++=======
++    {
++        TRACE("Limiting amount of video memory to %#lx bytes for OS version older than Vista.\n", LONG_MAX);
++        driver_info->vram_bytes = LONG_MAX;
++    }
++
++    /* Try to obtain driver version information for the current Windows version. This fails in
++     * some cases:
++     * - the gpu is not available on the currently selected OS version:
++     *   - Geforce GTX480 on Win98. When running applications in compatibility mode on Windows,
++     *     version information for the current Windows version is returned instead of faked info.
++     *     We do the same and assume the default Windows version to emulate is WinXP.
++     *
++     *   - Videocard is a Riva TNT but winver is set to win7 (there are no drivers for this beast)
++     *     For now return the XP driver info. Perhaps later on we should return VESA.
++     *
++     * - the gpu is not in our database (can happen when the user overrides the vendor_id / device_id)
++     *   This could be an indication that our database is not up to date, so this should be fixed.
++     */
++    if ((version_info = get_driver_version_info(driver, driver_model))
++            || (version_info = get_driver_version_info(driver, DRIVER_MODEL_GENERIC)))
++    {
++        driver_info->name = version_info->driver_name;
++        driver_info->version_high = MAKEDWORD_VERSION(driver_os_version, version_info->version);
++        driver_info->version_low = MAKEDWORD_VERSION(version_info->subversion, version_info->build);
++    }
++    else
++    {
++        ERR("No driver version info found for device %04x:%04x, driver model %#x.\n",
++                driver_info->vendor, driver_info->device, driver_model);
++        driver_info->name = "Display";
++        driver_info->version_high = MAKEDWORD_VERSION(driver_os_version, 15);
++        driver_info->version_low = MAKEDWORD_VERSION(8, 6); /* Nvidia RIVA TNT, arbitrary */
++    }
++
++    TRACE("Reporting (fake) driver version 0x%08x-0x%08x.\n",
++            driver_info->version_high, driver_info->version_low);
++}
++
++/* Context activation is done by the caller. */
++static void fixup_extensions(struct wined3d_gl_info *gl_info, struct wined3d_caps_gl_ctx *ctx,
++        const char *gl_renderer, enum wined3d_gl_vendor gl_vendor,
++        enum wined3d_pci_vendor card_vendor, enum wined3d_pci_device device)
++{
++    unsigned int i;
++
++    for (i = 0; i < ARRAY_SIZE(quirk_table); ++i)
++    {
++        if (!quirk_table[i].match(gl_info, ctx, gl_renderer, gl_vendor, card_vendor, device)) continue;
++        TRACE("Applying driver quirk \"%s\".\n", quirk_table[i].description);
++        quirk_table[i].apply(gl_info);
++    }
++
++    /* Find out if PBOs work as they are supposed to. */
++    test_pbo_functionality(gl_info);
++}
++
++static DWORD wined3d_parse_gl_version(const char *gl_version)
++{
++    const char *ptr = gl_version;
++    int major, minor;
++
++    major = atoi(ptr);
++    if (major <= 0)
++        ERR("Invalid OpenGL major version %d.\n", major);
++
++    while (isdigit(*ptr)) ++ptr;
++    if (*ptr++ != '.')
++        ERR("Invalid OpenGL version string %s.\n", debugstr_a(gl_version));
++
++    minor = atoi(ptr);
++
++    TRACE("Found OpenGL version %d.%d.\n", major, minor);
++
++    return MAKEDWORD_VERSION(major, minor);
++}
++
++static enum wined3d_gl_vendor wined3d_guess_gl_vendor(const struct wined3d_gl_info *gl_info,
++        const char *gl_vendor_string, const char *gl_renderer, const char *gl_version)
++{
++    /* MacOS has various specialities in the extensions it advertises. Some have to be loaded from
++     * the opengl 1.2+ core, while other extensions are advertised, but software emulated. So try to
++     * detect the Apple OpenGL implementation to apply some extension fixups afterwards.
++     *
++     * Detecting this isn't really easy. The vendor string doesn't mention Apple. Compile-time checks
++     * aren't sufficient either because a Linux binary may display on a macos X server via remote X11.
++     * So try to detect the GL implementation by looking at certain Apple extensions. Some extensions
++     * like client storage might be supported on other implementations too, but GL_APPLE_flush_render
++     * is specific to the Mac OS X window management, and GL_APPLE_ycbcr_422 is QuickTime specific. So
++     * the chance that other implementations support them is rather small since Win32 QuickTime uses
++     * DirectDraw, not OpenGL. */
++    if (gl_info->supported[APPLE_FENCE] && gl_info->supported[APPLE_YCBCR_422])
++        return GL_VENDOR_APPLE;
++
++    if (strstr(gl_vendor_string, "NVIDIA"))
++        return GL_VENDOR_NVIDIA;
++
++    if (strstr(gl_vendor_string, "ATI"))
++        return GL_VENDOR_FGLRX;
++
++    if (strstr(gl_vendor_string, "Mesa")
++            || strstr(gl_vendor_string, "X.Org")
++            || strstr(gl_vendor_string, "Advanced Micro Devices, Inc.")
++            || strstr(gl_vendor_string, "DRI R300 Project")
++            || strstr(gl_vendor_string, "Tungsten Graphics, Inc")
++            || strstr(gl_vendor_string, "VMware, Inc.")
++            || strstr(gl_vendor_string, "Intel")
++            || strstr(gl_renderer, "Mesa")
++            || strstr(gl_renderer, "Gallium")
++            || strstr(gl_renderer, "Intel")
++            || strstr(gl_version, "Mesa"))
++        return GL_VENDOR_MESA;
++
++    FIXME("Received unrecognized GL_VENDOR %s. Returning GL_VENDOR_UNKNOWN.\n",
++            debugstr_a(gl_vendor_string));
++
++    return GL_VENDOR_UNKNOWN;
++}
++
++static enum wined3d_pci_vendor wined3d_guess_card_vendor(const char *gl_vendor_string, const char *gl_renderer)
++{
++    if (strstr(gl_vendor_string, "NVIDIA")
++            || strstr(gl_vendor_string, "Nouveau")
++            || strstr(gl_vendor_string, "nouveau"))
++        return HW_VENDOR_NVIDIA;
++
++    if (strstr(gl_vendor_string, "ATI")
++            || strstr(gl_vendor_string, "Advanced Micro Devices, Inc.")
++            || strstr(gl_vendor_string, "X.Org R300 Project")
++            || strstr(gl_renderer, "AMD")
++            || strstr(gl_renderer, "FirePro")
++            || strstr(gl_renderer, "Radeon")
++            || strstr(gl_renderer, "R100")
++            || strstr(gl_renderer, "R200")
++            || strstr(gl_renderer, "R300")
++            || strstr(gl_renderer, "R600")
++            || strstr(gl_renderer, "R700"))
++        return HW_VENDOR_AMD;
++
++    if (strstr(gl_vendor_string, "Intel(R)")
++            /* Intel switched from Intel(R) to IntelÂ® recently, so just match Intel. */
++            || strstr(gl_renderer, "Intel")
++            || strstr(gl_renderer, "i915")
++            || strstr(gl_vendor_string, "Intel Inc."))
++        return HW_VENDOR_INTEL;
++
++    if (strstr(gl_renderer, "SVGA3D"))
++        return HW_VENDOR_VMWARE;
++
++    if (strstr(gl_vendor_string, "Mesa")
++            || strstr(gl_vendor_string, "Brian Paul")
++            || strstr(gl_vendor_string, "Tungsten Graphics, Inc")
++            || strstr(gl_vendor_string, "VMware, Inc."))
++        return HW_VENDOR_SOFTWARE;
++
++    FIXME("Received unrecognized GL_VENDOR %s. Returning HW_VENDOR_NVIDIA.\n", debugstr_a(gl_vendor_string));
++
++    return HW_VENDOR_NVIDIA;
++}
++
++static enum wined3d_feature_level feature_level_from_caps(const struct wined3d_gl_info *gl_info,
++        const struct shader_caps *shader_caps, const struct fragment_caps *fragment_caps)
++{
++    unsigned int shader_model;
++
++    shader_model = min(shader_caps->vs_version, shader_caps->ps_version);
++    shader_model = min(shader_model, max(shader_caps->gs_version, 3));
++    shader_model = min(shader_model, max(shader_caps->hs_version, 4));
++    shader_model = min(shader_model, max(shader_caps->ds_version, 4));
++
++    if (gl_info->supported[WINED3D_GL_VERSION_3_2] && gl_info->supported[ARB_SAMPLER_OBJECTS])
++    {
++        if (shader_model >= 5
++                && gl_info->supported[ARB_DRAW_INDIRECT]
++                && gl_info->supported[ARB_TEXTURE_COMPRESSION_BPTC])
++            return WINED3D_FEATURE_LEVEL_11;
++
++        if (shader_model == 4)
++            return WINED3D_FEATURE_LEVEL_10;
++    }
++
++    if (shader_model == 3)
++        return WINED3D_FEATURE_LEVEL_9_SM3;
++    if (shader_model == 2)
++        return WINED3D_FEATURE_LEVEL_9_SM2;
++    if (shader_model == 1)
++        return WINED3D_FEATURE_LEVEL_8;
++
++    if (fragment_caps->TextureOpCaps & WINED3DTEXOPCAPS_DOTPRODUCT3)
++        return WINED3D_FEATURE_LEVEL_7;
++    if (fragment_caps->MaxSimultaneousTextures > 1)
++        return WINED3D_FEATURE_LEVEL_6;
++
++    return WINED3D_FEATURE_LEVEL_5;
++}
++
++static const struct wined3d_renderer_table
++{
++    const char *renderer;
++    enum wined3d_pci_device id;
++}
++cards_nvidia_binary[] =
++{
++    /* Direct 3D 11 */
++    {"TITAN V",                     CARD_NVIDIA_TITANV},            /* GeForce 1000 - highend */
++    {"TITAN X (Pascal)",            CARD_NVIDIA_TITANX_PASCAL},     /* GeForce 1000 - highend */
++    {"GTX 1080 Ti",                 CARD_NVIDIA_GEFORCE_GTX1080TI}, /* GeForce 1000 - highend */
++    {"GTX 1080",                    CARD_NVIDIA_GEFORCE_GTX1080},   /* GeForce 1000 - highend */
++    {"GTX 1070",                    CARD_NVIDIA_GEFORCE_GTX1070},   /* GeForce 1000 - highend */
++    {"GTX 1060",                    CARD_NVIDIA_GEFORCE_GTX1060},   /* GeForce 1000 - midend high */
++    {"GTX 1050 Ti",                 CARD_NVIDIA_GEFORCE_GTX1050TI}, /* GeForce 1000 - midend */
++    {"GTX 1050",                    CARD_NVIDIA_GEFORCE_GTX1050},   /* GeForce 1000 - midend */
++    {"GTX 980 Ti",                  CARD_NVIDIA_GEFORCE_GTX980TI},  /* GeForce 900 - highend */
++    {"GTX 980",                     CARD_NVIDIA_GEFORCE_GTX980},    /* GeForce 900 - highend */
++    {"GTX 970M",                    CARD_NVIDIA_GEFORCE_GTX970M},   /* GeForce 900 - highend mobile*/
++    {"GTX 970",                     CARD_NVIDIA_GEFORCE_GTX970},    /* GeForce 900 - highend */
++    {"GTX TITAN X",                 CARD_NVIDIA_GEFORCE_GTXTITANX}, /* Geforce 900 - highend */
++    {"GTX 960M",                    CARD_NVIDIA_GEFORCE_GTX960M},   /* GeForce 900 - midend high mobile */
++    {"GTX 960",                     CARD_NVIDIA_GEFORCE_GTX960},    /* GeForce 900 - midend high */
++    {"GTX 950M",                    CARD_NVIDIA_GEFORCE_GTX950M},   /* GeForce 900 - midend mobile */
++    {"GTX 950",                     CARD_NVIDIA_GEFORCE_GTX950},    /* GeForce 900 - midend */
++    {"GeForce 940M",                CARD_NVIDIA_GEFORCE_940M},      /* GeForce 900 - midend mobile */
++    {"GTX 880M",                    CARD_NVIDIA_GEFORCE_GTX880M},   /* GeForce 800 - mobile */
++    {"GTX 870M",                    CARD_NVIDIA_GEFORCE_GTX870M},   /* GeForce 800 - mobile */
++    {"GTX 860M",                    CARD_NVIDIA_GEFORCE_GTX860M},   /* GeForce 800 - mobile */
++    {"GTX 850M",                    CARD_NVIDIA_GEFORCE_GTX850M},   /* GeForce 800 - mobile */
++    {"GeForce 845M",                CARD_NVIDIA_GEFORCE_845M},      /* GeForce 800 - mobile */
++    {"GeForce 840M",                CARD_NVIDIA_GEFORCE_840M},      /* GeForce 800 - mobile */
++    {"GeForce 830M",                CARD_NVIDIA_GEFORCE_830M},      /* GeForce 800 - mobile */
++    {"GeForce 820M",                CARD_NVIDIA_GEFORCE_820M},      /* GeForce 800 - mobile */
++    {"GTX 780 Ti",                  CARD_NVIDIA_GEFORCE_GTX780TI},  /* Geforce 700 - highend */
++    {"GTX TITAN Black",             CARD_NVIDIA_GEFORCE_GTXTITANB}, /* Geforce 700 - highend */
++    {"GTX TITAN Z",                 CARD_NVIDIA_GEFORCE_GTXTITANZ}, /* Geforce 700 - highend */
++    {"GTX TITAN",                   CARD_NVIDIA_GEFORCE_GTXTITAN},  /* Geforce 700 - highend */
++    {"GTX 780",                     CARD_NVIDIA_GEFORCE_GTX780},    /* Geforce 700 - highend */
++    {"GTX 770M",                    CARD_NVIDIA_GEFORCE_GTX770M},   /* Geforce 700 - midend high mobile */
++    {"GTX 770",                     CARD_NVIDIA_GEFORCE_GTX770},    /* Geforce 700 - highend */
++    {"GTX 765M",                    CARD_NVIDIA_GEFORCE_GTX765M},   /* Geforce 700 - midend high mobile */
++    {"GTX 760 Ti",                  CARD_NVIDIA_GEFORCE_GTX760TI},  /* Geforce 700 - midend high */
++    {"GTX 760",                     CARD_NVIDIA_GEFORCE_GTX760},    /* Geforce 700 - midend high  */
++    {"GTX 750 Ti",                  CARD_NVIDIA_GEFORCE_GTX750TI},  /* Geforce 700 - midend */
++    {"GTX 750",                     CARD_NVIDIA_GEFORCE_GTX750},    /* Geforce 700 - midend */
++    {"GT 750M",                     CARD_NVIDIA_GEFORCE_GT750M},    /* Geforce 700 - midend mobile */
++    {"GT 740M",                     CARD_NVIDIA_GEFORCE_GT740M},    /* Geforce 700 - midend mobile */
++    {"GT 730M",                     CARD_NVIDIA_GEFORCE_GT730M},    /* Geforce 700 - midend mobile */
++    {"GT 730",                      CARD_NVIDIA_GEFORCE_GT730},     /* Geforce 700 - lowend */
++    {"GTX 690",                     CARD_NVIDIA_GEFORCE_GTX690},    /* Geforce 600 - highend */
++    {"GTX 680",                     CARD_NVIDIA_GEFORCE_GTX680},    /* Geforce 600 - highend */
++    {"GTX 675MX",                   CARD_NVIDIA_GEFORCE_GTX675MX},  /* Geforce 600 - highend */
++    {"GTX 670MX",                   CARD_NVIDIA_GEFORCE_GTX670MX},  /* Geforce 600 - highend */
++    {"GTX 670",                     CARD_NVIDIA_GEFORCE_GTX670},    /* Geforce 600 - midend high */
++    {"GTX 660 Ti",                  CARD_NVIDIA_GEFORCE_GTX660TI},  /* Geforce 600 - midend high */
++    {"GTX 660M",                    CARD_NVIDIA_GEFORCE_GTX660M},   /* Geforce 600 - midend high mobile */
++    {"GTX 660",                     CARD_NVIDIA_GEFORCE_GTX660},    /* Geforce 600 - midend high */
++    {"GTX 650 Ti",                  CARD_NVIDIA_GEFORCE_GTX650TI},  /* Geforce 600 - lowend */
++    {"GTX 650",                     CARD_NVIDIA_GEFORCE_GTX650},    /* Geforce 600 - lowend */
++    {"GT 650M",                     CARD_NVIDIA_GEFORCE_GT650M},    /* Geforce 600 - midend mobile */
++    {"GT 640M",                     CARD_NVIDIA_GEFORCE_GT640M},    /* Geforce 600 - midend mobile */
++    {"GT 630M",                     CARD_NVIDIA_GEFORCE_GT630M},    /* Geforce 600 - midend mobile */
++    {"GT 630",                      CARD_NVIDIA_GEFORCE_GT630},     /* Geforce 600 - lowend */
++    {"GT 610",                      CARD_NVIDIA_GEFORCE_GT610},     /* Geforce 600 - lowend */
++    {"GTX 580",                     CARD_NVIDIA_GEFORCE_GTX580},    /* Geforce 500 - highend */
++    {"GTX 570",                     CARD_NVIDIA_GEFORCE_GTX570},    /* Geforce 500 - midend high */
++    {"GTX 560 Ti",                  CARD_NVIDIA_GEFORCE_GTX560TI},  /* Geforce 500 - midend */
++    {"GTX 560M",                    CARD_NVIDIA_GEFORCE_GTX560M},   /* Geforce 500 - midend mobile */
++    {"GTX 560",                     CARD_NVIDIA_GEFORCE_GTX560},    /* Geforce 500 - midend */
++    {"GT 555M",                     CARD_NVIDIA_GEFORCE_GT555M},    /* Geforce 500 - midend mobile */
++    {"GTX 550 Ti",                  CARD_NVIDIA_GEFORCE_GTX550},    /* Geforce 500 - midend */
++    {"GT 540M",                     CARD_NVIDIA_GEFORCE_GT540M},    /* Geforce 500 - midend mobile */
++    {"GT 525M",                     CARD_NVIDIA_GEFORCE_GT525M},    /* Geforce 500 - lowend mobile */
++    {"GT 520",                      CARD_NVIDIA_GEFORCE_GT520},     /* Geforce 500 - lowend */
++    {"GTX 480",                     CARD_NVIDIA_GEFORCE_GTX480},    /* Geforce 400 - highend */
++    {"GTX 470",                     CARD_NVIDIA_GEFORCE_GTX470},    /* Geforce 400 - midend high */
++    /* Direct 3D 10 */
++    {"GTX 465",                     CARD_NVIDIA_GEFORCE_GTX465},    /* Geforce 400 - midend */
++    {"GTX 460M",                    CARD_NVIDIA_GEFORCE_GTX460M},   /* Geforce 400 - highend mobile */
++    {"GTX 460",                     CARD_NVIDIA_GEFORCE_GTX460},    /* Geforce 400 - midend */
++    {"GTS 450",                     CARD_NVIDIA_GEFORCE_GTS450},    /* Geforce 400 - midend low */
++    {"GT 440",                      CARD_NVIDIA_GEFORCE_GT440},     /* Geforce 400 - lowend */
++    {"GT 430",                      CARD_NVIDIA_GEFORCE_GT430},     /* Geforce 400 - lowend */
++    {"GT 425M",                     CARD_NVIDIA_GEFORCE_GT425M},    /* Geforce 400 - lowend mobile */
++    {"GT 420",                      CARD_NVIDIA_GEFORCE_GT420},     /* Geforce 400 - lowend */
++    {"410M",                        CARD_NVIDIA_GEFORCE_410M},      /* Geforce 400 - lowend mobile */
++    {"GT 330",                      CARD_NVIDIA_GEFORCE_GT330},     /* Geforce 300 - highend */
++    {"GTS 360M",                    CARD_NVIDIA_GEFORCE_GTS350M},   /* Geforce 300 - highend mobile */
++    {"GTS 350M",                    CARD_NVIDIA_GEFORCE_GTS350M},   /* Geforce 300 - highend mobile */
++    {"GT 330M",                     CARD_NVIDIA_GEFORCE_GT325M},    /* Geforce 300 - midend mobile */
++    {"GT 325M",                     CARD_NVIDIA_GEFORCE_GT325M},    /* Geforce 300 - midend mobile */
++    {"GT 320M",                     CARD_NVIDIA_GEFORCE_GT320M},    /* Geforce 300 - midend mobile */
++    {"320M",                        CARD_NVIDIA_GEFORCE_320M},      /* Geforce 300 - midend mobile */
++    {"315M",                        CARD_NVIDIA_GEFORCE_315M},      /* Geforce 300 - midend mobile */
++    {"GTX 295",                     CARD_NVIDIA_GEFORCE_GTX280},    /* Geforce 200 - highend */
++    {"GTX 285",                     CARD_NVIDIA_GEFORCE_GTX280},    /* Geforce 200 - highend */
++    {"GTX 280",                     CARD_NVIDIA_GEFORCE_GTX280},    /* Geforce 200 - highend */
++    {"GTX 275",                     CARD_NVIDIA_GEFORCE_GTX275},    /* Geforce 200 - midend high */
++    {"GTX 260",                     CARD_NVIDIA_GEFORCE_GTX260},    /* Geforce 200 - midend */
++    {"GTS 250",                     CARD_NVIDIA_GEFORCE_GTS250},    /* Geforce 200 - midend */
++    {"GT 240",                      CARD_NVIDIA_GEFORCE_GT240},     /* Geforce 200 - midend */
++    {"GT 220",                      CARD_NVIDIA_GEFORCE_GT220},     /* Geforce 200 - lowend */
++    {"GeForce 310",                 CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
++    {"GeForce 305",                 CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
++    {"GeForce 210",                 CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
++    {"G 210",                       CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
++    {"GTS 150",                     CARD_NVIDIA_GEFORCE_9800GT},    /* Geforce 9 - highend / Geforce 200 - midend */
++    {"9800",                        CARD_NVIDIA_GEFORCE_9800GT},    /* Geforce 9 - highend / Geforce 200 - midend */
++    {"9700M GT",                    CARD_NVIDIA_GEFORCE_9700MGT},   /* Geforce 9 - midend */
++    {"GT 140",                      CARD_NVIDIA_GEFORCE_9600GT},    /* Geforce 9 - midend */
++    {"9600",                        CARD_NVIDIA_GEFORCE_9600GT},    /* Geforce 9 - midend */
++    {"GT 130",                      CARD_NVIDIA_GEFORCE_9500GT},    /* Geforce 9 - midend low / Geforce 200 - low */
++    {"GT 120",                      CARD_NVIDIA_GEFORCE_9500GT},    /* Geforce 9 - midend low / Geforce 200 - low */
++    {"9500",                        CARD_NVIDIA_GEFORCE_9500GT},    /* Geforce 9 - midend low / Geforce 200 - low */
++    {"9400M",                       CARD_NVIDIA_GEFORCE_9400M},     /* Geforce 9 - lowend */
++    {"9400",                        CARD_NVIDIA_GEFORCE_9400GT},    /* Geforce 9 - lowend */
++    {"9300",                        CARD_NVIDIA_GEFORCE_9300},      /* Geforce 9 - lowend low */
++    {"9200",                        CARD_NVIDIA_GEFORCE_9200},      /* Geforce 9 - lowend low */
++    {"9100",                        CARD_NVIDIA_GEFORCE_9200},      /* Geforce 9 - lowend low */
++    {"G 100",                       CARD_NVIDIA_GEFORCE_9200},      /* Geforce 9 - lowend low */
++    {"8800 GTX",                    CARD_NVIDIA_GEFORCE_8800GTX},   /* Geforce 8 - highend high */
++    {"8800",                        CARD_NVIDIA_GEFORCE_8800GTS},   /* Geforce 8 - highend */
++    {"8600M",                       CARD_NVIDIA_GEFORCE_8600MGT},   /* Geforce 8 - midend mobile */
++    {"8600 M",                      CARD_NVIDIA_GEFORCE_8600MGT},   /* Geforce 8 - midend mobile */
++    {"8700",                        CARD_NVIDIA_GEFORCE_8600GT},    /* Geforce 8 - midend */
++    {"8600",                        CARD_NVIDIA_GEFORCE_8600GT},    /* Geforce 8 - midend */
++    {"8500",                        CARD_NVIDIA_GEFORCE_8500GT},    /* Geforce 8 - mid-lowend */
++    {"8400",                        CARD_NVIDIA_GEFORCE_8400GS},    /* Geforce 8 - mid-lowend */
++    {"8300",                        CARD_NVIDIA_GEFORCE_8300GS},    /* Geforce 8 - lowend */
++    {"8200",                        CARD_NVIDIA_GEFORCE_8200},      /* Geforce 8 - lowend */
++    {"8100",                        CARD_NVIDIA_GEFORCE_8200},      /* Geforce 8 - lowend */
++    /* Direct 3D 9 SM3 */
++    {"Quadro FX 5",                 CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
++    {"Quadro FX 4",                 CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
++    {"7950",                        CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
++    {"7900",                        CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
++    {"7800",                        CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
++    {"7700",                        CARD_NVIDIA_GEFORCE_7600},      /* Geforce 7 - midend */
++    {"7600",                        CARD_NVIDIA_GEFORCE_7600},      /* Geforce 7 - midend */
++    {"7400",                        CARD_NVIDIA_GEFORCE_7400},      /* Geforce 7 - lower medium */
++    {"7300",                        CARD_NVIDIA_GEFORCE_7300},      /* Geforce 7 - lowend */
++    {"6800",                        CARD_NVIDIA_GEFORCE_6800},      /* Geforce 6 - highend */
++    {"6700",                        CARD_NVIDIA_GEFORCE_6600GT},    /* Geforce 6 - midend */
++    {"6610",                        CARD_NVIDIA_GEFORCE_6600GT},    /* Geforce 6 - midend */
++    {"6600",                        CARD_NVIDIA_GEFORCE_6600GT},    /* Geforce 6 - midend */
++    /* Direct 3D 9 SM2 */
++    {"Quadro FX",                   CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
++    {"5950",                        CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
++    {"5900",                        CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
++    {"5800",                        CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
++    {"5750",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
++    {"5700",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
++    {"5650",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
++    {"5600",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
++    {"5500",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
++    {"5300",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
++    {"5250",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
++    {"5200",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
++    {"5100",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
++    /* Direct 3D 8 */
++    {"Quadro4",                     CARD_NVIDIA_GEFORCE4_TI4200},
++    {"GeForce4 Ti",                 CARD_NVIDIA_GEFORCE4_TI4200},   /* Geforce4 Ti4200/Ti4400/Ti4600/Ti4800 */
++    /* Direct 3D 7 */
++    {"GeForce4 MX",                 CARD_NVIDIA_GEFORCE4_MX},       /* MX420/MX440/MX460/MX4000 */
++    {"Quadro2 MXR",                 CARD_NVIDIA_GEFORCE2_MX},
++    {"GeForce2 MX",                 CARD_NVIDIA_GEFORCE2_MX},       /* Geforce2 standard/MX100/MX200/MX400 */
++    {"Quadro2",                     CARD_NVIDIA_GEFORCE2},
++    {"GeForce2",                    CARD_NVIDIA_GEFORCE2},          /* Geforce2 GTS/Pro/Ti/Ultra */
++    /* Direct 3D 6 */
++    {"TNT2",                        CARD_NVIDIA_RIVA_TNT2},         /* Riva TNT2 standard/M64/Pro/Ultra */
++},
++/* See http://developer.amd.com/resources/hardware-drivers/ati-catalyst-pc-vendor-id-1002-li/
++ *
++ * Beware: renderer string do not match exact card model,
++ * eg HD 4800 is returned for multiple cards, even for RV790 based ones. */
++cards_amd_binary[] =
++{
++    {"RX 480",                      CARD_AMD_RADEON_RX_480},
++    {"RX 460",                      CARD_AMD_RADEON_RX_460},
++    {"R9 Fury Series",              CARD_AMD_RADEON_R9_FURY},
++    /* Southern Islands */
++    {"HD 7900",                     CARD_AMD_RADEON_HD7900},
++    {"HD 7800",                     CARD_AMD_RADEON_HD7800},
++    {"HD 7700",                     CARD_AMD_RADEON_HD7700},
++    /* Northern Islands */
++    {"HD 6970",                     CARD_AMD_RADEON_HD6900},
++    {"HD 6900",                     CARD_AMD_RADEON_HD6900},
++    {"HD 6800",                     CARD_AMD_RADEON_HD6800},
++    {"HD 6770M",                    CARD_AMD_RADEON_HD6600M},
++    {"HD 6750M",                    CARD_AMD_RADEON_HD6600M},
++    {"HD 6700",                     CARD_AMD_RADEON_HD6700},
++    {"HD 6670",                     CARD_AMD_RADEON_HD6600},
++    {"HD 6630M",                    CARD_AMD_RADEON_HD6600M},
++    {"HD 6600M",                    CARD_AMD_RADEON_HD6600M},
++    {"HD 6600",                     CARD_AMD_RADEON_HD6600},
++    {"HD 6570",                     CARD_AMD_RADEON_HD6600},
++    {"HD 6500M",                    CARD_AMD_RADEON_HD6600M},
++    {"HD 6500",                     CARD_AMD_RADEON_HD6600},
++    {"HD 6480G",                    CARD_AMD_RADEON_HD6480G},
++    {"HD 6400",                     CARD_AMD_RADEON_HD6400},
++    {"HD 6300",                     CARD_AMD_RADEON_HD6300},
++    {"HD 6200",                     CARD_AMD_RADEON_HD6300},
++    /* Evergreen */
++    {"HD 5870",                     CARD_AMD_RADEON_HD5800},    /* Radeon EG CYPRESS PRO */
++    {"HD 5850",                     CARD_AMD_RADEON_HD5800},    /* Radeon EG CYPRESS XT */
++    {"HD 5800",                     CARD_AMD_RADEON_HD5800},    /* Radeon EG CYPRESS HD58xx generic renderer string */
++    {"HD 5770",                     CARD_AMD_RADEON_HD5700},    /* Radeon EG JUNIPER XT */
++    {"HD 5750",                     CARD_AMD_RADEON_HD5700},    /* Radeon EG JUNIPER LE */
++    {"HD 5700",                     CARD_AMD_RADEON_HD5700},    /* Radeon EG JUNIPER HD57xx generic renderer string */
++    {"HD 5670",                     CARD_AMD_RADEON_HD5600},    /* Radeon EG REDWOOD XT */
++    {"HD 5570",                     CARD_AMD_RADEON_HD5600},    /* Radeon EG REDWOOD PRO mapped to HD5600 series */
++    {"HD 5550",                     CARD_AMD_RADEON_HD5600},    /* Radeon EG REDWOOD LE mapped to HD5600 series */
++    {"HD 5450",                     CARD_AMD_RADEON_HD5400},    /* Radeon EG CEDAR PRO */
++    {"HD 5000",                     CARD_AMD_RADEON_HD5600},    /* Defaulting to HD 5600 */
++    /* R700 */
++    {"HD 4890",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV790 */
++    {"HD 4870",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV770 */
++    {"HD 4850",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV770 */
++    {"HD 4830",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV770 */
++    {"HD 4800",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV7xx HD48xx generic renderer string */
++    {"HD 4770",                     CARD_AMD_RADEON_HD4700},    /* Radeon RV740 */
++    {"HD 4700",                     CARD_AMD_RADEON_HD4700},    /* Radeon RV7xx HD47xx generic renderer string */
++    {"HD 4670",                     CARD_AMD_RADEON_HD4600},    /* Radeon RV730 */
++    {"HD 4650",                     CARD_AMD_RADEON_HD4600},    /* Radeon RV730 */
++    {"HD 4600",                     CARD_AMD_RADEON_HD4600},    /* Radeon RV730 */
++    {"HD 4550",                     CARD_AMD_RADEON_HD4350},    /* Radeon RV710 */
++    {"HD 4350",                     CARD_AMD_RADEON_HD4350},    /* Radeon RV710 */
++    /* R600/R700 integrated */
++    {"HD 4200M",                    CARD_AMD_RADEON_HD4200M},
++    {"HD 3300",                     CARD_AMD_RADEON_HD3200},
++    {"HD 3200",                     CARD_AMD_RADEON_HD3200},
++    {"HD 3100",                     CARD_AMD_RADEON_HD3200},
++    /* R600 */
++    {"HD 3870",                     CARD_AMD_RADEON_HD2900},    /* HD2900/HD3800 - highend */
++    {"HD 3850",                     CARD_AMD_RADEON_HD2900},    /* HD2900/HD3800 - highend */
++    {"HD 2900",                     CARD_AMD_RADEON_HD2900},    /* HD2900/HD3800 - highend */
++    {"HD 3830",                     CARD_AMD_RADEON_HD2600},    /* China-only midend */
++    {"HD 3690",                     CARD_AMD_RADEON_HD2600},    /* HD2600/HD3600 - midend */
++    {"HD 3650",                     CARD_AMD_RADEON_HD2600},    /* HD2600/HD3600 - midend */
++    {"HD 2600",                     CARD_AMD_RADEON_HD2600},    /* HD2600/HD3600 - midend */
++    {"HD 3470",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
++    {"HD 3450",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
++    {"HD 3430",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
++    {"HD 3400",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
++    {"HD 2400",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
++    {"HD 2350",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
++    /* Radeon R5xx */
++    {"X1950",                       CARD_AMD_RADEON_X1600},
++    {"X1900",                       CARD_AMD_RADEON_X1600},
++    {"X1800",                       CARD_AMD_RADEON_X1600},
++    {"X1650",                       CARD_AMD_RADEON_X1600},
++    {"X1600",                       CARD_AMD_RADEON_X1600},
++    /* Radeon R4xx + X1300/X1400/X1450/X1550/X2300/X2500/HD2300 (lowend R5xx)
++     * Note X2300/X2500/HD2300 are R5xx GPUs with a 2xxx naming but they are still DX9-only */
++    {"HD 2300",                     CARD_AMD_RADEON_X700},
++    {"X2500",                       CARD_AMD_RADEON_X700},
++    {"X2300",                       CARD_AMD_RADEON_X700},
++    {"X1550",                       CARD_AMD_RADEON_X700},
++    {"X1450",                       CARD_AMD_RADEON_X700},
++    {"X1400",                       CARD_AMD_RADEON_X700},
++    {"X1300",                       CARD_AMD_RADEON_X700},
++    {"X850",                        CARD_AMD_RADEON_X700},
++    {"X800",                        CARD_AMD_RADEON_X700},
++    {"X700",                        CARD_AMD_RADEON_X700},
++    /* Radeon Xpress Series - onboard, DX9b, Shader 2.0, 300-400 MHz */
++    {"Radeon Xpress",               CARD_AMD_RADEON_XPRESS_200M},
++},
++cards_intel[] =
++{
++    /* Skylake */
++    {"Iris Pro Graphics P580",      CARD_INTEL_IPP580_1},
++    {"Skylake",                     CARD_INTEL_HD520_1},
++    /* Broadwell */
++    {"Iris Pro P6300",              CARD_INTEL_IPP6300},
++    {"Iris Pro 6200",               CARD_INTEL_IP6200},
++    {"Iris 6100",                   CARD_INTEL_I6100},
++    {"Iris(TM) Graphics 6100",      CARD_INTEL_I6100},  /* MacOS */
++    /* Haswell */
++    {"Iris Pro 5200",               CARD_INTEL_IP5200_1},
++    {"Iris 5100",                   CARD_INTEL_I5100_1},
++    {"HD Graphics 5000",            CARD_INTEL_HD5000}, /* MacOS */
++    {"Haswell Mobile",              CARD_INTEL_HWM},
++    {"Iris OpenGL Engine",          CARD_INTEL_HWM},    /* MacOS */
++    /* Ivybridge */
++    {"Ivybridge Server",            CARD_INTEL_IVBS},
++    {"Ivybridge Mobile",            CARD_INTEL_IVBM},
++    {"Ivybridge Desktop",           CARD_INTEL_IVBD},
++    {"HD Graphics 4000",            CARD_INTEL_IVBD},   /* MacOS */
++    /* Sandybridge */
++    {"Sandybridge Server",          CARD_INTEL_SNBS},
++    {"Sandybridge Mobile",          CARD_INTEL_SNBM},
++    {"Sandybridge Desktop",         CARD_INTEL_SNBD},
++    /* Ironlake */
++    {"Ironlake Mobile",             CARD_INTEL_ILKM},
++    {"Ironlake Desktop",            CARD_INTEL_ILKD},
++    /* G4x */
++    {"B43",                         CARD_INTEL_B43},
++    {"G41",                         CARD_INTEL_G41},
++    {"G45",                         CARD_INTEL_G45},
++    {"Q45",                         CARD_INTEL_Q45},
++    {"Integrated Graphics Device",  CARD_INTEL_IGD},
++    {"GM45",                        CARD_INTEL_GM45},
++    /* i965 */
++    {"965GME",                      CARD_INTEL_965GME},
++    {"965GM",                       CARD_INTEL_965GM},
++    {"X3100",                       CARD_INTEL_965GM},  /* MacOS */
++    {"946GZ",                       CARD_INTEL_946GZ},
++    {"965G",                        CARD_INTEL_965G},
++    {"965Q",                        CARD_INTEL_965Q},
++    /* i945 */
++    {"Pineview M",                  CARD_INTEL_PNVM},
++    {"Pineview G",                  CARD_INTEL_PNVG},
++    {"IGD",                         CARD_INTEL_PNVG},
++    {"Q33",                         CARD_INTEL_Q33},
++    {"G33",                         CARD_INTEL_G33},
++    {"Q35",                         CARD_INTEL_Q35},
++    {"945GME",                      CARD_INTEL_945GME},
++    {"945GM",                       CARD_INTEL_945GM},
++    {"GMA 950",                     CARD_INTEL_945GM},  /* MacOS */
++    {"945G",                        CARD_INTEL_945G},
++    /* i915 */
++    {"915GM",                       CARD_INTEL_915GM},
++    {"E7221G",                      CARD_INTEL_E7221G},
++    {"915G",                        CARD_INTEL_915G},
++    /* i8xx */
++    {"865G",                        CARD_INTEL_865G},
++    {"845G",                        CARD_INTEL_845G},
++    {"855GM",                       CARD_INTEL_855GM},
++    {"830M",                        CARD_INTEL_830M},
++},
++/* 20101109 - These are never returned by current Gallium radeon
++ * drivers: R700, RV790, R680, RV535, RV516, R410, RS485, RV360, RV351. */
++cards_amd_mesa[] =
++{
++    /* Polaris 10/11 */
++    {"POLARIS10",                   CARD_AMD_RADEON_RX_480},
++    {"POLARIS11",                   CARD_AMD_RADEON_RX_460},
++    /* Volcanic Islands */
++    {"FIJI",                        CARD_AMD_RADEON_R9_FURY},
++    {"TONGA",                       CARD_AMD_RADEON_R9_285},
++    /* Sea Islands */
++    {"HAWAII",                      CARD_AMD_RADEON_R9_290},
++    {"KAVERI",                      CARD_AMD_RADEON_R7    },
++    {"KABINI",                      CARD_AMD_RADEON_R3    },
++    {"BONAIRE",                     CARD_AMD_RADEON_HD8770},
++    /* Southern Islands */
++    {"OLAND",                       CARD_AMD_RADEON_HD8670},
++    {"HAINAN",                      CARD_AMD_RADEON_HD8600M},
++    {"TAHITI",                      CARD_AMD_RADEON_HD7900},
++    {"PITCAIRN",                    CARD_AMD_RADEON_HD7800},
++    {"CAPE VERDE",                  CARD_AMD_RADEON_HD7700},
++    /* Northern Islands */
++    {"ARUBA",                       CARD_AMD_RADEON_HD7660D},
++    {"CAYMAN",                      CARD_AMD_RADEON_HD6900},
++    {"BARTS",                       CARD_AMD_RADEON_HD6800},
++    {"TURKS",                       CARD_AMD_RADEON_HD6600},
++    {"SUMO2",                       CARD_AMD_RADEON_HD6410D},   /* SUMO2 first, because we do a strstr(). */
++    {"SUMO",                        CARD_AMD_RADEON_HD6550D},
++    {"CAICOS",                      CARD_AMD_RADEON_HD6400},
++    {"PALM",                        CARD_AMD_RADEON_HD6300},
++    /* Evergreen */
++    {"HEMLOCK",                     CARD_AMD_RADEON_HD5900},
++    {"CYPRESS",                     CARD_AMD_RADEON_HD5800},
++    {"JUNIPER",                     CARD_AMD_RADEON_HD5700},
++    {"REDWOOD",                     CARD_AMD_RADEON_HD5600},
++    {"CEDAR",                       CARD_AMD_RADEON_HD5400},
++    /* R700 */
++    {"R700",                        CARD_AMD_RADEON_HD4800},
++    {"RV790",                       CARD_AMD_RADEON_HD4800},
++    {"RV770",                       CARD_AMD_RADEON_HD4800},
++    {"RV740",                       CARD_AMD_RADEON_HD4700},
++    {"RV730",                       CARD_AMD_RADEON_HD4600},
++    {"RV710",                       CARD_AMD_RADEON_HD4350},
++    /* R600/R700 integrated */
++    {"RS880",                       CARD_AMD_RADEON_HD4200M},
++    {"RS780",                       CARD_AMD_RADEON_HD3200},
++    /* R600 */
++    {"R680",                        CARD_AMD_RADEON_HD2900},
++    {"R600",                        CARD_AMD_RADEON_HD2900},
++    {"RV670",                       CARD_AMD_RADEON_HD3850},
++    {"RV635",                       CARD_AMD_RADEON_HD2600},
++    {"RV630",                       CARD_AMD_RADEON_HD2600},
++    {"RV620",                       CARD_AMD_RADEON_HD2350},
++    {"RV610",                       CARD_AMD_RADEON_HD2350},
++    /* R500 */
++    {"R580",                        CARD_AMD_RADEON_X1600},
++    {"R520",                        CARD_AMD_RADEON_X1600},
++    {"RV570",                       CARD_AMD_RADEON_X1600},
++    {"RV560",                       CARD_AMD_RADEON_X1600},
++    {"RV535",                       CARD_AMD_RADEON_X1600},
++    {"RV530",                       CARD_AMD_RADEON_X1600},
++    {"RV516",                       CARD_AMD_RADEON_X700},
++    {"RV515",                       CARD_AMD_RADEON_X700},
++    /* R400 */
++    {"R481",                        CARD_AMD_RADEON_X700},
++    {"R480",                        CARD_AMD_RADEON_X700},
++    {"R430",                        CARD_AMD_RADEON_X700},
++    {"R423",                        CARD_AMD_RADEON_X700},
++    {"R420",                        CARD_AMD_RADEON_X700},
++    {"R410",                        CARD_AMD_RADEON_X700},
++    {"RV410",                       CARD_AMD_RADEON_X700},
++    /* Radeon Xpress - onboard, DX9b, Shader 2.0, 300-400 MHz */
++    {"RS740",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RS690",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RS600",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RS485",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RS482",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RS480",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RS400",                       CARD_AMD_RADEON_XPRESS_200M},
++    {"RC410",                       CARD_AMD_RADEON_XPRESS_200M},
++    /* R300 */
++    {"R360",                        CARD_AMD_RADEON_9500},
++    {"R350",                        CARD_AMD_RADEON_9500},
++    {"R300",                        CARD_AMD_RADEON_9500},
++    {"RV380",                       CARD_AMD_RADEON_9500},
++    {"RV370",                       CARD_AMD_RADEON_9500},
++    {"RV360",                       CARD_AMD_RADEON_9500},
++    {"RV351",                       CARD_AMD_RADEON_9500},
++    {"RV350",                       CARD_AMD_RADEON_9500},
++},
++cards_nvidia_mesa[] =
++{
++    /* Maxwell */
++    {"NV124",                       CARD_NVIDIA_GEFORCE_GTX970},
++    {"NV120",                       CARD_NVIDIA_GEFORCE_GTX980TI},
++    {"NV118",                       CARD_NVIDIA_GEFORCE_840M},
++    {"NV117",                       CARD_NVIDIA_GEFORCE_GTX750},
++    /* Kepler */
++    {"NV108",                       CARD_NVIDIA_GEFORCE_GT740M},
++    {"NVF1",                        CARD_NVIDIA_GEFORCE_GTX780TI},
++    {"NVF0",                        CARD_NVIDIA_GEFORCE_GTX780},
++    {"NVE6",                        CARD_NVIDIA_GEFORCE_GTX770M},
++    {"NVE4",                        CARD_NVIDIA_GEFORCE_GTX680},    /* 690 / 675MX / 760TI */
++    /* Fermi */
++    {"NVD9",                        CARD_NVIDIA_GEFORCE_GT520},
++    {"NVD7",                        CARD_NVIDIA_GEFORCE_820M},
++    {"NVCF",                        CARD_NVIDIA_GEFORCE_GTX550},
++    {"NVCE",                        CARD_NVIDIA_GEFORCE_GTX560},
++    {"NVC8",                        CARD_NVIDIA_GEFORCE_GTX570},
++    {"NVC4",                        CARD_NVIDIA_GEFORCE_GTX460},
++    {"NVC3",                        CARD_NVIDIA_GEFORCE_GT440},
++    {"NVC1",                        CARD_NVIDIA_GEFORCE_GT420},
++    {"NVC0",                        CARD_NVIDIA_GEFORCE_GTX480},
++    /* Tesla */
++    {"NVAF",                        CARD_NVIDIA_GEFORCE_GT320M},
++    {"NVAC",                        CARD_NVIDIA_GEFORCE_8200},
++    {"NVAA",                        CARD_NVIDIA_GEFORCE_8200},      /* 8100 */
++    {"NVA8",                        CARD_NVIDIA_GEFORCE_210},
++    {"NVA5",                        CARD_NVIDIA_GEFORCE_GT220},
++    {"NVA3",                        CARD_NVIDIA_GEFORCE_GT240},
++    {"NVA0",                        CARD_NVIDIA_GEFORCE_GTX280},
++    {"NV98",                        CARD_NVIDIA_GEFORCE_9200},
++    {"NV96",                        CARD_NVIDIA_GEFORCE_9400GT},
++    {"NV94",                        CARD_NVIDIA_GEFORCE_9600GT},
++    {"NV92",                        CARD_NVIDIA_GEFORCE_9800GT},
++    {"NV86",                        CARD_NVIDIA_GEFORCE_8500GT},
++    {"NV84",                        CARD_NVIDIA_GEFORCE_8600GT},
++    {"NV50",                        CARD_NVIDIA_GEFORCE_8800GTX},
++    /* Curie */
++    {"NV68",                        CARD_NVIDIA_GEFORCE_6200},      /* 7050 */
++    {"NV67",                        CARD_NVIDIA_GEFORCE_6200},      /* 7000M */
++    {"NV63",                        CARD_NVIDIA_GEFORCE_6200},      /* 7100 */
++    {"NV4E",                        CARD_NVIDIA_GEFORCE_6200},      /* 6100 Go / 6150 Go */
++    {"NV4C",                        CARD_NVIDIA_GEFORCE_6200},      /* 6150SE */
++    {"NV4B",                        CARD_NVIDIA_GEFORCE_7600},
++    {"NV4A",                        CARD_NVIDIA_GEFORCE_6200},
++    {"NV49",                        CARD_NVIDIA_GEFORCE_7800GT},    /* 7900 */
++    {"NV47",                        CARD_NVIDIA_GEFORCE_7800GT},
++    {"NV46",                        CARD_NVIDIA_GEFORCE_7400},
++    {"NV45",                        CARD_NVIDIA_GEFORCE_6800},
++    {"NV44",                        CARD_NVIDIA_GEFORCE_6200},
++    {"NV43",                        CARD_NVIDIA_GEFORCE_6600GT},
++    {"NV42",                        CARD_NVIDIA_GEFORCE_6800},
++    {"NV41",                        CARD_NVIDIA_GEFORCE_6800},
++    {"NV40",                        CARD_NVIDIA_GEFORCE_6800},
++    /* Rankine */
++    {"NV38",                        CARD_NVIDIA_GEFORCEFX_5800},    /* FX 5950 Ultra */
++    {"NV36",                        CARD_NVIDIA_GEFORCEFX_5800},    /* FX 5700/5750 */
++    {"NV35",                        CARD_NVIDIA_GEFORCEFX_5800},    /* FX 5900 */
++    {"NV34",                        CARD_NVIDIA_GEFORCEFX_5200},
++    {"NV31",                        CARD_NVIDIA_GEFORCEFX_5600},
++    {"NV30",                        CARD_NVIDIA_GEFORCEFX_5800},
++    /* Kelvin */
++    {"nv28",                        CARD_NVIDIA_GEFORCE4_TI4200},
++    {"nv25",                        CARD_NVIDIA_GEFORCE4_TI4200},
++    {"nv20",                        CARD_NVIDIA_GEFORCE3},
++    /* Celsius */
++    {"nv1F",                        CARD_NVIDIA_GEFORCE4_MX},       /* GF4 MX IGP */
++    {"nv1A",                        CARD_NVIDIA_GEFORCE2},          /* GF2 IGP */
++    {"nv18",                        CARD_NVIDIA_GEFORCE4_MX},
++    {"nv17",                        CARD_NVIDIA_GEFORCE4_MX},
++    {"nv16",                        CARD_NVIDIA_GEFORCE2},
++    {"nv15",                        CARD_NVIDIA_GEFORCE2},
++    {"nv11",                        CARD_NVIDIA_GEFORCE2_MX},
++    {"nv10",                        CARD_NVIDIA_GEFORCE},
++    /* Fahrenheit */
++    {"nv05",                        CARD_NVIDIA_RIVA_TNT2},
++    {"nv04",                        CARD_NVIDIA_RIVA_TNT},
++    {"nv03",                        CARD_NVIDIA_RIVA_128},
++},
++cards_vmware[] =
++{
++    {"SVGA3D",                      CARD_VMWARE_SVGA3D},
++};
++
++static const struct gl_vendor_selection
++{
++    enum wined3d_gl_vendor gl_vendor;
++    const char *description;        /* Description of the card selector i.e. Apple OS/X Intel */
++    const struct wined3d_renderer_table *cards; /* To be used as cards[], pointer to the first member in an array */
++    size_t cards_size;              /* Number of entries in the array above */
++}
++amd_gl_vendor_table[] =
++{
++    {GL_VENDOR_APPLE,   "Apple OSX AMD/ATI binary driver",  cards_amd_binary,       ARRAY_SIZE(cards_amd_binary)},
++    {GL_VENDOR_FGLRX,   "AMD/ATI binary driver",            cards_amd_binary,       ARRAY_SIZE(cards_amd_binary)},
++    {GL_VENDOR_MESA,    "Mesa AMD/ATI driver",              cards_amd_mesa,         ARRAY_SIZE(cards_amd_mesa)},
++},
++nvidia_gl_vendor_table[] =
++{
++    {GL_VENDOR_APPLE,   "Apple OSX NVidia binary driver",   cards_nvidia_binary,    ARRAY_SIZE(cards_nvidia_binary)},
++    {GL_VENDOR_MESA,    "Mesa Nouveau driver",              cards_nvidia_mesa,      ARRAY_SIZE(cards_nvidia_mesa)},
++    {GL_VENDOR_NVIDIA,  "Nvidia binary driver",             cards_nvidia_binary,    ARRAY_SIZE(cards_nvidia_binary)},
++},
++vmware_gl_vendor_table[] =
++{
++    {GL_VENDOR_MESA,    "VMware driver",                    cards_vmware,           ARRAY_SIZE(cards_vmware)},
++},
++intel_gl_vendor_table[] =
++{
++    {GL_VENDOR_APPLE,   "Apple OSX Intel binary driver",    cards_intel,            ARRAY_SIZE(cards_intel)},
++    {GL_VENDOR_MESA,    "Mesa Intel driver",                cards_intel,            ARRAY_SIZE(cards_intel)},
++};
++
++static const enum wined3d_pci_device
++card_fallback_nvidia[] =
++{
++    CARD_NVIDIA_RIVA_128,           /* D3D5 */
++    CARD_NVIDIA_RIVA_TNT,           /* D3D6 */
++    CARD_NVIDIA_GEFORCE,            /* D3D7 */
++    CARD_NVIDIA_GEFORCE3,           /* D3D8 */
++    CARD_NVIDIA_GEFORCEFX_5800,     /* D3D9_SM2 */
++    CARD_NVIDIA_GEFORCE_6800,       /* D3D9_SM3 */
++    CARD_NVIDIA_GEFORCE_8800GTX,    /* D3D10 */
++    CARD_NVIDIA_GEFORCE_GTX470,     /* D3D11 */
++},
++card_fallback_amd[] =
++{
++    CARD_AMD_RAGE_128PRO,           /* D3D5 */
++    CARD_AMD_RAGE_128PRO,           /* D3D6 */
++    CARD_AMD_RADEON_7200,           /* D3D7 */
++    CARD_AMD_RADEON_8500,           /* D3D8 */
++    CARD_AMD_RADEON_9500,           /* D3D9_SM2 */
++    CARD_AMD_RADEON_X1600,          /* D3D9_SM3 */
++    CARD_AMD_RADEON_HD2900,         /* D3D10 */
++    CARD_AMD_RADEON_HD5600,         /* D3D11 */
++},
++card_fallback_intel[] =
++{
++    CARD_INTEL_845G,                /* D3D5 */
++    CARD_INTEL_845G,                /* D3D6 */
++    CARD_INTEL_845G,                /* D3D7 */
++    CARD_INTEL_915G,                /* D3D8 */
++    CARD_INTEL_915G,                /* D3D9_SM2 */
++    CARD_INTEL_945G,                /* D3D9_SM3 */
++    CARD_INTEL_G45,                 /* D3D10 */
++    CARD_INTEL_IVBD,                /* D3D11 */
++};
++C_ASSERT(ARRAY_SIZE(card_fallback_nvidia)  == WINED3D_FEATURE_LEVEL_COUNT);
++C_ASSERT(ARRAY_SIZE(card_fallback_amd)     == WINED3D_FEATURE_LEVEL_COUNT);
++C_ASSERT(ARRAY_SIZE(card_fallback_intel)   == WINED3D_FEATURE_LEVEL_COUNT);
++
++static enum wined3d_pci_device select_card_handler(const struct gl_vendor_selection *table,
++        unsigned int table_size, enum wined3d_gl_vendor gl_vendor, const char *gl_renderer)
++{
++    unsigned int i, j;
++
++    for (i = 0; i < table_size; ++i)
++    {
++        if (table[i].gl_vendor != gl_vendor)
++            continue;
++
++        TRACE("Applying card selector \"%s\".\n", table[i].description);
++
++        for (j = 0; j < table[i].cards_size; ++j)
++        {
++            if (strstr(gl_renderer, table[i].cards[j].renderer))
++                return table[i].cards[j].id;
++        }
++        return PCI_DEVICE_NONE;
++    }
++    FIXME("Couldn't find a suitable card selector for GL vendor %04x (using GL_RENDERER %s)\n",
++            gl_vendor, debugstr_a(gl_renderer));
++
++    return PCI_DEVICE_NONE;
++}
++
++static const struct
++{
++    enum wined3d_pci_vendor card_vendor;
++    const char *description;        /* Description of the card selector i.e. Apple OS/X Intel */
++    const struct gl_vendor_selection *gl_vendor_selection;
++    unsigned int gl_vendor_count;
++    const enum wined3d_pci_device *card_fallback; /* An array with FEATURE_LEVEL_COUNT elements */
++}
++card_vendor_table[] =
++{
++    {HW_VENDOR_AMD,         "AMD",      amd_gl_vendor_table,
++            ARRAY_SIZE(amd_gl_vendor_table),
++            card_fallback_amd},
++    {HW_VENDOR_NVIDIA,      "Nvidia",   nvidia_gl_vendor_table,
++            ARRAY_SIZE(nvidia_gl_vendor_table),
++            card_fallback_nvidia},
++    {HW_VENDOR_VMWARE,      "VMware",   vmware_gl_vendor_table,
++            ARRAY_SIZE(vmware_gl_vendor_table),
++            card_fallback_amd},
++    {HW_VENDOR_INTEL,       "Intel",    intel_gl_vendor_table,
++            ARRAY_SIZE(intel_gl_vendor_table),
++            card_fallback_intel},
++};
++
++static enum wined3d_pci_device wined3d_guess_card(enum wined3d_feature_level feature_level,
++        DWORD glsl_version, const char *gl_renderer, enum wined3d_gl_vendor *gl_vendor,
++        enum wined3d_pci_vendor *card_vendor)
++{
++    /* A Direct3D device object contains the PCI id (vendor + device) of the
++     * videocard which is used for rendering. Various applications use this
++     * information to get a rough estimation of the features of the card and
++     * some might use it for enabling 3d effects only on certain types of
++     * videocards. In some cases games might even use it to work around bugs
++     * which happen on certain videocards/driver combinations. The problem is
++     * that OpenGL only exposes a rendering string containing the name of the
++     * videocard and not the PCI id.
++     *
++     * Various games depend on the PCI id, so somehow we need to provide one.
++     * A simple option is to parse the renderer string and translate this to
++     * the right PCI id. This is a lot of work because there are more than 200
++     * GPUs just for Nvidia. Various cards share the same renderer string, so
++     * the amount of code might be 'small' but there are quite a number of
++     * exceptions which would make this a pain to maintain. Another way would
++     * be to query the PCI id from the operating system (assuming this is the
++     * videocard which is used for rendering which is not always the case).
++     * This would work but it is not very portable. Second it would not work
++     * well in, let's say, a remote X situation in which the amount of 3d
++     * features which can be used is limited.
++     *
++     * As said most games only use the PCI id to get an indication of the
++     * capabilities of the card. It doesn't really matter if the given id is
++     * the correct one if we return the id of a card with similar 3d features.
++     *
++     * The code below checks the OpenGL capabilities of a videocard and matches
++     * that to a certain level of Direct3D functionality. Once a card passes
++     * the Direct3D9 check, we know that the card (in case of Nvidia) is at
++     * least a GeforceFX. To give a better estimate we do a basic check on the
++     * renderer string but if that won't pass we return a default card. This
++     * way is better than maintaining a full card database as even without a
++     * full database we can return a card with similar features. Second the
++     * size of the database can be made quite small because when you know what
++     * type of 3d functionality a card has, you know to which GPU family the
++     * GPU must belong. Because of this you only have to check a small part of
++     * the renderer string to distinguish between different models from that
++     * family.
++     *
++     * The code also selects a default amount of video memory which we will
++     * use for an estimation of the amount of free texture memory. In case of
++     * real D3D the amount of texture memory includes video memory and system
++     * memory (to be specific AGP memory or in case of PCIE TurboCache /
++     * HyperMemory). We don't know how much system memory can be addressed by
++     * the system but we can make a reasonable estimation about the amount of
++     * video memory. If the value is slightly wrong it doesn't matter as we
++     * didn't include AGP-like memory which makes the amount of addressable
++     * memory higher and second OpenGL isn't that critical it moves to system
++     * memory behind our backs if really needed. Note that the amount of video
++     * memory can be overruled using a registry setting. */
++
++    enum wined3d_pci_device device;
++    unsigned int i;
++
++    for (i = 0; i < ARRAY_SIZE(card_vendor_table); ++i)
++    {
++        if (card_vendor_table[i].card_vendor != *card_vendor)
++            continue;
++
++        TRACE("Applying card selector \"%s\".\n", card_vendor_table[i].description);
++        device = select_card_handler(card_vendor_table[i].gl_vendor_selection,
++                card_vendor_table[i].gl_vendor_count, *gl_vendor, gl_renderer);
++        if (device != PCI_DEVICE_NONE)
++            return device;
++
++        TRACE("Unrecognized renderer %s, falling back to default.\n", debugstr_a(gl_renderer));
++        return card_vendor_table[i].card_fallback[feature_level];
++    }
++
++    FIXME("No card selector available for card vendor %04x (using GL_RENDERER %s).\n",
++            *card_vendor, debugstr_a(gl_renderer));
++
++    /* Default to generic Nvidia hardware based on the supported OpenGL extensions. */
++    *card_vendor = HW_VENDOR_NVIDIA;
++    return card_fallback_nvidia[feature_level];
++}
++
++static const struct wined3d_vertex_pipe_ops *select_vertex_implementation(const struct wined3d_gl_info *gl_info,
++        const struct wined3d_shader_backend_ops *shader_backend_ops)
++{
++    if (shader_backend_ops == &glsl_shader_backend && gl_info->supported[ARB_VERTEX_SHADER])
++        return &glsl_vertex_pipe;
++    return &ffp_vertex_pipe;
++}
++
++static const struct fragment_pipeline *select_fragment_implementation(const struct wined3d_gl_info *gl_info,
++        const struct wined3d_shader_backend_ops *shader_backend_ops)
++{
++    if (shader_backend_ops == &glsl_shader_backend && gl_info->supported[ARB_FRAGMENT_SHADER])
++        return &glsl_fragment_pipe;
++    if (gl_info->supported[ARB_FRAGMENT_PROGRAM])
++        return &arbfp_fragment_pipeline;
++    if (gl_info->supported[ATI_FRAGMENT_SHADER])
++        return &atifs_fragment_pipeline;
++    if (gl_info->supported[NV_REGISTER_COMBINERS] && gl_info->supported[NV_TEXTURE_SHADER2])
++        return &nvts_fragment_pipeline;
++    if (gl_info->supported[NV_REGISTER_COMBINERS])
++        return &nvrc_fragment_pipeline;
++    return &ffp_fragment_pipeline;
++}
++
++static const struct wined3d_shader_backend_ops *select_shader_backend(const struct wined3d_gl_info *gl_info)
++{
++    BOOL glsl = wined3d_settings.use_glsl && gl_info->glsl_version >= MAKEDWORD_VERSION(1, 20);
++    if (!gl_info->supported[WINED3D_GL_LEGACY_CONTEXT] && !wined3d_settings.use_glsl)
++    {
++        ERR_(winediag)("Ignoring the UseGLSL registry key. "
++                "GLSL is the only shader backend available on core profile contexts. "
++                "You need to explicitly set GL version to use legacy contexts.\n");
++        glsl = TRUE;
++    }
++
++    if (glsl && gl_info->supported[ARB_VERTEX_SHADER] && gl_info->supported[ARB_FRAGMENT_SHADER])
++        return &glsl_shader_backend;
++    if (gl_info->supported[ARB_VERTEX_PROGRAM] && gl_info->supported[ARB_FRAGMENT_PROGRAM])
++        return &arb_program_shader_backend;
++    if (glsl && (gl_info->supported[ARB_VERTEX_SHADER] || gl_info->supported[ARB_FRAGMENT_SHADER]))
++        return &glsl_shader_backend;
++    if (gl_info->supported[ARB_VERTEX_PROGRAM] || gl_info->supported[ARB_FRAGMENT_PROGRAM])
++        return &arb_program_shader_backend;
++    return &none_shader_backend;
++}
++
++static void parse_extension_string(struct wined3d_gl_info *gl_info, const char *extensions,
++        const struct wined3d_extension_map *map, UINT entry_count)
++{
++    while (*extensions)
++    {
++        const char *start;
++        size_t len;
++        UINT i;
++
++        while (isspace(*extensions))
++            ++extensions;
++        start = extensions;
++        while (!isspace(*extensions) && *extensions)
++            ++extensions;
++
++        len = extensions - start;
++        if (!len)
++            continue;
++
++        TRACE("- %s.\n", debugstr_an(start, len));
++
++        for (i = 0; i < entry_count; ++i)
++        {
++            if (len == strlen(map[i].extension_string)
++                    && !memcmp(start, map[i].extension_string, len))
++            {
++                TRACE(" FOUND: %s support.\n", map[i].extension_string);
++                gl_info->supported[map[i].extension] = TRUE;
++                break;
++            }
++        }
++    }
++}
++
++static void enumerate_gl_extensions(struct wined3d_gl_info *gl_info,
++        const struct wined3d_extension_map *map, unsigned int map_entries_count)
++{
++    const char *gl_extension_name;
++    unsigned int i, j;
++    GLint extensions_count;
++
++    gl_info->gl_ops.gl.p_glGetIntegerv(GL_NUM_EXTENSIONS, &extensions_count);
++    for (i = 0; i < extensions_count; ++i)
++    {
++        gl_extension_name = (const char *)GL_EXTCALL(glGetStringi(GL_EXTENSIONS, i));
++        TRACE("- %s.\n", debugstr_a(gl_extension_name));
++        for (j = 0; j < map_entries_count; ++j)
++        {
++            if (!strcmp(gl_extension_name, map[j].extension_string))
++            {
++                TRACE("FOUND: %s support.\n", map[j].extension_string);
++                gl_info->supported[map[j].extension] = TRUE;
++                break;
++            }
++        }
++    }
++}
++
++static void load_gl_funcs(struct wined3d_gl_info *gl_info)
++{
++#define USE_GL_FUNC(pfn) gl_info->gl_ops.ext.p_##pfn = (void *)wglGetProcAddress(#pfn);
++    /* GL_APPLE_fence */
++    USE_GL_FUNC(glDeleteFencesAPPLE)
++    USE_GL_FUNC(glFinishFenceAPPLE)
++    USE_GL_FUNC(glFinishObjectAPPLE)
++    USE_GL_FUNC(glGenFencesAPPLE)
++    USE_GL_FUNC(glIsFenceAPPLE)
++    USE_GL_FUNC(glSetFenceAPPLE)
++    USE_GL_FUNC(glTestFenceAPPLE)
++    USE_GL_FUNC(glTestObjectAPPLE)
++    /* GL_APPLE_flush_buffer_range */
++    USE_GL_FUNC(glBufferParameteriAPPLE)
++    USE_GL_FUNC(glFlushMappedBufferRangeAPPLE)
++    /* GL_ARB_base_instance */
++    USE_GL_FUNC(glDrawArraysInstancedBaseInstance)
++    USE_GL_FUNC(glDrawElementsInstancedBaseVertexBaseInstance)
++    /* GL_ARB_blend_func_extended */
++    USE_GL_FUNC(glBindFragDataLocationIndexed)
++    USE_GL_FUNC(glGetFragDataIndex)
++    /* GL_ARB_buffer_storage */
++    USE_GL_FUNC(glBufferStorage)
++    /* GL_ARB_clear_buffer_object */
++    USE_GL_FUNC(glClearBufferData)
++    USE_GL_FUNC(glClearBufferSubData)
++    /* GL_ARB_clear_texture */
++    USE_GL_FUNC(glClearTexImage)
++    USE_GL_FUNC(glClearTexSubImage)
++    /* GL_ARB_clip_control */
++    USE_GL_FUNC(glClipControl)
++    /* GL_ARB_color_buffer_float */
++    USE_GL_FUNC(glClampColorARB)
++    /* GL_ARB_compute_shader */
++    USE_GL_FUNC(glDispatchCompute)
++    USE_GL_FUNC(glDispatchComputeIndirect)
++    /* GL_ARB_copy_buffer */
++    USE_GL_FUNC(glCopyBufferSubData)
++    /* GL_ARB_copy_image */
++    USE_GL_FUNC(glCopyImageSubData)
++    /* GL_ARB_debug_output */
++    USE_GL_FUNC(glDebugMessageCallbackARB)
++    USE_GL_FUNC(glDebugMessageControlARB)
++    USE_GL_FUNC(glDebugMessageInsertARB)
++    USE_GL_FUNC(glGetDebugMessageLogARB)
++    /* GL_ARB_draw_buffers */
++    USE_GL_FUNC(glDrawBuffersARB)
++    /* GL_ARB_draw_elements_base_vertex */
++    USE_GL_FUNC(glDrawElementsBaseVertex)
++    USE_GL_FUNC(glDrawElementsInstancedBaseVertex)
++    USE_GL_FUNC(glDrawRangeElementsBaseVertex)
++    USE_GL_FUNC(glMultiDrawElementsBaseVertex)
++    /* GL_ARB_draw_indirect */
++    USE_GL_FUNC(glDrawArraysIndirect)
++    USE_GL_FUNC(glDrawElementsIndirect)
++    /* GL_ARB_draw_instanced */
++    USE_GL_FUNC(glDrawArraysInstancedARB)
++    USE_GL_FUNC(glDrawElementsInstancedARB)
++    /* GL_ARB_ES2_compatibility */
++    USE_GL_FUNC(glReleaseShaderCompiler)
++    USE_GL_FUNC(glShaderBinary)
++    USE_GL_FUNC(glGetShaderPrecisionFormat)
++    USE_GL_FUNC(glDepthRangef)
++    USE_GL_FUNC(glClearDepthf)
++    /* GL_ARB_framebuffer_no_attachments */
++    USE_GL_FUNC(glFramebufferParameteri)
++    /* GL_ARB_framebuffer_object */
++    USE_GL_FUNC(glBindFramebuffer)
++    USE_GL_FUNC(glBindRenderbuffer)
++    USE_GL_FUNC(glBlitFramebuffer)
++    USE_GL_FUNC(glCheckFramebufferStatus)
++    USE_GL_FUNC(glDeleteFramebuffers)
++    USE_GL_FUNC(glDeleteRenderbuffers)
++    USE_GL_FUNC(glFramebufferRenderbuffer)
++    USE_GL_FUNC(glFramebufferTexture)
++    USE_GL_FUNC(glFramebufferTexture1D)
++    USE_GL_FUNC(glFramebufferTexture2D)
++    USE_GL_FUNC(glFramebufferTexture3D)
++    USE_GL_FUNC(glFramebufferTextureLayer)
++    USE_GL_FUNC(glGenFramebuffers)
++    USE_GL_FUNC(glGenRenderbuffers)
++    USE_GL_FUNC(glGenerateMipmap)
++    USE_GL_FUNC(glGetFramebufferAttachmentParameteriv)
++    USE_GL_FUNC(glGetRenderbufferParameteriv)
++    USE_GL_FUNC(glIsFramebuffer)
++    USE_GL_FUNC(glIsRenderbuffer)
++    USE_GL_FUNC(glRenderbufferStorage)
++    USE_GL_FUNC(glRenderbufferStorageMultisample)
++    /* GL_ARB_geometry_shader4 */
++    USE_GL_FUNC(glFramebufferTextureARB)
++    USE_GL_FUNC(glFramebufferTextureFaceARB)
++    USE_GL_FUNC(glFramebufferTextureLayerARB)
++    USE_GL_FUNC(glProgramParameteriARB)
++    /* GL_ARB_instanced_arrays */
++    USE_GL_FUNC(glVertexAttribDivisorARB)
++    /* GL_ARB_internalformat_query */
++    USE_GL_FUNC(glGetInternalformativ)
++    /* GL_ARB_internalformat_query2 */
++    USE_GL_FUNC(glGetInternalformati64v)
++    /* GL_ARB_map_buffer_range */
++    USE_GL_FUNC(glFlushMappedBufferRange)
++    USE_GL_FUNC(glMapBufferRange)
++    /* GL_ARB_multisample */
++    USE_GL_FUNC(glSampleCoverageARB)
++    /* GL_ARB_multitexture */
++    USE_GL_FUNC(glActiveTextureARB)
++    USE_GL_FUNC(glClientActiveTextureARB)
++    USE_GL_FUNC(glMultiTexCoord1fARB)
++    USE_GL_FUNC(glMultiTexCoord1fvARB)
++    USE_GL_FUNC(glMultiTexCoord2fARB)
++    USE_GL_FUNC(glMultiTexCoord2fvARB)
++    USE_GL_FUNC(glMultiTexCoord2svARB)
++    USE_GL_FUNC(glMultiTexCoord3fARB)
++    USE_GL_FUNC(glMultiTexCoord3fvARB)
++    USE_GL_FUNC(glMultiTexCoord4fARB)
++    USE_GL_FUNC(glMultiTexCoord4fvARB)
++    USE_GL_FUNC(glMultiTexCoord4svARB)
++    /* GL_ARB_occlusion_query */
++    USE_GL_FUNC(glBeginQueryARB)
++    USE_GL_FUNC(glDeleteQueriesARB)
++    USE_GL_FUNC(glEndQueryARB)
++    USE_GL_FUNC(glGenQueriesARB)
++    USE_GL_FUNC(glGetQueryivARB)
++    USE_GL_FUNC(glGetQueryObjectivARB)
++    USE_GL_FUNC(glGetQueryObjectuivARB)
++    USE_GL_FUNC(glIsQueryARB)
++    /* GL_ARB_point_parameters */
++    USE_GL_FUNC(glPointParameterfARB)
++    USE_GL_FUNC(glPointParameterfvARB)
++    /* GL_ARB_provoking_vertex */
++    USE_GL_FUNC(glProvokingVertex)
++    /* GL_ARB_sample_shading */
++    USE_GL_FUNC(glMinSampleShadingARB)
++    /* GL_ARB_sampler_objects */
++    USE_GL_FUNC(glGenSamplers)
++    USE_GL_FUNC(glDeleteSamplers)
++    USE_GL_FUNC(glIsSampler)
++    USE_GL_FUNC(glBindSampler)
++    USE_GL_FUNC(glSamplerParameteri)
++    USE_GL_FUNC(glSamplerParameterf)
++    USE_GL_FUNC(glSamplerParameteriv)
++    USE_GL_FUNC(glSamplerParameterfv)
++    USE_GL_FUNC(glSamplerParameterIiv)
++    USE_GL_FUNC(glSamplerParameterIuiv)
++    USE_GL_FUNC(glGetSamplerParameteriv)
++    USE_GL_FUNC(glGetSamplerParameterfv)
++    USE_GL_FUNC(glGetSamplerParameterIiv)
++    USE_GL_FUNC(glGetSamplerParameterIuiv)
++    /* GL_ARB_shader_atomic_counters */
++    USE_GL_FUNC(glGetActiveAtomicCounterBufferiv)
++    /* GL_ARB_shader_image_load_store */
++    USE_GL_FUNC(glBindImageTexture)
++    USE_GL_FUNC(glMemoryBarrier)
++    /* GL_ARB_shader_objects */
++    USE_GL_FUNC(glAttachObjectARB)
++    USE_GL_FUNC(glBindAttribLocationARB)
++    USE_GL_FUNC(glCompileShaderARB)
++    USE_GL_FUNC(glCreateProgramObjectARB)
++    USE_GL_FUNC(glCreateShaderObjectARB)
++    USE_GL_FUNC(glDeleteObjectARB)
++    USE_GL_FUNC(glDetachObjectARB)
++    USE_GL_FUNC(glGetActiveUniformARB)
++    USE_GL_FUNC(glGetAttachedObjectsARB)
++    USE_GL_FUNC(glGetAttribLocationARB)
++    USE_GL_FUNC(glGetHandleARB)
++    USE_GL_FUNC(glGetInfoLogARB)
++    USE_GL_FUNC(glGetObjectParameterfvARB)
++    USE_GL_FUNC(glGetObjectParameterivARB)
++    USE_GL_FUNC(glGetShaderSourceARB)
++    USE_GL_FUNC(glGetUniformLocationARB)
++    USE_GL_FUNC(glGetUniformfvARB)
++    USE_GL_FUNC(glGetUniformivARB)
++    USE_GL_FUNC(glLinkProgramARB)
++    USE_GL_FUNC(glShaderSourceARB)
++    USE_GL_FUNC(glUniform1fARB)
++    USE_GL_FUNC(glUniform1fvARB)
++    USE_GL_FUNC(glUniform1iARB)
++    USE_GL_FUNC(glUniform1ivARB)
++    USE_GL_FUNC(glUniform2fARB)
++    USE_GL_FUNC(glUniform2fvARB)
++    USE_GL_FUNC(glUniform2iARB)
++    USE_GL_FUNC(glUniform2ivARB)
++    USE_GL_FUNC(glUniform3fARB)
++    USE_GL_FUNC(glUniform3fvARB)
++    USE_GL_FUNC(glUniform3iARB)
++    USE_GL_FUNC(glUniform3ivARB)
++    USE_GL_FUNC(glUniform4fARB)
++    USE_GL_FUNC(glUniform4fvARB)
++    USE_GL_FUNC(glUniform4iARB)
++    USE_GL_FUNC(glUniform4ivARB)
++    USE_GL_FUNC(glUniformMatrix2fvARB)
++    USE_GL_FUNC(glUniformMatrix3fvARB)
++    USE_GL_FUNC(glUniformMatrix4fvARB)
++    USE_GL_FUNC(glUseProgramObjectARB)
++    USE_GL_FUNC(glValidateProgramARB)
++    /* GL_ARB_shader_storage_buffer_object */
++    USE_GL_FUNC(glShaderStorageBlockBinding)
++    /* GL_ARB_sync */
++    USE_GL_FUNC(glClientWaitSync)
++    USE_GL_FUNC(glDeleteSync)
++    USE_GL_FUNC(glFenceSync)
++    USE_GL_FUNC(glGetInteger64v)
++    USE_GL_FUNC(glGetSynciv)
++    USE_GL_FUNC(glIsSync)
++    USE_GL_FUNC(glWaitSync)
++    /* GL_ARB_tessellation_shader */
++    USE_GL_FUNC(glPatchParameteri)
++    USE_GL_FUNC(glPatchParameterfv)
++    /* GL_ARB_texture_buffer_object */
++    USE_GL_FUNC(glTexBufferARB)
++    /* GL_ARB_texture_buffer_range */
++    USE_GL_FUNC(glTexBufferRange)
++    /* GL_ARB_texture_compression */
++    USE_GL_FUNC(glCompressedTexImage2DARB)
++    USE_GL_FUNC(glCompressedTexImage3DARB)
++    USE_GL_FUNC(glCompressedTexSubImage2DARB)
++    USE_GL_FUNC(glCompressedTexSubImage3DARB)
++    USE_GL_FUNC(glGetCompressedTexImageARB)
++    /* GL_ARB_texture_multisample */
++    USE_GL_FUNC(glGetMultisamplefv);
++    USE_GL_FUNC(glSampleMaski);
++    USE_GL_FUNC(glTexImage2DMultisample);
++    USE_GL_FUNC(glTexImage3DMultisample);
++    /* GL_ARB_texture_storage */
++    USE_GL_FUNC(glTexStorage1D)
++    USE_GL_FUNC(glTexStorage2D)
++    USE_GL_FUNC(glTexStorage3D)
++    /* GL_ARB_texture_storage_multisample */
++    USE_GL_FUNC(glTexStorage2DMultisample);
++    USE_GL_FUNC(glTexStorage3DMultisample);
++    /* GL_ARB_texture_view */
++    USE_GL_FUNC(glTextureView)
++    /* GL_ARB_timer_query */
++    USE_GL_FUNC(glQueryCounter)
++    USE_GL_FUNC(glGetQueryObjectui64v)
++    /* GL_ARB_transform_feedback2 */
++    USE_GL_FUNC(glBindTransformFeedback);
++    USE_GL_FUNC(glDeleteTransformFeedbacks);
++    USE_GL_FUNC(glDrawTransformFeedback);
++    USE_GL_FUNC(glGenTransformFeedbacks);
++    USE_GL_FUNC(glIsTransformFeedback);
++    USE_GL_FUNC(glPauseTransformFeedback);
++    USE_GL_FUNC(glResumeTransformFeedback);
++    /* GL_ARB_transform_feedback3 */
++    USE_GL_FUNC(glBeginQueryIndexed);
++    USE_GL_FUNC(glDrawTransformFeedbackStream);
++    USE_GL_FUNC(glEndQueryIndexed);
++    USE_GL_FUNC(glGetQueryIndexediv);
++    /* GL_ARB_uniform_buffer_object */
++    USE_GL_FUNC(glBindBufferBase)
++    USE_GL_FUNC(glBindBufferRange)
++    USE_GL_FUNC(glGetActiveUniformBlockName)
++    USE_GL_FUNC(glGetActiveUniformBlockiv)
++    USE_GL_FUNC(glGetActiveUniformName)
++    USE_GL_FUNC(glGetActiveUniformsiv)
++    USE_GL_FUNC(glGetIntegeri_v)
++    USE_GL_FUNC(glGetUniformBlockIndex)
++    USE_GL_FUNC(glGetUniformIndices)
++    USE_GL_FUNC(glUniformBlockBinding)
++    /* GL_ARB_vertex_buffer_object */
++    USE_GL_FUNC(glBindBufferARB)
++    USE_GL_FUNC(glBufferDataARB)
++    USE_GL_FUNC(glBufferSubDataARB)
++    USE_GL_FUNC(glDeleteBuffersARB)
++    USE_GL_FUNC(glGenBuffersARB)
++    USE_GL_FUNC(glGetBufferParameterivARB)
++    USE_GL_FUNC(glGetBufferPointervARB)
++    USE_GL_FUNC(glGetBufferSubDataARB)
++    USE_GL_FUNC(glIsBufferARB)
++    USE_GL_FUNC(glMapBufferARB)
++    USE_GL_FUNC(glUnmapBufferARB)
++    /* GL_ARB_vertex_program */
++    USE_GL_FUNC(glBindProgramARB)
++    USE_GL_FUNC(glDeleteProgramsARB)
++    USE_GL_FUNC(glDisableVertexAttribArrayARB)
++    USE_GL_FUNC(glEnableVertexAttribArrayARB)
++    USE_GL_FUNC(glGenProgramsARB)
++    USE_GL_FUNC(glGetProgramivARB)
++    USE_GL_FUNC(glProgramEnvParameter4fvARB)
++    USE_GL_FUNC(glProgramLocalParameter4fvARB)
++    USE_GL_FUNC(glProgramStringARB)
++    USE_GL_FUNC(glVertexAttrib1dARB)
++    USE_GL_FUNC(glVertexAttrib1dvARB)
++    USE_GL_FUNC(glVertexAttrib1fARB)
++    USE_GL_FUNC(glVertexAttrib1fvARB)
++    USE_GL_FUNC(glVertexAttrib1sARB)
++    USE_GL_FUNC(glVertexAttrib1svARB)
++    USE_GL_FUNC(glVertexAttrib2dARB)
++    USE_GL_FUNC(glVertexAttrib2dvARB)
++    USE_GL_FUNC(glVertexAttrib2fARB)
++    USE_GL_FUNC(glVertexAttrib2fvARB)
++    USE_GL_FUNC(glVertexAttrib2sARB)
++    USE_GL_FUNC(glVertexAttrib2svARB)
++    USE_GL_FUNC(glVertexAttrib3dARB)
++    USE_GL_FUNC(glVertexAttrib3dvARB)
++    USE_GL_FUNC(glVertexAttrib3fARB)
++    USE_GL_FUNC(glVertexAttrib3fvARB)
++    USE_GL_FUNC(glVertexAttrib3sARB)
++    USE_GL_FUNC(glVertexAttrib3svARB)
++    USE_GL_FUNC(glVertexAttrib4NbvARB)
++    USE_GL_FUNC(glVertexAttrib4NivARB)
++    USE_GL_FUNC(glVertexAttrib4NsvARB)
++    USE_GL_FUNC(glVertexAttrib4NubARB)
++    USE_GL_FUNC(glVertexAttrib4NubvARB)
++    USE_GL_FUNC(glVertexAttrib4NuivARB)
++    USE_GL_FUNC(glVertexAttrib4NusvARB)
++    USE_GL_FUNC(glVertexAttrib4bvARB)
++    USE_GL_FUNC(glVertexAttrib4dARB)
++    USE_GL_FUNC(glVertexAttrib4dvARB)
++    USE_GL_FUNC(glVertexAttrib4fARB)
++    USE_GL_FUNC(glVertexAttrib4fvARB)
++    USE_GL_FUNC(glVertexAttrib4ivARB)
++    USE_GL_FUNC(glVertexAttrib4sARB)
++    USE_GL_FUNC(glVertexAttrib4svARB)
++    USE_GL_FUNC(glVertexAttrib4ubvARB)
++    USE_GL_FUNC(glVertexAttrib4uivARB)
++    USE_GL_FUNC(glVertexAttrib4usvARB)
++    USE_GL_FUNC(glVertexAttribPointerARB)
++    /* GL_ARB_viewport_array */
++    USE_GL_FUNC(glDepthRangeArrayv)
++    USE_GL_FUNC(glDepthRangeIndexed)
++    USE_GL_FUNC(glGetDoublei_v)
++    USE_GL_FUNC(glGetFloati_v)
++    USE_GL_FUNC(glScissorArrayv)
++    USE_GL_FUNC(glScissorIndexed)
++    USE_GL_FUNC(glScissorIndexedv)
++    USE_GL_FUNC(glViewportArrayv)
++    USE_GL_FUNC(glViewportIndexedf)
++    USE_GL_FUNC(glViewportIndexedfv)
++    /* GL_ATI_fragment_shader */
++    USE_GL_FUNC(glAlphaFragmentOp1ATI)
++    USE_GL_FUNC(glAlphaFragmentOp2ATI)
++    USE_GL_FUNC(glAlphaFragmentOp3ATI)
++    USE_GL_FUNC(glBeginFragmentShaderATI)
++    USE_GL_FUNC(glBindFragmentShaderATI)
++    USE_GL_FUNC(glColorFragmentOp1ATI)
++    USE_GL_FUNC(glColorFragmentOp2ATI)
++    USE_GL_FUNC(glColorFragmentOp3ATI)
++    USE_GL_FUNC(glDeleteFragmentShaderATI)
++    USE_GL_FUNC(glEndFragmentShaderATI)
++    USE_GL_FUNC(glGenFragmentShadersATI)
++    USE_GL_FUNC(glPassTexCoordATI)
++    USE_GL_FUNC(glSampleMapATI)
++    USE_GL_FUNC(glSetFragmentShaderConstantATI)
++    /* GL_ATI_separate_stencil */
++    USE_GL_FUNC(glStencilOpSeparateATI)
++    USE_GL_FUNC(glStencilFuncSeparateATI)
++    /* GL_EXT_blend_color */
++    USE_GL_FUNC(glBlendColorEXT)
++    /* GL_EXT_blend_equation_separate */
++    USE_GL_FUNC(glBlendFuncSeparateEXT)
++    /* GL_EXT_blend_func_separate */
++    USE_GL_FUNC(glBlendEquationSeparateEXT)
++    /* GL_EXT_blend_minmax */
++    USE_GL_FUNC(glBlendEquationEXT)
++    /* GL_EXT_depth_bounds_test */
++    USE_GL_FUNC(glDepthBoundsEXT)
++    /* GL_EXT_draw_buffers2 */
++    USE_GL_FUNC(glColorMaskIndexedEXT)
++    USE_GL_FUNC(glDisableIndexedEXT)
++    USE_GL_FUNC(glEnableIndexedEXT)
++    USE_GL_FUNC(glGetBooleanIndexedvEXT)
++    USE_GL_FUNC(glGetIntegerIndexedvEXT)
++    USE_GL_FUNC(glIsEnabledIndexedEXT)
++    /* GL_EXT_fog_coord */
++    USE_GL_FUNC(glFogCoordPointerEXT)
++    USE_GL_FUNC(glFogCoorddEXT)
++    USE_GL_FUNC(glFogCoorddvEXT)
++    USE_GL_FUNC(glFogCoordfEXT)
++    USE_GL_FUNC(glFogCoordfvEXT)
++    /* GL_EXT_framebuffer_blit */
++    USE_GL_FUNC(glBlitFramebufferEXT)
++    /* GL_EXT_framebuffer_multisample */
++    USE_GL_FUNC(glRenderbufferStorageMultisampleEXT)
++    /* GL_EXT_framebuffer_object */
++    USE_GL_FUNC(glBindFramebufferEXT)
++    USE_GL_FUNC(glBindRenderbufferEXT)
++    USE_GL_FUNC(glCheckFramebufferStatusEXT)
++    USE_GL_FUNC(glDeleteFramebuffersEXT)
++    USE_GL_FUNC(glDeleteRenderbuffersEXT)
++    USE_GL_FUNC(glFramebufferRenderbufferEXT)
++    USE_GL_FUNC(glFramebufferTexture1DEXT)
++    USE_GL_FUNC(glFramebufferTexture2DEXT)
++    USE_GL_FUNC(glFramebufferTexture3DEXT)
++    USE_GL_FUNC(glGenFramebuffersEXT)
++    USE_GL_FUNC(glGenRenderbuffersEXT)
++    USE_GL_FUNC(glGenerateMipmapEXT)
++    USE_GL_FUNC(glGetFramebufferAttachmentParameterivEXT)
++    USE_GL_FUNC(glGetRenderbufferParameterivEXT)
++    USE_GL_FUNC(glIsFramebufferEXT)
++    USE_GL_FUNC(glIsRenderbufferEXT)
++    USE_GL_FUNC(glRenderbufferStorageEXT)
++    /* GL_EXT_gpu_program_parameters */
++    USE_GL_FUNC(glProgramEnvParameters4fvEXT)
++    USE_GL_FUNC(glProgramLocalParameters4fvEXT)
++    /* GL_EXT_gpu_shader4 */
++    USE_GL_FUNC(glBindFragDataLocationEXT)
++    USE_GL_FUNC(glGetFragDataLocationEXT)
++    USE_GL_FUNC(glGetUniformuivEXT)
++    USE_GL_FUNC(glGetVertexAttribIivEXT)
++    USE_GL_FUNC(glGetVertexAttribIuivEXT)
++    USE_GL_FUNC(glUniform1uiEXT)
++    USE_GL_FUNC(glUniform1uivEXT)
++    USE_GL_FUNC(glUniform2uiEXT)
++    USE_GL_FUNC(glUniform2uivEXT)
++    USE_GL_FUNC(glUniform3uiEXT)
++    USE_GL_FUNC(glUniform3uivEXT)
++    USE_GL_FUNC(glUniform4uiEXT)
++    USE_GL_FUNC(glUniform4uivEXT)
++    USE_GL_FUNC(glVertexAttribI1iEXT)
++    USE_GL_FUNC(glVertexAttribI1ivEXT)
++    USE_GL_FUNC(glVertexAttribI1uiEXT)
++    USE_GL_FUNC(glVertexAttribI1uivEXT)
++    USE_GL_FUNC(glVertexAttribI2iEXT)
++    USE_GL_FUNC(glVertexAttribI2ivEXT)
++    USE_GL_FUNC(glVertexAttribI2uiEXT)
++    USE_GL_FUNC(glVertexAttribI2uivEXT)
++    USE_GL_FUNC(glVertexAttribI3iEXT)
++    USE_GL_FUNC(glVertexAttribI3ivEXT)
++    USE_GL_FUNC(glVertexAttribI3uiEXT)
++    USE_GL_FUNC(glVertexAttribI3uivEXT)
++    USE_GL_FUNC(glVertexAttribI4bvEXT)
++    USE_GL_FUNC(glVertexAttribI4iEXT)
++    USE_GL_FUNC(glVertexAttribI4ivEXT)
++    USE_GL_FUNC(glVertexAttribI4svEXT)
++    USE_GL_FUNC(glVertexAttribI4ubvEXT)
++    USE_GL_FUNC(glVertexAttribI4uiEXT)
++    USE_GL_FUNC(glVertexAttribI4uivEXT)
++    USE_GL_FUNC(glVertexAttribI4usvEXT)
++    USE_GL_FUNC(glVertexAttribIPointerEXT)
++    /* GL_EXT_point_parameters */
++    USE_GL_FUNC(glPointParameterfEXT)
++    USE_GL_FUNC(glPointParameterfvEXT)
++    /* GL_EXT_provoking_vertex */
++    USE_GL_FUNC(glProvokingVertexEXT)
++    /* GL_EXT_secondary_color */
++    USE_GL_FUNC(glSecondaryColor3fEXT)
++    USE_GL_FUNC(glSecondaryColor3fvEXT)
++    USE_GL_FUNC(glSecondaryColor3ubEXT)
++    USE_GL_FUNC(glSecondaryColor3ubvEXT)
++    USE_GL_FUNC(glSecondaryColorPointerEXT)
++    /* GL_EXT_stencil_two_side */
++    USE_GL_FUNC(glActiveStencilFaceEXT)
++    /* GL_EXT_texture3D */
++    USE_GL_FUNC(glTexImage3D)
++    USE_GL_FUNC(glTexImage3DEXT)
++    USE_GL_FUNC(glTexSubImage3D)
++    USE_GL_FUNC(glTexSubImage3DEXT)
++    /* GL_NV_fence */
++    USE_GL_FUNC(glDeleteFencesNV)
++    USE_GL_FUNC(glFinishFenceNV)
++    USE_GL_FUNC(glGenFencesNV)
++    USE_GL_FUNC(glGetFenceivNV)
++    USE_GL_FUNC(glIsFenceNV)
++    USE_GL_FUNC(glSetFenceNV)
++    USE_GL_FUNC(glTestFenceNV)
++    /* GL_NV_half_float */
++    USE_GL_FUNC(glColor3hNV)
++    USE_GL_FUNC(glColor3hvNV)
++    USE_GL_FUNC(glColor4hNV)
++    USE_GL_FUNC(glColor4hvNV)
++    USE_GL_FUNC(glFogCoordhNV)
++    USE_GL_FUNC(glFogCoordhvNV)
++    USE_GL_FUNC(glMultiTexCoord1hNV)
++    USE_GL_FUNC(glMultiTexCoord1hvNV)
++    USE_GL_FUNC(glMultiTexCoord2hNV)
++    USE_GL_FUNC(glMultiTexCoord2hvNV)
++    USE_GL_FUNC(glMultiTexCoord3hNV)
++    USE_GL_FUNC(glMultiTexCoord3hvNV)
++    USE_GL_FUNC(glMultiTexCoord4hNV)
++    USE_GL_FUNC(glMultiTexCoord4hvNV)
++    USE_GL_FUNC(glNormal3hNV)
++    USE_GL_FUNC(glNormal3hvNV)
++    USE_GL_FUNC(glSecondaryColor3hNV)
++    USE_GL_FUNC(glSecondaryColor3hvNV)
++    USE_GL_FUNC(glTexCoord1hNV)
++    USE_GL_FUNC(glTexCoord1hvNV)
++    USE_GL_FUNC(glTexCoord2hNV)
++    USE_GL_FUNC(glTexCoord2hvNV)
++    USE_GL_FUNC(glTexCoord3hNV)
++    USE_GL_FUNC(glTexCoord3hvNV)
++    USE_GL_FUNC(glTexCoord4hNV)
++    USE_GL_FUNC(glTexCoord4hvNV)
++    USE_GL_FUNC(glVertex2hNV)
++    USE_GL_FUNC(glVertex2hvNV)
++    USE_GL_FUNC(glVertex3hNV)
++    USE_GL_FUNC(glVertex3hvNV)
++    USE_GL_FUNC(glVertex4hNV)
++    USE_GL_FUNC(glVertex4hvNV)
++    USE_GL_FUNC(glVertexAttrib1hNV)
++    USE_GL_FUNC(glVertexAttrib1hvNV)
++    USE_GL_FUNC(glVertexAttrib2hNV)
++    USE_GL_FUNC(glVertexAttrib2hvNV)
++    USE_GL_FUNC(glVertexAttrib3hNV)
++    USE_GL_FUNC(glVertexAttrib3hvNV)
++    USE_GL_FUNC(glVertexAttrib4hNV)
++    USE_GL_FUNC(glVertexAttrib4hvNV)
++    USE_GL_FUNC(glVertexAttribs1hvNV)
++    USE_GL_FUNC(glVertexAttribs2hvNV)
++    USE_GL_FUNC(glVertexAttribs3hvNV)
++    USE_GL_FUNC(glVertexAttribs4hvNV)
++    USE_GL_FUNC(glVertexWeighthNV)
++    USE_GL_FUNC(glVertexWeighthvNV)
++    /* GL_NV_point_sprite */
++    USE_GL_FUNC(glPointParameteriNV)
++    USE_GL_FUNC(glPointParameterivNV)
++    /* GL_NV_register_combiners */
++    USE_GL_FUNC(glCombinerInputNV)
++    USE_GL_FUNC(glCombinerOutputNV)
++    USE_GL_FUNC(glCombinerParameterfNV)
++    USE_GL_FUNC(glCombinerParameterfvNV)
++    USE_GL_FUNC(glCombinerParameteriNV)
++    USE_GL_FUNC(glCombinerParameterivNV)
++    USE_GL_FUNC(glFinalCombinerInputNV)
++    /* WGL extensions */
++    USE_GL_FUNC(wglChoosePixelFormatARB)
++    USE_GL_FUNC(wglGetExtensionsStringARB)
++    USE_GL_FUNC(wglGetPixelFormatAttribfvARB)
++    USE_GL_FUNC(wglGetPixelFormatAttribivARB)
++    USE_GL_FUNC(wglQueryCurrentRendererIntegerWINE)
++    USE_GL_FUNC(wglQueryCurrentRendererStringWINE)
++    USE_GL_FUNC(wglQueryRendererIntegerWINE)
++    USE_GL_FUNC(wglQueryRendererStringWINE)
++    USE_GL_FUNC(wglSetPixelFormatWINE)
++    USE_GL_FUNC(wglSwapIntervalEXT)
++
++    /* Newer core functions */
++    USE_GL_FUNC(glActiveTexture)                               /* OpenGL 1.3 */
++    USE_GL_FUNC(glAttachShader)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glBeginQuery)                                  /* OpenGL 1.5 */
++    USE_GL_FUNC(glBeginTransformFeedback)                      /* OpenGL 3.0 */
++    USE_GL_FUNC(glBindAttribLocation)                          /* OpenGL 2.0 */
++    USE_GL_FUNC(glBindBuffer)                                  /* OpenGL 1.5 */
++    USE_GL_FUNC(glBindFragDataLocation)                        /* OpenGL 3.0 */
++    USE_GL_FUNC(glBindVertexArray)                             /* OpenGL 3.0 */
++    USE_GL_FUNC(glBlendColor)                                  /* OpenGL 1.4 */
++    USE_GL_FUNC(glBlendEquation)                               /* OpenGL 1.4 */
++    USE_GL_FUNC(glBlendEquationSeparate)                       /* OpenGL 2.0 */
++    USE_GL_FUNC(glBlendFuncSeparate)                           /* OpenGL 1.4 */
++    USE_GL_FUNC(glBufferData)                                  /* OpenGL 1.5 */
++    USE_GL_FUNC(glBufferSubData)                               /* OpenGL 1.5 */
++    USE_GL_FUNC(glColorMaski)                                  /* OpenGL 3.0 */
++    USE_GL_FUNC(glCompileShader)                               /* OpenGL 2.0 */
++    USE_GL_FUNC(glCompressedTexImage2D)                        /* OpenGL 1.3 */
++    USE_GL_FUNC(glCompressedTexImage3D)                        /* OpenGL 1.3 */
++    USE_GL_FUNC(glCompressedTexSubImage2D)                     /* OpenGL 1.3 */
++    USE_GL_FUNC(glCompressedTexSubImage3D)                     /* OpenGL 1.3 */
++    USE_GL_FUNC(glCreateProgram)                               /* OpenGL 2.0 */
++    USE_GL_FUNC(glCreateShader)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glDebugMessageCallback)                        /* OpenGL 4.3 */
++    USE_GL_FUNC(glDebugMessageControl)                         /* OpenGL 4.3 */
++    USE_GL_FUNC(glDebugMessageInsert)                          /* OpenGL 4.3 */
++    USE_GL_FUNC(glDeleteBuffers)                               /* OpenGL 1.5 */
++    USE_GL_FUNC(glDeleteProgram)                               /* OpenGL 2.0 */
++    USE_GL_FUNC(glDeleteQueries)                               /* OpenGL 1.5 */
++    USE_GL_FUNC(glDeleteShader)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glDeleteVertexArrays)                          /* OpenGL 3.0 */
++    USE_GL_FUNC(glDetachShader)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glDisablei)                                    /* OpenGL 3.0 */
++    USE_GL_FUNC(glDisableVertexAttribArray)                    /* OpenGL 2.0 */
++    USE_GL_FUNC(glDrawArraysInstanced)                         /* OpenGL 3.1 */
++    USE_GL_FUNC(glDrawBuffers)                                 /* OpenGL 2.0 */
++    USE_GL_FUNC(glDrawElementsInstanced)                       /* OpenGL 3.1 */
++    USE_GL_FUNC(glEnablei)                                     /* OpenGL 3.0 */
++    USE_GL_FUNC(glEnableVertexAttribArray)                     /* OpenGL 2.0 */
++    USE_GL_FUNC(glEndQuery)                                    /* OpenGL 1.5 */
++    USE_GL_FUNC(glEndTransformFeedback)                        /* OpenGL 3.0 */
++    USE_GL_FUNC(glFramebufferTexture)                          /* OpenGL 3.2 */
++    USE_GL_FUNC(glGenBuffers)                                  /* OpenGL 1.5 */
++    USE_GL_FUNC(glGenQueries)                                  /* OpenGL 1.5 */
++    USE_GL_FUNC(glGenVertexArrays)                             /* OpenGL 3.0 */
++    USE_GL_FUNC(glGetActiveUniform)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetAttachedShaders)                          /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetAttribLocation)                           /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetBooleani_v)                               /* OpenGL 3.0 */
++    USE_GL_FUNC(glGetBufferSubData)                            /* OpenGL 1.5 */
++    USE_GL_FUNC(glGetCompressedTexImage)                       /* OpenGL 1.3 */
++    USE_GL_FUNC(glGetDebugMessageLog)                          /* OpenGL 4.3 */
++    USE_GL_FUNC(glGetIntegeri_v)                               /* OpenGL 3.0 */
++    USE_GL_FUNC(glGetProgramInfoLog)                           /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetProgramiv)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetQueryiv)                                  /* OpenGL 1.5 */
++    USE_GL_FUNC(glGetQueryObjectuiv)                           /* OpenGL 1.5 */
++    USE_GL_FUNC(glGetShaderInfoLog)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetShaderiv)                                 /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetShaderSource)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetStringi)                                  /* OpenGL 3.0 */
++    USE_GL_FUNC(glGetTextureLevelParameteriv)                  /* OpenGL 4.5 */
++    USE_GL_FUNC(glGetTextureParameteriv)                       /* OpenGL 4.5 */
++    USE_GL_FUNC(glGetUniformfv)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetUniformiv)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glGetUniformLocation)                          /* OpenGL 2.0 */
++    USE_GL_FUNC(glIsEnabledi)                                  /* OpenGL 3.0 */
++    USE_GL_FUNC(glLinkProgram)                                 /* OpenGL 2.0 */
++    USE_GL_FUNC(glMapBuffer)                                   /* OpenGL 1.5 */
++    USE_GL_FUNC(glMinSampleShading)                            /* OpenGL 4.0 */
++    USE_GL_FUNC(glPointParameteri)                             /* OpenGL 1.4 */
++    USE_GL_FUNC(glPointParameteriv)                            /* OpenGL 1.4 */
++    USE_GL_FUNC(glShaderSource)                                /* OpenGL 2.0 */
++    USE_GL_FUNC(glStencilFuncSeparate)                         /* OpenGL 2.0 */
++    USE_GL_FUNC(glStencilOpSeparate)                           /* OpenGL 2.0 */
++    USE_GL_FUNC(glTexBuffer)                                   /* OpenGL 3.1 */
++    USE_GL_FUNC(glTexImage3D)                                  /* OpenGL 1.2 */
++    USE_GL_FUNC(glTexSubImage3D)                               /* OpenGL 1.2 */
++    USE_GL_FUNC(glTransformFeedbackVaryings)                   /* OpenGL 3.0 */
++    USE_GL_FUNC(glUniform1f)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform1fv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform1i)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform1iv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform2f)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform2fv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform2i)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform2iv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform3f)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform3fv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform3i)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform3iv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform4f)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform4fv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform4i)                                   /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniform4iv)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniformMatrix2fv)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniformMatrix3fv)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glUniformMatrix4fv)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glUnmapBuffer)                                 /* OpenGL 1.5 */
++    USE_GL_FUNC(glUseProgram)                                  /* OpenGL 2.0 */
++    USE_GL_FUNC(glValidateProgram)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib1f)                              /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib1fv)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib2f)                              /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib2fv)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib3f)                              /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib3fv)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4f)                              /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4fv)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4Nsv)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4Nub)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4Nubv)                           /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4Nusv)                           /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4sv)                             /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttrib4ubv)                            /* OpenGL 2.0 */
++    USE_GL_FUNC(glVertexAttribDivisor)                         /* OpenGL 3.3 */
++    USE_GL_FUNC(glVertexAttribIPointer)                        /* OpenGL 3.0 */
++    USE_GL_FUNC(glVertexAttribPointer)                         /* OpenGL 2.0 */
++#undef USE_GL_FUNC
++
++#ifndef USE_WIN32_OPENGL
++    /* hack: use the functions directly from the TEB table to bypass the thunks */
++    /* note that we still need the above wglGetProcAddress calls to initialize the table */
++    gl_info->gl_ops.ext = ((struct opengl_funcs *)NtCurrentTeb()->glTable)->ext;
++#endif
++
++#define MAP_GL_FUNCTION(core_func, ext_func)                                          \
++        do                                                                            \
++        {                                                                             \
++            if (!gl_info->gl_ops.ext.p_##core_func)                                   \
++                gl_info->gl_ops.ext.p_##core_func = gl_info->gl_ops.ext.p_##ext_func; \
++        } while (0)
++#define MAP_GL_FUNCTION_CAST(core_func, ext_func)                                             \
++        do                                                                                    \
++        {                                                                                     \
++            if (!gl_info->gl_ops.ext.p_##core_func)                                           \
++                gl_info->gl_ops.ext.p_##core_func = (void *)gl_info->gl_ops.ext.p_##ext_func; \
++        } while (0)
++
++    MAP_GL_FUNCTION(glActiveTexture, glActiveTextureARB);
++    MAP_GL_FUNCTION(glAttachShader, glAttachObjectARB);
++    MAP_GL_FUNCTION(glBeginQuery, glBeginQueryARB);
++    MAP_GL_FUNCTION(glBindAttribLocation, glBindAttribLocationARB);
++    MAP_GL_FUNCTION(glBindBuffer, glBindBufferARB);
++    MAP_GL_FUNCTION(glBindFragDataLocation, glBindFragDataLocationEXT);
++    MAP_GL_FUNCTION(glBlendColor, glBlendColorEXT);
++    MAP_GL_FUNCTION(glBlendEquation, glBlendEquationEXT);
++    MAP_GL_FUNCTION(glBlendEquationSeparate, glBlendEquationSeparateEXT);
++    MAP_GL_FUNCTION(glBlendFuncSeparate, glBlendFuncSeparateEXT);
++    MAP_GL_FUNCTION(glBufferData, glBufferDataARB);
++    MAP_GL_FUNCTION(glBufferSubData, glBufferSubDataARB);
++    MAP_GL_FUNCTION(glColorMaski, glColorMaskIndexedEXT);
++    MAP_GL_FUNCTION(glCompileShader, glCompileShaderARB);
++    MAP_GL_FUNCTION(glCompressedTexImage2D, glCompressedTexImage2DARB);
++    MAP_GL_FUNCTION(glCompressedTexImage3D, glCompressedTexImage3DARB);
++    MAP_GL_FUNCTION(glCompressedTexSubImage2D, glCompressedTexSubImage2DARB);
++    MAP_GL_FUNCTION(glCompressedTexSubImage3D, glCompressedTexSubImage3DARB);
++    MAP_GL_FUNCTION(glCreateProgram, glCreateProgramObjectARB);
++    MAP_GL_FUNCTION(glCreateShader, glCreateShaderObjectARB);
++    MAP_GL_FUNCTION(glDebugMessageCallback, glDebugMessageCallbackARB);
++    MAP_GL_FUNCTION(glDebugMessageControl, glDebugMessageControlARB);
++    MAP_GL_FUNCTION(glDebugMessageInsert, glDebugMessageInsertARB);
++    MAP_GL_FUNCTION(glDeleteBuffers, glDeleteBuffersARB);
++    MAP_GL_FUNCTION(glDeleteProgram, glDeleteObjectARB);
++    MAP_GL_FUNCTION(glDeleteQueries, glDeleteQueriesARB);
++    MAP_GL_FUNCTION(glDeleteShader, glDeleteObjectARB);
++    MAP_GL_FUNCTION(glDetachShader, glDetachObjectARB);
++    MAP_GL_FUNCTION(glDisablei, glDisableIndexedEXT);
++    MAP_GL_FUNCTION(glDisableVertexAttribArray, glDisableVertexAttribArrayARB);
++    MAP_GL_FUNCTION(glDrawArraysInstanced, glDrawArraysInstancedARB);
++    MAP_GL_FUNCTION(glDrawBuffers, glDrawBuffersARB);
++    MAP_GL_FUNCTION(glDrawElementsInstanced, glDrawElementsInstancedARB);
++    MAP_GL_FUNCTION(glEnablei, glEnableIndexedEXT);
++    MAP_GL_FUNCTION(glEnableVertexAttribArray, glEnableVertexAttribArrayARB);
++    MAP_GL_FUNCTION(glEndQuery, glEndQueryARB);
++    MAP_GL_FUNCTION(glFramebufferTexture, glFramebufferTextureARB);
++    MAP_GL_FUNCTION(glGenBuffers, glGenBuffersARB);
++    MAP_GL_FUNCTION(glGenQueries, glGenQueriesARB);
++    MAP_GL_FUNCTION(glGetActiveUniform, glGetActiveUniformARB);
++    MAP_GL_FUNCTION(glGetAttachedShaders, glGetAttachedObjectsARB);
++    MAP_GL_FUNCTION(glGetAttribLocation, glGetAttribLocationARB);
++    MAP_GL_FUNCTION(glGetBooleani_v, glGetBooleanIndexedvEXT);
++    MAP_GL_FUNCTION(glGetBufferSubData, glGetBufferSubDataARB);
++    MAP_GL_FUNCTION(glGetCompressedTexImage, glGetCompressedTexImageARB);
++    MAP_GL_FUNCTION(glGetDebugMessageLog, glGetDebugMessageLogARB);
++    MAP_GL_FUNCTION(glGetIntegeri_v, glGetIntegerIndexedvEXT);
++    MAP_GL_FUNCTION(glGetProgramInfoLog, glGetInfoLogARB);
++    MAP_GL_FUNCTION(glGetProgramiv, glGetObjectParameterivARB);
++    MAP_GL_FUNCTION(glGetQueryiv, glGetQueryivARB);
++    MAP_GL_FUNCTION(glGetQueryObjectuiv, glGetQueryObjectuivARB);
++    MAP_GL_FUNCTION(glGetShaderInfoLog, glGetInfoLogARB);
++    MAP_GL_FUNCTION(glGetShaderiv, glGetObjectParameterivARB);
++    MAP_GL_FUNCTION(glGetShaderSource, glGetShaderSourceARB);
++    MAP_GL_FUNCTION(glGetUniformfv, glGetUniformfvARB);
++    MAP_GL_FUNCTION(glGetUniformiv, glGetUniformivARB);
++    MAP_GL_FUNCTION(glGetUniformLocation, glGetUniformLocationARB);
++    MAP_GL_FUNCTION(glIsEnabledi, glIsEnabledIndexedEXT);
++    MAP_GL_FUNCTION(glLinkProgram, glLinkProgramARB);
++    MAP_GL_FUNCTION(glMapBuffer, glMapBufferARB);
++    MAP_GL_FUNCTION(glMinSampleShading, glMinSampleShadingARB);
++    MAP_GL_FUNCTION_CAST(glShaderSource, glShaderSourceARB);
++    MAP_GL_FUNCTION(glTexBuffer, glTexBufferARB);
++    MAP_GL_FUNCTION_CAST(glTexImage3D, glTexImage3DEXT);
++    MAP_GL_FUNCTION(glTexSubImage3D, glTexSubImage3DEXT);
++    MAP_GL_FUNCTION(glUniform1f, glUniform1fARB);
++    MAP_GL_FUNCTION(glUniform1fv, glUniform1fvARB);
++    MAP_GL_FUNCTION(glUniform1i, glUniform1iARB);
++    MAP_GL_FUNCTION(glUniform1iv, glUniform1ivARB);
++    MAP_GL_FUNCTION(glUniform2f, glUniform2fARB);
++    MAP_GL_FUNCTION(glUniform2fv, glUniform2fvARB);
++    MAP_GL_FUNCTION(glUniform2i, glUniform2iARB);
++    MAP_GL_FUNCTION(glUniform2iv, glUniform2ivARB);
++    MAP_GL_FUNCTION(glUniform3f, glUniform3fARB);
++    MAP_GL_FUNCTION(glUniform3fv, glUniform3fvARB);
++    MAP_GL_FUNCTION(glUniform3i, glUniform3iARB);
++    MAP_GL_FUNCTION(glUniform3iv, glUniform3ivARB);
++    MAP_GL_FUNCTION(glUniform4f, glUniform4fARB);
++    MAP_GL_FUNCTION(glUniform4fv, glUniform4fvARB);
++    MAP_GL_FUNCTION(glUniform4i, glUniform4iARB);
++    MAP_GL_FUNCTION(glUniform4iv, glUniform4ivARB);
++    MAP_GL_FUNCTION(glUniformMatrix2fv, glUniformMatrix2fvARB);
++    MAP_GL_FUNCTION(glUniformMatrix3fv, glUniformMatrix3fvARB);
++    MAP_GL_FUNCTION(glUniformMatrix4fv, glUniformMatrix4fvARB);
++    MAP_GL_FUNCTION(glUnmapBuffer, glUnmapBufferARB);
++    MAP_GL_FUNCTION(glUseProgram, glUseProgramObjectARB);
++    MAP_GL_FUNCTION(glValidateProgram, glValidateProgramARB);
++    MAP_GL_FUNCTION(glVertexAttrib1f, glVertexAttrib1fARB);
++    MAP_GL_FUNCTION(glVertexAttrib1fv, glVertexAttrib1fvARB);
++    MAP_GL_FUNCTION(glVertexAttrib2f, glVertexAttrib2fARB);
++    MAP_GL_FUNCTION(glVertexAttrib2fv, glVertexAttrib2fvARB);
++    MAP_GL_FUNCTION(glVertexAttrib3f, glVertexAttrib3fARB);
++    MAP_GL_FUNCTION(glVertexAttrib3fv, glVertexAttrib3fvARB);
++    MAP_GL_FUNCTION(glVertexAttrib4f, glVertexAttrib4fARB);
++    MAP_GL_FUNCTION(glVertexAttrib4fv, glVertexAttrib4fvARB);
++    MAP_GL_FUNCTION(glVertexAttrib4Nsv, glVertexAttrib4NsvARB);
++    MAP_GL_FUNCTION(glVertexAttrib4Nub, glVertexAttrib4NubARB);
++    MAP_GL_FUNCTION(glVertexAttrib4Nubv, glVertexAttrib4NubvARB);
++    MAP_GL_FUNCTION(glVertexAttrib4Nusv, glVertexAttrib4NusvARB);
++    MAP_GL_FUNCTION(glVertexAttrib4sv, glVertexAttrib4svARB);
++    MAP_GL_FUNCTION(glVertexAttrib4ubv, glVertexAttrib4ubvARB);
++    MAP_GL_FUNCTION(glVertexAttribDivisor, glVertexAttribDivisorARB);
++    MAP_GL_FUNCTION(glVertexAttribIPointer, glVertexAttribIPointerEXT);
++    MAP_GL_FUNCTION(glVertexAttribPointer, glVertexAttribPointerARB);
++#undef MAP_GL_FUNCTION
++#undef MAP_GL_FUNCTION_CAST
++}
++
++static void wined3d_adapter_init_limits(struct wined3d_gl_info *gl_info)
++{
++    unsigned int i, sampler_count;
++    GLfloat gl_floatv[2];
++    GLint gl_max;
++
++    gl_info->limits.buffers = 1;
++    gl_info->limits.textures = 0;
++    gl_info->limits.texture_coords = 0;
++    for (i = 0; i < WINED3D_SHADER_TYPE_COUNT; ++i)
++    {
++        gl_info->limits.uniform_blocks[i] = 0;
++        gl_info->limits.samplers[i] = 0;
++    }
++    gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] = 1;
++    gl_info->limits.combined_samplers = gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL];
++    gl_info->limits.graphics_samplers = gl_info->limits.combined_samplers;
++    gl_info->limits.vertex_attribs = 16;
++    gl_info->limits.texture_buffer_offset_alignment = 1;
++    gl_info->limits.glsl_vs_float_constants = 0;
++    gl_info->limits.glsl_ps_float_constants = 0;
++    gl_info->limits.arb_vs_float_constants = 0;
++    gl_info->limits.arb_vs_native_constants = 0;
++    gl_info->limits.arb_vs_instructions = 0;
++    gl_info->limits.arb_vs_temps = 0;
++    gl_info->limits.arb_ps_float_constants = 0;
++    gl_info->limits.arb_ps_local_constants = 0;
++    gl_info->limits.arb_ps_instructions = 0;
++    gl_info->limits.arb_ps_temps = 0;
++
++    gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_CLIP_DISTANCES, &gl_max);
++    gl_info->limits.user_clip_distances = min(MAX_CLIP_DISTANCES, gl_max);
++    TRACE("Clip plane support - max planes %d.\n", gl_max);
++
++    if (gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_LIGHTS, &gl_max);
++        gl_info->limits.lights = gl_max;
++        TRACE("Light support - max lights %d.\n", gl_max);
++    }
++
++    gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_SIZE, &gl_max);
++    gl_info->limits.texture_size = gl_max;
++    TRACE("Maximum texture size support - max texture size %d.\n", gl_max);
++
++    gl_info->gl_ops.gl.p_glGetFloatv(gl_info->supported[WINED3D_GL_LEGACY_CONTEXT]
++            ? GL_ALIASED_POINT_SIZE_RANGE : GL_POINT_SIZE_RANGE, gl_floatv);
++    gl_info->limits.pointsize_min = gl_floatv[0];
++    gl_info->limits.pointsize_max = gl_floatv[1];
++    TRACE("Maximum point size support - max point size %f.\n", gl_floatv[1]);
++
++    if (gl_info->supported[ARB_MAP_BUFFER_ALIGNMENT])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MIN_MAP_BUFFER_ALIGNMENT, &gl_max);
++        TRACE("Minimum buffer map alignment: %d.\n", gl_max);
++    }
++    else
++    {
++        WARN_(d3d_perf)("Driver doesn't guarantee a minimum buffer map alignment.\n");
++    }
++    if (gl_info->supported[NV_REGISTER_COMBINERS])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_GENERAL_COMBINERS_NV, &gl_max);
++        gl_info->limits.general_combiners = gl_max;
++        TRACE("Max general combiners: %d.\n", gl_max);
++    }
++    if (gl_info->supported[ARB_DRAW_BUFFERS] && wined3d_settings.offscreen_rendering_mode == ORM_FBO)
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_DRAW_BUFFERS_ARB, &gl_max);
++        gl_info->limits.buffers = min(MAX_RENDER_TARGET_VIEWS, gl_max);
++        TRACE("Max draw buffers: %u.\n", gl_max);
++    }
++    if (gl_info->supported[ARB_MULTITEXTURE])
++    {
++        if (gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
++        {
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_UNITS_ARB, &gl_max);
++            gl_info->limits.textures = min(MAX_TEXTURES, gl_max);
++            TRACE("Max textures: %d.\n", gl_info->limits.textures);
++
++            if (gl_info->supported[ARB_FRAGMENT_PROGRAM])
++            {
++                gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_COORDS_ARB, &gl_max);
++                gl_info->limits.texture_coords = min(MAX_TEXTURES, gl_max);
++            }
++            else
++            {
++                gl_info->limits.texture_coords = gl_info->limits.textures;
++            }
++            TRACE("Max texture coords: %d.\n", gl_info->limits.texture_coords);
++        }
++
++        if (gl_info->supported[ARB_FRAGMENT_PROGRAM] || gl_info->supported[ARB_FRAGMENT_SHADER])
++        {
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_IMAGE_UNITS, &gl_max);
++            gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] = gl_max;
++        }
++        else
++        {
++            gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] = gl_info->limits.textures;
++        }
++        TRACE("Max fragment samplers: %d.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL]);
++
++        if (gl_info->supported[ARB_VERTEX_SHADER])
++        {
++            unsigned int vertex_sampler_count;
++
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_TEXTURE_IMAGE_UNITS_ARB, &gl_max);
++            vertex_sampler_count = gl_info->limits.samplers[WINED3D_SHADER_TYPE_VERTEX] = gl_max;
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS_ARB, &gl_max);
++            gl_info->limits.combined_samplers = gl_max;
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_ATTRIBS_ARB, &gl_max);
++            gl_info->limits.vertex_attribs = gl_max;
++
++            /* Loading GLSL sampler uniforms is much simpler if we can assume that the sampler setup
++             * is known at shader link time. In a vertex shader + pixel shader combination this isn't
++             * an issue because then the sampler setup only depends on the two shaders. If a pixel
++             * shader is used with fixed function vertex processing we're fine too because fixed function
++             * vertex processing doesn't use any samplers. If fixed function fragment processing is
++             * used we have to make sure that all vertex sampler setups are valid together with all
++             * possible fixed function fragment processing setups. This is true if vsamplers + MAX_TEXTURES
++             * <= max_samplers. This is true on all d3d9 cards that support vtf(gf 6 and gf7 cards).
++             * dx9 radeon cards do not support vertex texture fetch. DX10 cards have 128 samplers, and
++             * dx9 is limited to 8 fixed function texture stages and 4 vertex samplers. DX10 does not have
++             * a fixed function pipeline anymore.
++             *
++             * So this is just a check to check that our assumption holds true. If not, write a warning
++             * and reduce the number of vertex samplers or probably disable vertex texture fetch. */
++            if (vertex_sampler_count && gl_info->limits.combined_samplers < 12
++                    && MAX_TEXTURES + vertex_sampler_count > gl_info->limits.combined_samplers)
++            {
++                FIXME("OpenGL implementation supports %u vertex samplers and %u total samplers.\n",
++                        vertex_sampler_count, gl_info->limits.combined_samplers);
++                FIXME("Expected vertex samplers + MAX_TEXTURES(=8) > combined_samplers.\n");
++                if (gl_info->limits.combined_samplers > MAX_TEXTURES)
++                    vertex_sampler_count = gl_info->limits.combined_samplers - MAX_TEXTURES;
++                else
++                    vertex_sampler_count = 0;
++                gl_info->limits.samplers[WINED3D_SHADER_TYPE_VERTEX] = vertex_sampler_count;
++            }
++        }
++        else
++        {
++            gl_info->limits.combined_samplers = gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL];
++        }
++        TRACE("Max vertex samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_VERTEX]);
++        TRACE("Max combined samplers: %u.\n", gl_info->limits.combined_samplers);
++        TRACE("Max vertex attributes: %u.\n", gl_info->limits.vertex_attribs);
++    }
++    else
++    {
++        gl_info->limits.textures = 1;
++        gl_info->limits.texture_coords = 1;
++    }
++
++    if (gl_info->supported[EXT_TEXTURE3D])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_3D_TEXTURE_SIZE_EXT, &gl_max);
++        gl_info->limits.texture3d_size = gl_max;
++        TRACE("Max texture3D size: %d.\n", gl_info->limits.texture3d_size);
++    }
++    if (gl_info->supported[ARB_TEXTURE_FILTER_ANISOTROPIC])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_MAX_ANISOTROPY, &gl_max);
++        gl_info->limits.anisotropy = gl_max;
++        TRACE("Max anisotropy: %d.\n", gl_info->limits.anisotropy);
++    }
++    if (gl_info->supported[ARB_FRAGMENT_PROGRAM])
++    {
++        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_ENV_PARAMETERS_ARB, &gl_max));
++        gl_info->limits.arb_ps_float_constants = gl_max;
++        TRACE("Max ARB_FRAGMENT_PROGRAM float constants: %d.\n", gl_info->limits.arb_ps_float_constants);
++        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_PARAMETERS_ARB, &gl_max));
++        gl_info->limits.arb_ps_native_constants = gl_max;
++        TRACE("Max ARB_FRAGMENT_PROGRAM native float constants: %d.\n",
++                gl_info->limits.arb_ps_native_constants);
++        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_TEMPORARIES_ARB, &gl_max));
++        gl_info->limits.arb_ps_temps = gl_max;
++        TRACE("Max ARB_FRAGMENT_PROGRAM native temporaries: %d.\n", gl_info->limits.arb_ps_temps);
++        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_INSTRUCTIONS_ARB, &gl_max));
++        gl_info->limits.arb_ps_instructions = gl_max;
++        TRACE("Max ARB_FRAGMENT_PROGRAM native instructions: %d.\n", gl_info->limits.arb_ps_instructions);
++        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_LOCAL_PARAMETERS_ARB, &gl_max));
++        gl_info->limits.arb_ps_local_constants = gl_max;
++        TRACE("Max ARB_FRAGMENT_PROGRAM local parameters: %d.\n", gl_info->limits.arb_ps_instructions);
++    }
++    if (gl_info->supported[ARB_VERTEX_PROGRAM])
++    {
++        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_ENV_PARAMETERS_ARB, &gl_max));
++        gl_info->limits.arb_vs_float_constants = gl_max;
++        TRACE("Max ARB_VERTEX_PROGRAM float constants: %d.\n", gl_info->limits.arb_vs_float_constants);
++        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_PARAMETERS_ARB, &gl_max));
++        gl_info->limits.arb_vs_native_constants = gl_max;
++        TRACE("Max ARB_VERTEX_PROGRAM native float constants: %d.\n",
++                gl_info->limits.arb_vs_native_constants);
++        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_TEMPORARIES_ARB, &gl_max));
++        gl_info->limits.arb_vs_temps = gl_max;
++        TRACE("Max ARB_VERTEX_PROGRAM native temporaries: %d.\n", gl_info->limits.arb_vs_temps);
++        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_INSTRUCTIONS_ARB, &gl_max));
++        gl_info->limits.arb_vs_instructions = gl_max;
++        TRACE("Max ARB_VERTEX_PROGRAM native instructions: %d.\n", gl_info->limits.arb_vs_instructions);
++    }
++    if (gl_info->supported[ARB_VERTEX_SHADER])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_UNIFORM_COMPONENTS_ARB, &gl_max);
++        gl_info->limits.glsl_vs_float_constants = gl_max / 4;
++        TRACE("Max ARB_VERTEX_SHADER float constants: %u.\n", gl_info->limits.glsl_vs_float_constants);
++
++        if (gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
++        {
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_UNIFORM_BLOCKS, &gl_max);
++            gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_VERTEX] = min(gl_max, WINED3D_MAX_CBS);
++            TRACE("Max vertex uniform blocks: %u (%d).\n",
++                    gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_VERTEX], gl_max);
++        }
++    }
++    if (gl_info->supported[ARB_TESSELLATION_SHADER])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_CONTROL_UNIFORM_BLOCKS, &gl_max);
++        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_HULL] = min(gl_max, WINED3D_MAX_CBS);
++        TRACE("Max hull uniform blocks: %u (%d).\n",
++                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_HULL], gl_max);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_CONTROL_TEXTURE_IMAGE_UNITS, &gl_max);
++        gl_info->limits.samplers[WINED3D_SHADER_TYPE_HULL] = gl_max;
++        TRACE("Max hull samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_HULL]);
++
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_EVALUATION_UNIFORM_BLOCKS, &gl_max);
++        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_DOMAIN] = min(gl_max, WINED3D_MAX_CBS);
++        TRACE("Max domain uniform blocks: %u (%d).\n",
++                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_DOMAIN], gl_max);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_EVALUATION_TEXTURE_IMAGE_UNITS, &gl_max);
++        gl_info->limits.samplers[WINED3D_SHADER_TYPE_DOMAIN] = gl_max;
++        TRACE("Max domain samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_DOMAIN]);
++    }
++    if (gl_info->supported[WINED3D_GL_VERSION_3_2] && gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_GEOMETRY_UNIFORM_BLOCKS, &gl_max);
++        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_GEOMETRY] = min(gl_max, WINED3D_MAX_CBS);
++        TRACE("Max geometry uniform blocks: %u (%d).\n",
++                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_GEOMETRY], gl_max);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_GEOMETRY_TEXTURE_IMAGE_UNITS, &gl_max);
++        gl_info->limits.samplers[WINED3D_SHADER_TYPE_GEOMETRY] = gl_max;
++        TRACE("Max geometry samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_GEOMETRY]);
++    }
++    if (gl_info->supported[ARB_FRAGMENT_SHADER])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAGMENT_UNIFORM_COMPONENTS_ARB, &gl_max);
++        gl_info->limits.glsl_ps_float_constants = gl_max / 4;
++        TRACE("Max ARB_FRAGMENT_SHADER float constants: %u.\n", gl_info->limits.glsl_ps_float_constants);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VARYING_FLOATS_ARB, &gl_max);
++        gl_info->limits.glsl_varyings = gl_max;
++        TRACE("Max GLSL varyings: %u (%u 4 component varyings).\n", gl_max, gl_max / 4);
++
++        if (gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
++        {
++            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAGMENT_UNIFORM_BLOCKS, &gl_max);
++            gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_PIXEL] = min(gl_max, WINED3D_MAX_CBS);
++            TRACE("Max fragment uniform blocks: %u (%d).\n",
++                    gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_PIXEL], gl_max);
++        }
++    }
++    if (gl_info->supported[ARB_COMPUTE_SHADER])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMPUTE_UNIFORM_BLOCKS, &gl_max);
++        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_COMPUTE] = min(gl_max, WINED3D_MAX_CBS);
++        TRACE("Max compute uniform blocks: %u (%d).\n",
++                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_COMPUTE], gl_max);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMPUTE_TEXTURE_IMAGE_UNITS, &gl_max);
++        gl_info->limits.samplers[WINED3D_SHADER_TYPE_COMPUTE] = gl_max;
++        TRACE("Max compute samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_COMPUTE]);
++    }
++    if (gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMBINED_UNIFORM_BLOCKS, &gl_max);
++        TRACE("Max combined uniform blocks: %d.\n", gl_max);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_UNIFORM_BUFFER_BINDINGS, &gl_max);
++        TRACE("Max uniform buffer bindings: %d.\n", gl_max);
++    }
++    if (gl_info->supported[ARB_TEXTURE_BUFFER_RANGE])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_TEXTURE_BUFFER_OFFSET_ALIGNMENT, &gl_max);
++        gl_info->limits.texture_buffer_offset_alignment = gl_max;
++        TRACE("Minimum required texture buffer offset alignment %d.\n", gl_max);
++    }
++    if (gl_info->supported[ARB_SHADER_ATOMIC_COUNTERS])
++    {
++        GLint max_fragment_buffers, max_combined_buffers, max_bindings;
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAGMENT_ATOMIC_COUNTER_BUFFERS, &max_fragment_buffers);
++        TRACE("Max fragment atomic counter buffers: %d.\n", max_fragment_buffers);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMBINED_ATOMIC_COUNTER_BUFFERS, &max_combined_buffers);
++        TRACE("Max combined atomic counter buffers: %d.\n", max_combined_buffers);
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_ATOMIC_COUNTER_BUFFER_BINDINGS, &max_bindings);
++        TRACE("Max atomic counter buffer bindings: %d.\n", max_bindings);
++        if (max_fragment_buffers < MAX_UNORDERED_ACCESS_VIEWS
++                || max_combined_buffers < MAX_UNORDERED_ACCESS_VIEWS
++                || max_bindings < MAX_UNORDERED_ACCESS_VIEWS)
++        {
++            WARN("Disabling ARB_shader_atomic_counters.\n");
++            gl_info->supported[ARB_SHADER_ATOMIC_COUNTERS] = FALSE;
++        }
++    }
++    if (gl_info->supported[ARB_TRANSFORM_FEEDBACK3])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_STREAMS, &gl_max);
++        TRACE("Max vertex streams: %d.\n", gl_max);
++    }
++
++    if (gl_info->supported[NV_LIGHT_MAX_EXPONENT])
++        gl_info->gl_ops.gl.p_glGetFloatv(GL_MAX_SHININESS_NV, &gl_info->limits.shininess);
++    else
++        gl_info->limits.shininess = 128.0f;
++
++    if (gl_info->supported[ARB_FRAMEBUFFER_OBJECT] || gl_info->supported[EXT_FRAMEBUFFER_MULTISAMPLE])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_SAMPLES, &gl_max);
++        gl_info->limits.samples = gl_max;
++    }
++
++    if (gl_info->supported[ARB_FRAMEBUFFER_NO_ATTACHMENTS])
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAMEBUFFER_WIDTH, &gl_max);
++        gl_info->limits.framebuffer_width = gl_max;
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAMEBUFFER_HEIGHT, &gl_max);
++        gl_info->limits.framebuffer_height = gl_max;
++    }
++    else
++    {
++        gl_info->limits.framebuffer_width = gl_info->limits.texture_size;
++        gl_info->limits.framebuffer_height = gl_info->limits.texture_size;
++    }
++
++    gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] =
++            min(gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL], MAX_GL_FRAGMENT_SAMPLERS);
++    sampler_count = 0;
++    for (i = 0; i < WINED3D_SHADER_TYPE_GRAPHICS_COUNT; ++i)
++        sampler_count += gl_info->limits.samplers[i];
++    if (gl_info->supported[WINED3D_GL_VERSION_3_2] && gl_info->limits.combined_samplers < sampler_count)
++    {
++        /* The minimum value for GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS in OpenGL
++         * 3.2 is 48 (16 per stage). When tessellation shaders are supported
++         * the minimum value is increased to 80. */
++        WARN("Graphics pipeline sampler count %u is greater than combined sampler count %u.\n",
++                sampler_count, gl_info->limits.combined_samplers);
++        for (i = 0; i < WINED3D_SHADER_TYPE_GRAPHICS_COUNT; ++i)
++            gl_info->limits.samplers[i] = min(gl_info->limits.samplers[i], 16);
++    }
++
++    /* A majority of OpenGL implementations allow us to statically partition
++     * the set of texture bindings into six separate sets. */
++    gl_info->limits.graphics_samplers = gl_info->limits.combined_samplers;
++    sampler_count = 0;
++    for (i = 0; i < WINED3D_SHADER_TYPE_COUNT; ++i)
++        sampler_count += gl_info->limits.samplers[i];
++    if (gl_info->limits.combined_samplers >= sampler_count)
++        gl_info->limits.graphics_samplers -= gl_info->limits.samplers[WINED3D_SHADER_TYPE_COMPUTE];
++}
++
++/* Context activation is done by the caller. */
++static BOOL wined3d_adapter_init_gl_caps(struct wined3d_adapter *adapter,
++        struct wined3d_caps_gl_ctx *caps_gl_ctx, DWORD wined3d_creation_flags)
++{
++    static const struct
++    {
++        enum wined3d_gl_extension extension;
++        DWORD min_gl_version;
++    }
++    core_extensions[] =
++    {
++        {EXT_TEXTURE3D,                    MAKEDWORD_VERSION(1, 2)},
++        {ARB_MULTISAMPLE,                  MAKEDWORD_VERSION(1, 3)},
++        {ARB_MULTITEXTURE,                 MAKEDWORD_VERSION(1, 3)},
++        {ARB_TEXTURE_BORDER_CLAMP,         MAKEDWORD_VERSION(1, 3)},
++        {ARB_TEXTURE_COMPRESSION,          MAKEDWORD_VERSION(1, 3)},
++        {ARB_TEXTURE_CUBE_MAP,             MAKEDWORD_VERSION(1, 3)},
++        {ARB_DEPTH_TEXTURE,                MAKEDWORD_VERSION(1, 4)},
++        {ARB_POINT_PARAMETERS,             MAKEDWORD_VERSION(1, 4)},
++        {ARB_SHADOW,                       MAKEDWORD_VERSION(1, 4)},
++        {ARB_TEXTURE_MIRRORED_REPEAT,      MAKEDWORD_VERSION(1, 4)},
++        {EXT_BLEND_COLOR,                  MAKEDWORD_VERSION(1, 4)},
++        {EXT_BLEND_FUNC_SEPARATE,          MAKEDWORD_VERSION(1, 4)},
++        {EXT_BLEND_MINMAX,                 MAKEDWORD_VERSION(1, 4)},
++        {EXT_BLEND_SUBTRACT,               MAKEDWORD_VERSION(1, 4)},
++        {EXT_STENCIL_WRAP,                 MAKEDWORD_VERSION(1, 4)},
++        {NV_POINT_SPRITE,                  MAKEDWORD_VERSION(1, 4)},
++        {ARB_OCCLUSION_QUERY,              MAKEDWORD_VERSION(1, 5)},
++        {ARB_VERTEX_BUFFER_OBJECT,         MAKEDWORD_VERSION(1, 5)},
++        {ARB_DRAW_BUFFERS,                 MAKEDWORD_VERSION(2, 0)},
++        {ARB_FRAGMENT_SHADER,              MAKEDWORD_VERSION(2, 0)},
++        {ARB_SHADING_LANGUAGE_100,         MAKEDWORD_VERSION(2, 0)},
++        {ARB_TEXTURE_NON_POWER_OF_TWO,     MAKEDWORD_VERSION(2, 0)},
++        {ARB_VERTEX_SHADER,                MAKEDWORD_VERSION(2, 0)},
++        {EXT_BLEND_EQUATION_SEPARATE,      MAKEDWORD_VERSION(2, 0)},
++        {ARB_PIXEL_BUFFER_OBJECT,          MAKEDWORD_VERSION(2, 1)},
++        {EXT_TEXTURE_SRGB,                 MAKEDWORD_VERSION(2, 1)},
++        {ARB_COLOR_BUFFER_FLOAT,           MAKEDWORD_VERSION(3, 0)},
++        {ARB_DEPTH_BUFFER_FLOAT,           MAKEDWORD_VERSION(3, 0)},
++        {ARB_FRAMEBUFFER_OBJECT,           MAKEDWORD_VERSION(3, 0)},
++        {ARB_FRAMEBUFFER_SRGB,             MAKEDWORD_VERSION(3, 0)},
++        {ARB_HALF_FLOAT_PIXEL,             MAKEDWORD_VERSION(3, 0)},
++        {ARB_HALF_FLOAT_VERTEX,            MAKEDWORD_VERSION(3, 0)},
++        {ARB_MAP_BUFFER_RANGE,             MAKEDWORD_VERSION(3, 0)},
++        {ARB_TEXTURE_COMPRESSION_RGTC,     MAKEDWORD_VERSION(3, 0)},
++        {ARB_TEXTURE_FLOAT,                MAKEDWORD_VERSION(3, 0)},
++        {ARB_TEXTURE_RG,                   MAKEDWORD_VERSION(3, 0)},
++        {EXT_DRAW_BUFFERS2,                MAKEDWORD_VERSION(3, 0)},
++        {EXT_PACKED_FLOAT,                 MAKEDWORD_VERSION(3, 0)},
++        {EXT_TEXTURE_ARRAY,                MAKEDWORD_VERSION(3, 0)},
++        {EXT_TEXTURE_INTEGER,              MAKEDWORD_VERSION(3, 0)},
++        {EXT_TEXTURE_SHARED_EXPONENT,      MAKEDWORD_VERSION(3, 0)},
++        /* We don't want to enable EXT_GPU_SHADER4: even though similar
++         * functionality is available in core GL 3.0 / GLSL 1.30, it's different
++         * enough that reusing the same flag for the new features hurts more
++         * than it helps. */
++        /* EXT_framebuffer_object, EXT_framebuffer_blit,
++         * EXT_framebuffer_multisample and EXT_packed_depth_stencil
++         * are integrated into ARB_framebuffer_object. */
++
++        {ARB_COPY_BUFFER,                  MAKEDWORD_VERSION(3, 1)},
++        {ARB_DRAW_INSTANCED,               MAKEDWORD_VERSION(3, 1)},
++        {ARB_TEXTURE_BUFFER_OBJECT,        MAKEDWORD_VERSION(3, 1)},
++        {ARB_UNIFORM_BUFFER_OBJECT,        MAKEDWORD_VERSION(3, 1)},
++        {EXT_TEXTURE_SNORM,                MAKEDWORD_VERSION(3, 1)},
++        /* We don't need or want GL_ARB_texture_rectangle (core in 3.1). */
++
++        {ARB_DEPTH_CLAMP,                  MAKEDWORD_VERSION(3, 2)},
++        {ARB_DRAW_ELEMENTS_BASE_VERTEX,    MAKEDWORD_VERSION(3, 2)},
++        /* ARB_geometry_shader4 exposes a somewhat different API compared to 3.2
++         * core geometry shaders so it's not really correct to expose the
++         * extension for core-only support. */
++        {ARB_FRAGMENT_COORD_CONVENTIONS,   MAKEDWORD_VERSION(3, 2)},
++        {ARB_PROVOKING_VERTEX,             MAKEDWORD_VERSION(3, 2)},
++        {ARB_SEAMLESS_CUBE_MAP,            MAKEDWORD_VERSION(3, 2)},
++        {ARB_SYNC,                         MAKEDWORD_VERSION(3, 2)},
++        {ARB_TEXTURE_MULTISAMPLE,          MAKEDWORD_VERSION(3, 2)},
++        {ARB_VERTEX_ARRAY_BGRA,            MAKEDWORD_VERSION(3, 2)},
++
++        {ARB_BLEND_FUNC_EXTENDED,          MAKEDWORD_VERSION(3, 3)},
++        {ARB_EXPLICIT_ATTRIB_LOCATION,     MAKEDWORD_VERSION(3, 3)},
++        {ARB_INSTANCED_ARRAYS,             MAKEDWORD_VERSION(3, 3)},
++        {ARB_SAMPLER_OBJECTS,              MAKEDWORD_VERSION(3, 3)},
++        {ARB_SHADER_BIT_ENCODING,          MAKEDWORD_VERSION(3, 3)},
++        {ARB_TEXTURE_RGB10_A2UI,           MAKEDWORD_VERSION(3, 3)},
++        {ARB_TEXTURE_SWIZZLE,              MAKEDWORD_VERSION(3, 3)},
++        {ARB_TIMER_QUERY,                  MAKEDWORD_VERSION(3, 3)},
++        {ARB_VERTEX_TYPE_2_10_10_10_REV,   MAKEDWORD_VERSION(3, 3)},
++
++        {ARB_DRAW_INDIRECT,                MAKEDWORD_VERSION(4, 0)},
++        {ARB_GPU_SHADER5,                  MAKEDWORD_VERSION(4, 0)},
++        {ARB_SAMPLE_SHADING,               MAKEDWORD_VERSION(4, 0)},
++        {ARB_TESSELLATION_SHADER,          MAKEDWORD_VERSION(4, 0)},
++        {ARB_TEXTURE_CUBE_MAP_ARRAY,       MAKEDWORD_VERSION(4, 0)},
++        {ARB_TEXTURE_GATHER,               MAKEDWORD_VERSION(4, 0)},
++        {ARB_TRANSFORM_FEEDBACK2,          MAKEDWORD_VERSION(4, 0)},
++        {ARB_TRANSFORM_FEEDBACK3,          MAKEDWORD_VERSION(4, 0)},
++
++        {ARB_ES2_COMPATIBILITY,            MAKEDWORD_VERSION(4, 1)},
++        {ARB_VIEWPORT_ARRAY,               MAKEDWORD_VERSION(4, 1)},
++
++        {ARB_BASE_INSTANCE,                MAKEDWORD_VERSION(4, 2)},
++        {ARB_CONSERVATIVE_DEPTH,           MAKEDWORD_VERSION(4, 2)},
++        {ARB_INTERNALFORMAT_QUERY,         MAKEDWORD_VERSION(4, 2)},
++        {ARB_MAP_BUFFER_ALIGNMENT,         MAKEDWORD_VERSION(4, 2)},
++        {ARB_SHADER_ATOMIC_COUNTERS,       MAKEDWORD_VERSION(4, 2)},
++        {ARB_SHADER_IMAGE_LOAD_STORE,      MAKEDWORD_VERSION(4, 2)},
++        {ARB_SHADING_LANGUAGE_420PACK,     MAKEDWORD_VERSION(4, 2)},
++        {ARB_SHADING_LANGUAGE_PACKING,     MAKEDWORD_VERSION(4, 2)},
++        {ARB_TEXTURE_COMPRESSION_BPTC,     MAKEDWORD_VERSION(4, 2)},
++        {ARB_TEXTURE_STORAGE,              MAKEDWORD_VERSION(4, 2)},
++
++        {ARB_CLEAR_BUFFER_OBJECT,          MAKEDWORD_VERSION(4, 3)},
++        {ARB_COMPUTE_SHADER,               MAKEDWORD_VERSION(4, 3)},
++        {ARB_COPY_IMAGE,                   MAKEDWORD_VERSION(4, 3)},
++        {ARB_DEBUG_OUTPUT,                 MAKEDWORD_VERSION(4, 3)},
++        {ARB_ES3_COMPATIBILITY,            MAKEDWORD_VERSION(4, 3)},
++        {ARB_FRAGMENT_LAYER_VIEWPORT,      MAKEDWORD_VERSION(4, 3)},
++        {ARB_FRAMEBUFFER_NO_ATTACHMENTS,   MAKEDWORD_VERSION(4, 3)},
++        {ARB_INTERNALFORMAT_QUERY2,        MAKEDWORD_VERSION(4, 3)},
++        {ARB_SHADER_IMAGE_SIZE,            MAKEDWORD_VERSION(4, 3)},
++        {ARB_SHADER_STORAGE_BUFFER_OBJECT, MAKEDWORD_VERSION(4, 3)},
++        {ARB_STENCIL_TEXTURING,            MAKEDWORD_VERSION(4, 3)},
++        {ARB_TEXTURE_BUFFER_RANGE,         MAKEDWORD_VERSION(4, 3)},
++        {ARB_TEXTURE_QUERY_LEVELS,         MAKEDWORD_VERSION(4, 3)},
++        {ARB_TEXTURE_STORAGE_MULTISAMPLE,  MAKEDWORD_VERSION(4, 2)},
++        {ARB_TEXTURE_VIEW,                 MAKEDWORD_VERSION(4, 3)},
++
++        {ARB_CLEAR_TEXTURE,                MAKEDWORD_VERSION(4, 4)},
++
++        {ARB_CLIP_CONTROL,                 MAKEDWORD_VERSION(4, 5)},
++        {ARB_CULL_DISTANCE,                MAKEDWORD_VERSION(4, 5)},
++        {ARB_DERIVATIVE_CONTROL,           MAKEDWORD_VERSION(4, 5)},
++        {ARB_SHADER_TEXTURE_IMAGE_SAMPLES, MAKEDWORD_VERSION(4, 5)},
++
++        {ARB_PIPELINE_STATISTICS_QUERY,    MAKEDWORD_VERSION(4, 6)},
++        {ARB_TEXTURE_FILTER_ANISOTROPIC,   MAKEDWORD_VERSION(4, 6)},
++    };
++    struct wined3d_driver_info *driver_info = &adapter->driver_info;
++    const char *gl_vendor_str, *gl_renderer_str, *gl_version_str;
++    struct wined3d_d3d_info *d3d_info = &adapter->d3d_info;
++    struct wined3d_gl_info *gl_info = &adapter->gl_info;
++    const struct gpu_description *gpu_description;
++    struct wined3d_vertex_caps vertex_caps;
++    struct fragment_caps fragment_caps;
++    struct shader_caps shader_caps;
++    const char *WGL_Extensions = NULL;
++    enum wined3d_gl_vendor gl_vendor;
++    DWORD gl_version, gl_ext_emul_mask;
++    GLint context_profile = 0;
++    UINT64 vram_bytes = 0;
++    unsigned int i, j;
++    HDC hdc;
++
++    TRACE("adapter %p.\n", adapter);
++
++    gl_renderer_str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_RENDERER);
++    TRACE("GL_RENDERER: %s.\n", debugstr_a(gl_renderer_str));
++    if (!gl_renderer_str)
++    {
++        ERR("Received a NULL GL_RENDERER.\n");
++        return FALSE;
++    }
++
++    gl_vendor_str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_VENDOR);
++    TRACE("GL_VENDOR: %s.\n", debugstr_a(gl_vendor_str));
++    if (!gl_vendor_str)
++    {
++        ERR("Received a NULL GL_VENDOR.\n");
++        return FALSE;
++    }
++
++    /* Parse the GL_VERSION field into major and minor information */
++    gl_version_str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_VERSION);
++    TRACE("GL_VERSION: %s.\n", debugstr_a(gl_version_str));
++    if (!gl_version_str)
++    {
++        ERR("Received a NULL GL_VERSION.\n");
++        return FALSE;
++    }
++    gl_version = wined3d_parse_gl_version(gl_version_str);
++
++    load_gl_funcs(gl_info);
++
++    memset(gl_info->supported, 0, sizeof(gl_info->supported));
++    gl_info->supported[WINED3D_GL_EXT_NONE] = TRUE;
++
++    if (gl_version >= MAKEDWORD_VERSION(3, 2))
++    {
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_CONTEXT_PROFILE_MASK, &context_profile);
++        checkGLcall("Querying context profile");
++    }
++    if (context_profile & GL_CONTEXT_CORE_PROFILE_BIT)
++        TRACE("Got a core profile context.\n");
++    else
++        gl_info->supported[WINED3D_GL_LEGACY_CONTEXT] = TRUE;
++
++    TRACE("GL extensions reported:\n");
++    if (gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
++    {
++        const char *gl_extensions = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_EXTENSIONS);
++
++        if (!gl_extensions)
++        {
++            ERR("Received a NULL GL_EXTENSIONS.\n");
++            return FALSE;
++        }
++        parse_extension_string(gl_info, gl_extensions, gl_extension_map, ARRAY_SIZE(gl_extension_map));
++    }
++    else
++    {
++        enumerate_gl_extensions(gl_info, gl_extension_map, ARRAY_SIZE(gl_extension_map));
++    }
++
++    hdc = wglGetCurrentDC();
++    /* Not all GL drivers might offer WGL extensions e.g. VirtualBox. */
++    if (GL_EXTCALL(wglGetExtensionsStringARB))
++        WGL_Extensions = (const char *)GL_EXTCALL(wglGetExtensionsStringARB(hdc));
++    if (!WGL_Extensions)
++        WARN("WGL extensions not supported.\n");
++    else
++        parse_extension_string(gl_info, WGL_Extensions, wgl_extension_map, ARRAY_SIZE(wgl_extension_map));
++
++    for (i = 0; i < ARRAY_SIZE(core_extensions); ++i)
++    {
++        if (!gl_info->supported[core_extensions[i].extension]
++                && gl_version >= core_extensions[i].min_gl_version)
++        {
++            for (j = 0; j < ARRAY_SIZE(gl_extension_map); ++j)
++                if (gl_extension_map[j].extension == core_extensions[i].extension)
++                    break;
++
++            if (j < ARRAY_SIZE(gl_extension_map))
++            {
++                TRACE("GL CORE: %s support.\n", gl_extension_map[j].extension_string);
++                gl_info->supported[core_extensions[i].extension] = TRUE;
++            }
++            else
++            {
++                FIXME("GL extension %u not in the GL extensions map.\n", core_extensions[i].extension);
++            }
++        }
++    }
++
++    if (gl_info->supported[EXT_BLEND_MINMAX] || gl_info->supported[EXT_BLEND_SUBTRACT])
++        gl_info->supported[WINED3D_GL_BLEND_EQUATION] = TRUE;
++
++    if (gl_version >= MAKEDWORD_VERSION(2, 0))
++    {
++        gl_info->supported[WINED3D_GL_VERSION_2_0] = TRUE;
++        /* We want to use the core APIs for two-sided stencil in GL 2.0. */
++        gl_info->supported[EXT_STENCIL_TWO_SIDE] = FALSE;
++    }
++    if (gl_version >= MAKEDWORD_VERSION(3, 2))
++        gl_info->supported[WINED3D_GL_VERSION_3_2] = TRUE;
++
++    /* All the points are actually point sprites in core contexts, the APIs from
++     * ARB_point_sprite are not supported anymore. */
++    if (!gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
++        gl_info->supported[ARB_POINT_SPRITE] = FALSE;
++
++    if (gl_info->supported[APPLE_FENCE])
++    {
++        /* GL_NV_fence and GL_APPLE_fence provide the same functionality basically.
++         * The apple extension interacts with some other apple exts. Disable the NV
++         * extension if the apple one is support to prevent confusion in other parts
++         * of the code. */
++        gl_info->supported[NV_FENCE] = FALSE;
++    }
++    if (gl_info->supported[APPLE_FLOAT_PIXELS])
++    {
++        /* GL_APPLE_float_pixels == GL_ARB_texture_float + GL_ARB_half_float_pixel
++         *
++         * The enums are the same:
++         * GL_RGBA16F_ARB     = GL_RGBA_FLOAT16_APPLE = 0x881a
++         * GL_RGB16F_ARB      = GL_RGB_FLOAT16_APPLE  = 0x881b
++         * GL_RGBA32F_ARB     = GL_RGBA_FLOAT32_APPLE = 0x8814
++         * GL_RGB32F_ARB      = GL_RGB_FLOAT32_APPLE  = 0x8815
++         * GL_HALF_FLOAT_ARB  = GL_HALF_APPLE         = 0x140b
++         */
++        if (!gl_info->supported[ARB_TEXTURE_FLOAT])
++        {
++            TRACE(" IMPLIED: GL_ARB_texture_float support (by GL_APPLE_float_pixels).\n");
++            gl_info->supported[ARB_TEXTURE_FLOAT] = TRUE;
++        }
++        if (!gl_info->supported[ARB_HALF_FLOAT_PIXEL])
++        {
++            TRACE(" IMPLIED: GL_ARB_half_float_pixel support (by GL_APPLE_float_pixels).\n");
++            gl_info->supported[ARB_HALF_FLOAT_PIXEL] = TRUE;
++        }
++    }
++    if (gl_info->supported[ARB_MAP_BUFFER_RANGE])
++    {
++        /* GL_ARB_map_buffer_range and GL_APPLE_flush_buffer_range provide the same
++         * functionality. Prefer the ARB extension */
++        gl_info->supported[APPLE_FLUSH_BUFFER_RANGE] = FALSE;
++    }
++    if (gl_info->supported[ARB_TEXTURE_CUBE_MAP])
++    {
++        TRACE(" IMPLIED: NVIDIA (NV) Texture Gen Reflection support.\n");
++        gl_info->supported[NV_TEXGEN_REFLECTION] = TRUE;
++    }
++    if (!gl_info->supported[ARB_VERTEX_ARRAY_BGRA] && gl_info->supported[EXT_VERTEX_ARRAY_BGRA])
++    {
++        TRACE(" IMPLIED: ARB_vertex_array_bgra support (by EXT_vertex_array_bgra).\n");
++        gl_info->supported[ARB_VERTEX_ARRAY_BGRA] = TRUE;
++    }
++    if (!gl_info->supported[EXT_TEXTURE_COMPRESSION_RGTC] && gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC])
++    {
++        TRACE(" IMPLIED: EXT_texture_compression_rgtc support (by ARB_texture_compression_rgtc).\n");
++        gl_info->supported[EXT_TEXTURE_COMPRESSION_RGTC] = TRUE;
++    }
++    if (!gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] && gl_info->supported[EXT_TEXTURE_COMPRESSION_RGTC])
++    {
++        TRACE(" IMPLIED: ARB_texture_compression_rgtc support (by EXT_texture_compression_rgtc).\n");
++        gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] = TRUE;
++    }
++    if (gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] && !gl_info->supported[ARB_TEXTURE_RG])
++    {
++        TRACE("ARB_texture_rg not supported, disabling ARB_texture_compression_rgtc.\n");
++        gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] = FALSE;
++    }
++    if (gl_info->supported[NV_TEXTURE_SHADER2])
++    {
++        if (gl_info->supported[NV_REGISTER_COMBINERS])
++        {
++            /* Also disable ATI_FRAGMENT_SHADER if register combiners and texture_shader2
++             * are supported. The nv extensions provide the same functionality as the
++             * ATI one, and a bit more(signed pixelformats). */
++            gl_info->supported[ATI_FRAGMENT_SHADER] = FALSE;
++        }
++    }
++    if (gl_info->supported[ARB_TEXTURE_NON_POWER_OF_TWO])
++    {
++        /* If we have full NP2 texture support, disable
++         * GL_ARB_texture_rectangle because we will never use it.
++         * This saves a few redundant glDisable calls. */
++        gl_info->supported[ARB_TEXTURE_RECTANGLE] = FALSE;
++    }
++    if (gl_info->supported[ATI_FRAGMENT_SHADER])
++    {
++        /* Disable NV_register_combiners and fragment shader if this is supported.
++         * generally the NV extensions are preferred over the ATI ones, and this
++         * extension is disabled if register_combiners and texture_shader2 are both
++         * supported. So we reach this place only if we have incomplete NV dxlevel 8
++         * fragment processing support. */
++        gl_info->supported[NV_REGISTER_COMBINERS] = FALSE;
++        gl_info->supported[NV_REGISTER_COMBINERS2] = FALSE;
++        gl_info->supported[NV_TEXTURE_SHADER] = FALSE;
++        gl_info->supported[NV_TEXTURE_SHADER2] = FALSE;
++    }
++    if (gl_info->supported[NV_HALF_FLOAT])
++    {
++        /* GL_ARB_half_float_vertex is a subset of GL_NV_half_float. */
++        gl_info->supported[ARB_HALF_FLOAT_VERTEX] = TRUE;
++    }
++    if (gl_info->supported[ARB_FRAMEBUFFER_SRGB] && !gl_info->supported[EXT_TEXTURE_SRGB_DECODE])
++    {
++        /* Current wined3d sRGB infrastructure requires EXT_texture_sRGB_decode
++         * for GL_ARB_framebuffer_sRGB support (without EXT_texture_sRGB_decode
++         * we never render to sRGB surfaces). */
++        TRACE("EXT_texture_sRGB_decode is not supported, disabling ARB_framebuffer_sRGB.\n");
++        gl_info->supported[ARB_FRAMEBUFFER_SRGB] = FALSE;
++    }
++    if (gl_info->supported[ARB_OCCLUSION_QUERY])
++    {
++        GLint counter_bits;
++
++        GL_EXTCALL(glGetQueryiv(GL_SAMPLES_PASSED, GL_QUERY_COUNTER_BITS, &counter_bits));
++        TRACE("Occlusion query counter has %d bits.\n", counter_bits);
++        if (!counter_bits)
++            gl_info->supported[ARB_OCCLUSION_QUERY] = FALSE;
++    }
++    if (gl_info->supported[ARB_TIMER_QUERY])
++    {
++        GLint counter_bits;
++
++        GL_EXTCALL(glGetQueryiv(GL_TIMESTAMP, GL_QUERY_COUNTER_BITS, &counter_bits));
++        TRACE("Timestamp query counter has %d bits.\n", counter_bits);
++        if (!counter_bits)
++            gl_info->supported[ARB_TIMER_QUERY] = FALSE;
++    }
++    if (gl_version >= MAKEDWORD_VERSION(3, 0))
++    {
++        GLint counter_bits;
++
++        gl_info->supported[WINED3D_GL_PRIMITIVE_QUERY] = TRUE;
++
++        GL_EXTCALL(glGetQueryiv(GL_PRIMITIVES_GENERATED, GL_QUERY_COUNTER_BITS, &counter_bits));
++        TRACE("Primitives query counter has %d bits.\n", counter_bits);
++        if (!counter_bits)
++            gl_info->supported[WINED3D_GL_PRIMITIVE_QUERY] = FALSE;
++
++        GL_EXTCALL(glGetQueryiv(GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN, GL_QUERY_COUNTER_BITS, &counter_bits));
++        TRACE("Transform feedback primitives query counter has %d bits.\n", counter_bits);
++        if (!counter_bits)
++            gl_info->supported[WINED3D_GL_PRIMITIVE_QUERY] = FALSE;
++    }
++    if (gl_info->supported[ARB_VIEWPORT_ARRAY])
++    {
++        GLint subpixel_bits;
++
++        gl_info->gl_ops.gl.p_glGetIntegerv(GL_VIEWPORT_SUBPIXEL_BITS, &subpixel_bits);
++        TRACE("Viewport supports %d subpixel bits.\n", subpixel_bits);
++        if (subpixel_bits < 8 && gl_info->supported[ARB_CLIP_CONTROL])
++        {
++            TRACE("Disabling ARB_clip_control because viewport subpixel bits < 8.\n");
++            gl_info->supported[ARB_CLIP_CONTROL] = FALSE;
++        }
++    }
++    if (gl_info->supported[ARB_CLIP_CONTROL] && !gl_info->supported[ARB_VIEWPORT_ARRAY])
++    {
++        /* When using ARB_clip_control we need the float viewport parameters
++         * introduced by ARB_viewport_array to take care of the shifted pixel
++         * coordinates. */
++        TRACE("Disabling ARB_clip_control because ARB_viewport_array is not supported.\n");
++        gl_info->supported[ARB_CLIP_CONTROL] = FALSE;
++    }
++    if (gl_info->supported[ARB_STENCIL_TEXTURING] && !gl_info->supported[ARB_TEXTURE_SWIZZLE])
++    {
++        /* The stencil value needs to be placed in the green channel.  */
++        TRACE("Disabling ARB_stencil_texturing because ARB_texture_swizzle is not supported.\n");
++        gl_info->supported[ARB_STENCIL_TEXTURING] = FALSE;
++    }
++    if (!gl_info->supported[ATI_TEXTURE_MIRROR_ONCE] && gl_info->supported[EXT_TEXTURE_MIRROR_CLAMP])
++    {
++        TRACE(" IMPLIED: ATI_texture_mirror_once support (by EXT_texture_mirror_clamp).\n");
++        gl_info->supported[ATI_TEXTURE_MIRROR_ONCE] = TRUE;
++    }
++    if (!gl_info->supported[ARB_TEXTURE_MIRROR_CLAMP_TO_EDGE] && gl_info->supported[ATI_TEXTURE_MIRROR_ONCE])
++    {
++        TRACE(" IMPLIED: ARB_texture_mirror_clamp_to_edge support (by ATI_texture_mirror_once).\n");
++        gl_info->supported[ARB_TEXTURE_MIRROR_CLAMP_TO_EDGE] = TRUE;
++    }
++    if (gl_info->supported[ARB_TEXTURE_STORAGE] && gl_info->supported[APPLE_YCBCR_422])
++    {
++        /* AFAIK APPLE_ycbcr_422 is only available in legacy contexts so we shouldn't ever hit this. */
++        ERR("Disabling APPLE_ycbcr_422 because of ARB_texture_storage.\n");
++        gl_info->supported[APPLE_YCBCR_422] = FALSE;
++    }
++    if (gl_info->supported[ARB_DRAW_INDIRECT] && !gl_info->supported[ARB_BASE_INSTANCE])
++    {
++        /* If ARB_base_instance is not supported the baseInstance field
++         * in indirect draw parameters must be 0 or behavior is undefined.
++         */
++        WARN("Disabling ARB_draw_indirect because ARB_base_instance is not supported.\n");
++        gl_info->supported[ARB_DRAW_INDIRECT] = FALSE;
++    }
++    if (gl_info->supported[ARB_TEXTURE_MULTISAMPLE] && !wined3d_settings.multisample_textures)
++        gl_info->supported[ARB_TEXTURE_MULTISAMPLE] = FALSE;
++    if (gl_info->supported[ARB_TEXTURE_MULTISAMPLE] && !gl_info->supported[ARB_TEXTURE_STORAGE_MULTISAMPLE])
++    {
++        WARN("Disabling ARB_texture_multisample because immutable storage is not supported.\n");
++        gl_info->supported[ARB_TEXTURE_MULTISAMPLE] = FALSE;
++    }
++
++    wined3d_adapter_init_limits(gl_info);
++
++    if (gl_info->supported[ARB_VERTEX_PROGRAM] && test_arb_vs_offset_limit(gl_info))
++        gl_info->quirks |= WINED3D_QUIRK_ARB_VS_OFFSET_LIMIT;
++
++    if (gl_info->supported[ARB_SHADING_LANGUAGE_100])
++    {
++        const char *str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_SHADING_LANGUAGE_VERSION_ARB);
++        unsigned int major, minor;
++
++        TRACE("GLSL version string: %s.\n", debugstr_a(str));
++
++        /* The format of the GLSL version string is "major.minor[.release] [vendor info]". */
++        sscanf(str, "%u.%u", &major, &minor);
++        gl_info->glsl_version = MAKEDWORD_VERSION(major, minor);
++        if (gl_info->glsl_version >= MAKEDWORD_VERSION(1, 30))
++            gl_info->supported[WINED3D_GLSL_130] = TRUE;
++    }
++
++    checkGLcall("extension detection");
++
++    adapter->shader_backend = select_shader_backend(gl_info);
++    adapter->vertex_pipe = select_vertex_implementation(gl_info, adapter->shader_backend);
++    adapter->fragment_pipe = select_fragment_implementation(gl_info, adapter->shader_backend);
++
++    adapter->shader_backend->shader_get_caps(gl_info, &shader_caps);
++    d3d_info->vs_clipping = shader_caps.wined3d_caps & WINED3D_SHADER_CAP_VS_CLIPPING;
++    d3d_info->limits.vs_version = shader_caps.vs_version;
++    d3d_info->limits.hs_version = shader_caps.hs_version;
++    d3d_info->limits.ds_version = shader_caps.ds_version;
++    d3d_info->limits.gs_version = shader_caps.gs_version;
++    d3d_info->limits.ps_version = shader_caps.ps_version;
++    d3d_info->limits.cs_version = shader_caps.cs_version;
++    d3d_info->limits.vs_uniform_count = shader_caps.vs_uniform_count;
++    d3d_info->limits.ps_uniform_count = shader_caps.ps_uniform_count;
++    d3d_info->limits.varying_count = shader_caps.varying_count;
++    d3d_info->shader_double_precision = shader_caps.wined3d_caps & WINED3D_SHADER_CAP_DOUBLE_PRECISION;
++
++    adapter->vertex_pipe->vp_get_caps(gl_info, &vertex_caps);
++    d3d_info->xyzrhw = vertex_caps.xyzrhw;
++    d3d_info->ffp_generic_attributes = vertex_caps.ffp_generic_attributes;
++    d3d_info->limits.ffp_vertex_blend_matrices = vertex_caps.max_vertex_blend_matrices;
++    d3d_info->limits.active_light_count = vertex_caps.max_active_lights;
++    d3d_info->emulated_flatshading = vertex_caps.emulated_flatshading;
++
++    adapter->fragment_pipe->get_caps(gl_info, &fragment_caps);
++    d3d_info->limits.ffp_blend_stages = fragment_caps.MaxTextureBlendStages;
++    d3d_info->limits.ffp_textures = fragment_caps.MaxSimultaneousTextures;
++    d3d_info->shader_color_key = fragment_caps.wined3d_caps & WINED3D_FRAGMENT_CAP_COLOR_KEY;
++    d3d_info->wined3d_creation_flags = wined3d_creation_flags;
++    d3d_info->feature_level = feature_level_from_caps(gl_info, &shader_caps, &fragment_caps);
++
++    TRACE("Max texture stages: %u.\n", d3d_info->limits.ffp_blend_stages);
++
++    d3d_info->valid_rt_mask = 0;
++    for (i = 0; i < gl_info->limits.buffers; ++i)
++        d3d_info->valid_rt_mask |= (1u << i);
++
++    if (!d3d_info->shader_color_key)
+     {
+diff --git a/dlls/wined3d/query.c b/dlls/wined3d/query.c
+index 4239fc08b3d..cefdedee4f1 100644
+--- a/dlls/wined3d/query.c
++++ b/dlls/wined3d/query.c
+@@ -181,3 +181,3 @@ static BOOL wined3d_fence_supported(const struct wined3d_gl_info *gl_info)
+ 
+-static enum wined3d_fence_result wined3d_fence_test(const struct wined3d_fence *fence,
++enum wined3d_fence_result wined3d_fence_test(const struct wined3d_fence *fence,
+         const struct wined3d_device *device, DWORD flags)
+diff --git a/dlls/wined3d/wined3d_private.h b/dlls/wined3d/wined3d_private.h
+index e4cd7d39984..a88a2345619 100644
+--- a/dlls/wined3d/wined3d_private.h
++++ b/dlls/wined3d/wined3d_private.h
+@@ -1709,2 +1709,5 @@ enum wined3d_fence_result wined3d_fence_wait(const struct wined3d_fence *fence,
+         const struct wined3d_device *device) DECLSPEC_HIDDEN;
++// XXX(acomminos): really expose this?
++enum wined3d_fence_result wined3d_fence_test(const struct wined3d_fence *fence,
++        const struct wined3d_device *device, DWORD flags) DECLSPEC_HIDDEN;
+ 
+@@ -3041,2 +3044,6 @@ struct wined3d_device
+     UINT context_count;
++
++    /* Dynamic buffer heap */
++    struct wined3d_buffer_heap *wo_buffer_heap;
++    struct wined3d_buffer_heap *cb_buffer_heap;
+ };
+@@ -3583,2 +3590,8 @@ void state_unbind_resources(struct wined3d_state *state) DECLSPEC_HIDDEN;
+ 
++struct wined3d_map_range
++{
++    GLintptr offset;
++    GLsizeiptr size;
++};
++
+ enum wined3d_cs_queue_id
+@@ -3760,8 +3773,57 @@ enum wined3d_buffer_conversion_type
+ 
+-struct wined3d_map_range
++struct wined3d_buffer_heap_element;
++struct wined3d_buffer_heap_fenced_element;
++
++// Number of power-of-two buckets to populate.
++#define WINED3D_BUFFER_HEAP_BINS 32
++
++struct wined3d_buffer_heap_bin
+ {
+-    UINT offset;
+-    UINT size;
++    struct wined3d_buffer_heap_element *head;
++    struct wined3d_buffer_heap_element *tail;
++};
++
++struct wined3d_buffer_heap_bin_set
++{
++    struct wined3d_buffer_heap_bin bins[WINED3D_BUFFER_HEAP_BINS];
+ };
+ 
++// A heap that manages allocations with a single GL buffer.
++struct wined3d_buffer_heap
++{
++    GLuint buffer_object;
++    void *map_ptr;
++    GLsizeiptr alignment;
++    CRITICAL_SECTION temp_lock; // Temporary lock while we implement the fenced free list.
++
++    struct wined3d_buffer_heap_bin_set free_list;
++
++    // Elements that need to be fenced, but haven't reached the required size.
++    struct wined3d_buffer_heap_bin_set pending_fenced_bins;
++
++    // List of sets of buffers behind a common fence, in FIFO order.
++    struct wined3d_buffer_heap_fenced_element *fenced_head;
++    struct wined3d_buffer_heap_fenced_element *fenced_tail;
++};
++
++HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr size, GLsizeiptr alignment, BOOL write_only, struct wined3d_buffer_heap **heap) DECLSPEC_HIDDEN;
++HRESULT wined3d_buffer_heap_destroy(struct wined3d_buffer_heap *heap, struct wined3d_context *context) DECLSPEC_HIDDEN;
++// Fetches a buffer from the heap of at least the given size.
++// Attempts to coalesce blocks under memory pressure.
++HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr size, struct wined3d_map_range* out_range) DECLSPEC_HIDDEN;
++// Immediately frees a heap-allocated buffer segment.
++HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3d_map_range range) DECLSPEC_HIDDEN;
++// Enqueues a buffer segment to return to the heap once its fence has been signaled.
++HRESULT wined3d_buffer_heap_free_fenced(struct wined3d_buffer_heap *heap, struct wined3d_device *device, struct wined3d_map_range range) DECLSPEC_HIDDEN;
++// Issues a fence for the current set of pending fenced buffers.
++// Double-buffered: if the last fence issued has not yet been triggered, waits
++// on it.
++HRESULT wined3d_buffer_heap_cs_fence_issue(struct wined3d_buffer_heap *heap, struct wined3d_device *device) DECLSPEC_HIDDEN;
++// Waits on the next issued fence in FIFO order. Frees the fenced buffers after
++// the fence has been triggered.
++HRESULT wined3d_buffer_heap_cs_fence_wait(struct wined3d_buffer_heap *heap, struct wined3d_device *device) DECLSPEC_HIDDEN;
++// Performs deferred coalescing of buffers. To be called under memory pressure.
++// Outputs the number of coalesced regions in `num_coalesced`.
++HRESULT wined3d_buffer_heap_deferred_coalesce(struct wined3d_buffer_heap *heap, int *num_coalesced) DECLSPEC_HIDDEN;
++
+ struct wined3d_buffer
+-- 
+2.19.1
+
diff --git a/patches/0002-wined3d-Add-support-for-backing-dynamic-wined3d_buff.patch b/patches/0002-wined3d-Add-support-for-backing-dynamic-wined3d_buff.patch
new file mode 100644
index 000000000..43253bfd8
--- /dev/null
+++ b/patches/0002-wined3d-Add-support-for-backing-dynamic-wined3d_buff.patch
@@ -0,0 +1,533 @@
+From 147481495d9dee2df168bbe089b1edc9259bfa72 Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Mon, 5 Mar 2018 15:39:11 -0800
+Subject: [PATCH 02/11] wined3d: Add support for backing dynamic wined3d_buffer
+ objects by a persistent map.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer.c          | 221 ++++++++++++++++++++++++++++++++-
+ dlls/wined3d/context.c         |   6 +-
+ dlls/wined3d/cs.c              |  60 ++++++++-
+ dlls/wined3d/resource.c        |  18 ++-
+ dlls/wined3d/state.c           |  18 ++-
+ dlls/wined3d/texture.c         |  13 ++
+ dlls/wined3d/utils.c           |   1 +
+ dlls/wined3d/wined3d_private.h |  11 ++
+ 8 files changed, 337 insertions(+), 11 deletions(-)
+
+diff --git a/dlls/wined3d/buffer.c b/dlls/wined3d/buffer.c
+index 58e56857b4c..ef11f0eaa18 100644
+--- a/dlls/wined3d/buffer.c
++++ b/dlls/wined3d/buffer.c
+@@ -30,2 +30,3 @@
+ WINE_DEFAULT_DEBUG_CHANNEL(d3d);
++WINE_DECLARE_DEBUG_CHANNEL(d3d_perf);
+ 
+@@ -36,2 +37,3 @@ WINE_DEFAULT_DEBUG_CHANNEL(d3d);
+ #define WINED3D_BUFFER_APPLESYNC    0x10    /* Using sync as in GL_APPLE_flush_buffer_range. */
++#define WINED3D_BUFFER_PERSISTENT   0x20    /* Uses a persistent-mapped buffer via ARB_buffer_storage. */
+ 
+@@ -274,2 +276,49 @@ fail:
+ 
++/* Context activation is done by the caller. */
++static BOOL buffer_alloc_persistent_map(struct wined3d_buffer *buffer, struct wined3d_context *context)
++{
++    struct wined3d_resource *resource = &buffer->resource;
++    struct wined3d_device *device = resource->device;
++    struct wined3d_buffer_heap *heap;
++    struct wined3d_map_range map_range;
++    HRESULT hr;
++
++    if (resource->bind_flags & WINED3D_BIND_CONSTANT_BUFFER)
++    {
++        // Use a heap aligned to constant buffer offset requirements.
++        heap = device->cb_buffer_heap;
++    }
++    else
++    {
++        if (!(resource->usage & WINED3DUSAGE_WRITEONLY))
++            FIXME("Using a write-only persistent buffer for %p without WINED3DUSAGE_WRITEONLY.\n", buffer);
++        heap = device->wo_buffer_heap;
++    }
++
++    buffer->buffer_heap = heap;
++    if (FAILED(hr = wined3d_buffer_heap_alloc(heap, resource->size, &map_range)))
++    {
++        goto fail;
++    }
++    buffer->cs_persistent_map = map_range;
++    buffer->mt_persistent_map = map_range;
++    return TRUE;
++
++fail:
++    // FIXME(acomminos): fall back to standalone BO here?
++    ERR("Failed to create persistent map for buffer %p, hr=%x\n", buffer, hr);
++    buffer->buffer_heap = NULL;
++    return FALSE;
++}
++
++static void buffer_free_persistent_map(struct wined3d_buffer *buffer)
++{
++    if (!buffer->buffer_heap)
++        return;
++
++    // TODO(acomminos): get the CS thread to free pending main thread buffers.
++    wined3d_buffer_heap_free(buffer->buffer_heap, buffer->cs_persistent_map);
++    buffer->buffer_heap = NULL;
++}
++
+ static BOOL buffer_process_converted_attribute(struct wined3d_buffer *buffer,
+@@ -635,2 +683,13 @@ static BOOL wined3d_buffer_prepare_location(struct wined3d_buffer *buffer,
+ 
++        case WINED3D_LOCATION_PERSISTENT_MAP:
++            if (buffer->buffer_heap)
++                return TRUE;
++
++            if (!(buffer->flags & WINED3D_BUFFER_PERSISTENT))
++            {
++                WARN("Trying to map a persistent region for buffer %p without WINED3D_BUFFER_PERSISTENT.\n", buffer);
++                return FALSE;
++            }
++            return buffer_alloc_persistent_map(buffer, context);
++
+         default:
+@@ -693,2 +752,12 @@ BOOL wined3d_buffer_load_location(struct wined3d_buffer *buffer,
+ 
++        case WINED3D_LOCATION_PERSISTENT_MAP:
++            // TODO(acomminos): are we guaranteed location_sysmem to be kept?
++            // no.
++            if (buffer->conversion_map)
++                FIXME("Attempting to use conversion map with persistent mapping.\n");
++            memcpy(buffer->buffer_heap->map_ptr +
++                   buffer->cs_persistent_map.offset,
++                   buffer->resource.heap_memory, buffer->resource.size);
++            break;
++
+         default:
+@@ -699,3 +768,4 @@ BOOL wined3d_buffer_load_location(struct wined3d_buffer *buffer,
+     wined3d_buffer_validate_location(buffer, location);
+-    if (buffer->resource.heap_memory && location == WINED3D_LOCATION_BUFFER
++    if (buffer->resource.heap_memory
++            && location & WINED3D_LOCATION_BUFFER
+             && !(buffer->resource.usage & WINED3DUSAGE_DYNAMIC))
+@@ -703,2 +773,7 @@ BOOL wined3d_buffer_load_location(struct wined3d_buffer *buffer,
+ 
++    // FIXME(acomminos)
++    if (buffer->resource.heap_memory
++           && location & WINED3D_LOCATION_PERSISTENT_MAP)
++        wined3d_buffer_evict_sysmem(buffer);
++
+     return TRUE;
+@@ -724,4 +799,16 @@ DWORD wined3d_buffer_get_memory(struct wined3d_buffer *buffer,
+         data->addr = NULL;
++        data->length = buffer->resource.size;
+         return WINED3D_LOCATION_BUFFER;
+     }
++    if (locations & WINED3D_LOCATION_PERSISTENT_MAP)
++    {
++        // FIXME(acomminos): should we expose a buffer object we don't wholly own here?
++        data->buffer_object = buffer->buffer_heap->buffer_object;
++        data->addr = buffer->cs_persistent_map.offset;
++        // Note that the size of the underlying buffer allocation may be larger
++        // than the buffer knows about. In this case, we've rounded it up to be
++        // aligned (e.g. for uniform buffer offsets).
++        data->length = buffer->cs_persistent_map.size;
++        return WINED3D_LOCATION_PERSISTENT_MAP;
++    }
+     if (locations & WINED3D_LOCATION_SYSMEM)
+@@ -730,2 +817,3 @@ DWORD wined3d_buffer_get_memory(struct wined3d_buffer *buffer,
+         data->addr = buffer->resource.heap_memory;
++        data->length = buffer->resource.size;
+         return WINED3D_LOCATION_SYSMEM;
+@@ -765,2 +853,4 @@ static void buffer_unload(struct wined3d_resource *resource)
+ 
++    buffer_free_persistent_map(buffer);
++
+     resource_unload(resource);
+@@ -788,2 +878,6 @@ static void wined3d_buffer_gl_destroy_object(void *object)
+ 
++    struct wined3d_buffer *buffer;
++    buffer = &buffer_gl->b;
++    buffer_free_persistent_map(buffer);
++
+     heap_free(buffer_gl->b.maps);
+@@ -907,2 +999,12 @@ void wined3d_buffer_load(struct wined3d_buffer *buffer, struct wined3d_context *
+ 
++    if (buffer->flags & WINED3D_BUFFER_PERSISTENT)
++    {
++        if (wined3d_buffer_load_location(buffer, context, WINED3D_LOCATION_PERSISTENT_MAP))
++            return;
++
++        ERR("Failed to preload persistent mapping for %p, falling back to BO.\n", buffer);
++        buffer->flags |= WINED3D_BUFFER_USE_BO;
++        buffer->flags &= ~WINED3D_BUFFER_PERSISTENT;
++    }
++
+     /* TODO: Make converting independent from VBOs */
+@@ -1018,2 +1120,21 @@ static HRESULT wined3d_buffer_gl_map(struct wined3d_buffer_gl *buffer_gl,
+ 
++    if (buffer_gl->b.locations & WINED3D_LOCATION_PERSISTENT_MAP)
++    {
++        const struct wined3d_gl_info *gl_info;
++        context = context_acquire(device, NULL, 0);
++
++        FIXME_(d3d_perf)("Fences not used for persistent buffer maps on CS thread, using glFinish.\n");
++
++        gl_info = context->gl_info;
++        gl_info->gl_ops.gl.p_glFinish();
++
++        base = buffer_gl->b.buffer_heap->map_ptr
++             + buffer_gl->b.cs_persistent_map.offset;
++        *data = base + offset;
++
++        context_release(context);
++
++        return WINED3D_OK;
++    }
++
+     if (buffer_gl->buffer_object)
+@@ -1160,2 +1281,8 @@ static void wined3d_buffer_gl_unmap(struct wined3d_buffer_gl *buffer_gl)
+ 
++    if (buffer_gl->b.flags & WINED3D_BUFFER_PERSISTENT)
++    {
++        TRACE("Persistent buffer, ignore unmap.\n");
++        return;
++    }
++
+     if (buffer_gl->b.map_ptr)
+@@ -1284,2 +1411,61 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+         struct wined3d_map_desc *map_desc, const struct wined3d_box *box, DWORD flags)
++{
++    struct wined3d_buffer_gl *buffer_gl = wined3d_buffer_gl(buffer_from_resource(resource));
++    struct wined3d_buffer *buffer = &(buffer_gl->b);
++    UINT offset = box ? box->left : 0;
++
++    if (sub_resource_idx)
++    {
++        WARN("Invalid sub_resource_idx %u.\n", sub_resource_idx);
++        return E_INVALIDARG;
++    }
++
++    // Support immediate mapping of persistent buffers off the command thread,
++    // which require no GL calls to interface with.
++    if (buffer->locations & WINED3D_LOCATION_PERSISTENT_MAP)
++    {
++        map_desc->row_pitch = map_desc->slice_pitch = resource->size;
++        if (flags & WINED3D_MAP_DISCARD)
++        {
++            HRESULT hr;
++            struct wined3d_map_range map_range;
++            if (FAILED(hr = wined3d_buffer_heap_alloc(buffer->buffer_heap, resource->size, &map_range)))
++            {
++                FIXME_(d3d_perf)("Failed to allocate new buffer, falling back to sync path.\n");
++                return hr;
++            }
++            map_desc->data = buffer->buffer_heap->map_ptr + map_range.offset + offset;
++            resource->map_count++;
++
++            buffer->mt_persistent_map = map_range;
++
++            // Discard handler on CSMT thread is responsible for returning the
++            // currently used buffer to the free pool, along with the fence that
++            // must be called before the buffer can be reused.
++            wined3d_cs_emit_discard_buffer(resource->device->cs, buffer, map_range);
++            return WINED3D_OK;
++        }
++        else if (flags & WINED3D_MAP_NOOVERWRITE)
++        {
++            // Allow immediate access for persistent buffers without a fence.
++            // Always use the latest buffer in this case in case the latest
++            // DISCARDed one hasn't reached the command stream yet.
++            struct wined3d_map_range map_range = buffer->mt_persistent_map;
++            map_desc->data = buffer->buffer_heap->map_ptr + map_range.offset + offset;
++            resource->map_count++;
++            return WINED3D_OK;
++        }
++        else
++        {
++            // TODO(acomminos): Should check mapped ranges to see if the region is writeable even though NOOVERWRITE is specified.
++            WARN_(d3d_perf)("Mapping persistent buffer %p in sync with CS thread.\n", buffer);
++            // XXX(acomminos): kill this early return. they're the worst.
++        }
++    }
++
++    return E_NOTIMPL;
++}
++
++static HRESULT buffer_resource_sub_resource_map_cs(struct wined3d_resource *resource, unsigned int sub_resource_idx,
++        struct wined3d_map_desc *map_desc, const struct wined3d_box *box, DWORD flags)
+ {
+@@ -1309,2 +1494,14 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+ static HRESULT buffer_resource_sub_resource_unmap(struct wined3d_resource *resource, unsigned int sub_resource_idx)
++{
++    struct wined3d_buffer *buffer = buffer_from_resource(resource);
++    if (buffer->locations & WINED3D_LOCATION_PERSISTENT_MAP)
++    {
++        // Nothing to be done to unmap a region of a persistent buffer.
++        resource->map_count--;
++        return WINED3D_OK;
++    }
++    return E_NOTIMPL;
++}
++
++static HRESULT buffer_resource_sub_resource_unmap_cs(struct wined3d_resource *resource, unsigned int sub_resource_idx)
+ {
+@@ -1328,2 +1525,4 @@ static const struct wined3d_resource_ops buffer_resource_ops =
+     buffer_resource_sub_resource_unmap,
++    buffer_resource_sub_resource_map_cs,
++    buffer_resource_sub_resource_unmap_cs,
+ };
+@@ -1406,2 +1605,16 @@ static HRESULT wined3d_buffer_init(struct wined3d_buffer *buffer, struct wined3d
+ 
++    if (buffer->resource.usage & WINED3DUSAGE_DYNAMIC)
++    {
++        if (!gl_info->supported[ARB_BUFFER_STORAGE])
++        {
++            WARN_(d3d_perf)("Not creating a persistent mapping for a dynamic buffer because ARB_buffer_storage is unsupported.\n");
++        }
++        else
++        {
++            // If supported, use persistent mapped buffers instead of a
++            // standalone BO for dynamic buffers.
++            buffer->flags |= WINED3D_BUFFER_PERSISTENT;
++        }
++    }
++
+     /* Observations show that draw_primitive_immediate_mode() is faster on
+@@ -1411,3 +1624,7 @@ static HRESULT wined3d_buffer_init(struct wined3d_buffer *buffer, struct wined3d
+ 
+-    if (!gl_info->supported[ARB_VERTEX_BUFFER_OBJECT])
++    if (buffer->flags & WINED3D_BUFFER_PERSISTENT)
++    {
++        TRACE("Not creating a BO because a persistent mapped buffer will be used.\n");
++    }
++    else if (!gl_info->supported[ARB_VERTEX_BUFFER_OBJECT])
+     {
+diff --git a/dlls/wined3d/context.c b/dlls/wined3d/context.c
+index 9027e94ed09..27f173b4e10 100644
+--- a/dlls/wined3d/context.c
++++ b/dlls/wined3d/context.c
+@@ -4905,3 +4905,7 @@ void draw_primitive(struct wined3d_device *device, const struct wined3d_state *s
+         struct wined3d_buffer *index_buffer = state->index_buffer;
+-        if (!wined3d_buffer_gl(index_buffer)->buffer_object || !stream_info->all_vbo)
++        if (index_buffer->locations & WINED3D_LOCATION_PERSISTENT_MAP)
++        {
++            idx_data = index_buffer->cs_persistent_map.offset;
++        }
++        else if (!wined3d_buffer_gl(index_buffer)->buffer_object || !stream_info->all_vbo)
+         {
+diff --git a/dlls/wined3d/cs.c b/dlls/wined3d/cs.c
+index ac9adb03fa9..0f5dd607c95 100644
+--- a/dlls/wined3d/cs.c
++++ b/dlls/wined3d/cs.c
+@@ -75,2 +75,3 @@ enum wined3d_cs_op
+     WINED3D_CS_OP_GENERATE_MIPMAPS,
++    WINED3D_CS_OP_DISCARD_BUFFER,
+     WINED3D_CS_OP_STOP,
+@@ -441,2 +442,9 @@ struct wined3d_cs_generate_mipmaps
+ 
++struct wined3d_cs_discard_buffer
++{
++    enum wined3d_cs_op opcode;
++    struct wined3d_buffer *buffer;
++    struct wined3d_map_range map_range;
++};
++
+ struct wined3d_cs_stop
+@@ -2105,3 +2113,3 @@ static void wined3d_cs_exec_map(struct wined3d_cs *cs, const void *data)
+ 
+-    *op->hr = resource->resource_ops->resource_sub_resource_map(resource,
++    *op->hr = resource->resource_ops->resource_sub_resource_map_cs(resource,
+             op->sub_resource_idx, op->map_desc, op->box, op->flags);
+@@ -2139,3 +2147,3 @@ static void wined3d_cs_exec_unmap(struct wined3d_cs *cs, const void *data)
+ 
+-    *op->hr = resource->resource_ops->resource_sub_resource_unmap(resource, op->sub_resource_idx);
++    *op->hr = resource->resource_ops->resource_sub_resource_unmap_cs(resource, op->sub_resource_idx);
+ }
+@@ -2489,2 +2497,49 @@ void wined3d_cs_emit_generate_mipmaps(struct wined3d_cs *cs, struct wined3d_shad
+ 
++static void wined3d_cs_exec_discard_buffer(struct wined3d_cs *cs, const void *data)
++{
++    const struct wined3d_cs_discard_buffer *op = data;
++    struct wined3d_buffer *buffer = op->buffer;
++    HRESULT hr;
++
++    // TODO(acomminos): should call into buffer.c here instead.
++    if (FAILED(hr = wined3d_buffer_heap_free_fenced(buffer->buffer_heap, cs->device, buffer->cs_persistent_map)))
++    {
++        ERR("Failed to do a fenced free on discarded buffer %p, hr %x\n. Freeing anyway.", buffer, hr);
++        wined3d_buffer_heap_free(buffer->buffer_heap, buffer->cs_persistent_map);
++    }
++
++    buffer->cs_persistent_map = op->map_range;
++
++    // TODO(acomminos): merge this logic with buffer.c functions for standalone BOs
++    if (buffer->resource.bind_flags & WINED3D_BIND_VERTEX_BUFFER)
++        device_invalidate_state(cs->device, STATE_STREAMSRC);
++    if (buffer->resource.bind_flags & WINED3D_BIND_INDEX_BUFFER)
++        device_invalidate_state(cs->device, STATE_INDEXBUFFER);
++    if (buffer->resource.bind_flags & WINED3D_BIND_CONSTANT_BUFFER)
++    {
++        device_invalidate_state(cs->device, STATE_CONSTANT_BUFFER(WINED3D_SHADER_TYPE_VERTEX));
++        device_invalidate_state(cs->device, STATE_CONSTANT_BUFFER(WINED3D_SHADER_TYPE_HULL));
++        device_invalidate_state(cs->device, STATE_CONSTANT_BUFFER(WINED3D_SHADER_TYPE_DOMAIN));
++        device_invalidate_state(cs->device, STATE_CONSTANT_BUFFER(WINED3D_SHADER_TYPE_GEOMETRY));
++        device_invalidate_state(cs->device, STATE_CONSTANT_BUFFER(WINED3D_SHADER_TYPE_PIXEL));
++        device_invalidate_state(cs->device, STATE_CONSTANT_BUFFER(WINED3D_SHADER_TYPE_COMPUTE));
++    }
++
++    wined3d_resource_release(&op->buffer->resource);
++}
++
++void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer *buffer, struct wined3d_map_range map_range)
++{
++    struct wined3d_cs_discard_buffer *op;
++
++    op = cs->ops->require_space(cs, sizeof(*op), WINED3D_CS_QUEUE_DEFAULT);
++    op->opcode = WINED3D_CS_OP_DISCARD_BUFFER;
++    op->buffer = buffer;
++    op->map_range = map_range;
++
++    wined3d_resource_acquire(&buffer->resource);
++
++    cs->ops->submit(cs, WINED3D_CS_QUEUE_DEFAULT);
++}
++
+ static void wined3d_cs_emit_stop(struct wined3d_cs *cs)
+@@ -2549,2 +2604,3 @@ static void (* const wined3d_cs_op_handlers[])(struct wined3d_cs *cs, const void
+     /* WINED3D_CS_OP_GENERATE_MIPMAPS            */ wined3d_cs_exec_generate_mipmaps,
++    /* WINED3D_CS_OP_DISCARD_BUFFER              */ wined3d_cs_exec_discard_buffer,
+ };
+diff --git a/dlls/wined3d/resource.c b/dlls/wined3d/resource.c
+index 9df0a0923b2..528c5c19ceb 100644
+--- a/dlls/wined3d/resource.c
++++ b/dlls/wined3d/resource.c
+@@ -335,2 +335,3 @@ HRESULT CDECL wined3d_resource_map(struct wined3d_resource *resource, unsigned i
+ {
++    HRESULT hr;
+     TRACE("resource %p, sub_resource_idx %u, map_desc %p, box %s, flags %#x.\n",
+@@ -357,5 +358,10 @@ HRESULT CDECL wined3d_resource_map(struct wined3d_resource *resource, unsigned i
+     flags = wined3d_resource_sanitise_map_flags(resource, flags);
+-    wined3d_resource_wait_idle(resource);
++    if (FAILED(hr = resource->resource_ops->resource_sub_resource_map(resource, sub_resource_idx, map_desc, box, flags)))
++    {
++        TRACE_(d3d_perf)("Mapping resource %p on the command stream.\n", resource);
++        wined3d_resource_wait_idle(resource);
++        hr = wined3d_cs_map(resource->device->cs, resource, sub_resource_idx, map_desc, box, flags);
++    }
+ 
+-    return wined3d_cs_map(resource->device->cs, resource, sub_resource_idx, map_desc, box, flags);
++    return hr;
+ }
+@@ -364,5 +370,11 @@ HRESULT CDECL wined3d_resource_unmap(struct wined3d_resource *resource, unsigned
+ {
++    HRESULT hr;
+     TRACE("resource %p, sub_resource_idx %u.\n", resource, sub_resource_idx);
+ 
+-    return wined3d_cs_unmap(resource->device->cs, resource, sub_resource_idx);
++    if (FAILED(hr = resource->resource_ops->resource_sub_resource_unmap(resource, sub_resource_idx)))
++    {
++        TRACE_(d3d_perf)("Unmapping resource %p on the command stream.\n", resource);
++        hr = wined3d_cs_unmap(resource->device->cs, resource, sub_resource_idx);
++    }
++    return hr;
+ }
+diff --git a/dlls/wined3d/state.c b/dlls/wined3d/state.c
+index ab67c578901..3d2608d96f3 100644
+--- a/dlls/wined3d/state.c
++++ b/dlls/wined3d/state.c
+@@ -4325,3 +4325,7 @@ static void indexbuffer(struct wined3d_context *context, const struct wined3d_st
+         struct wined3d_buffer_gl *ib = wined3d_buffer_gl(state->index_buffer);
+-        GL_EXTCALL(glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, ib->buffer_object));
++        // FIXME(acomminos): disasterous.
++        if (ib->b.locations & WINED3D_LOCATION_PERSISTENT_MAP)
++            GL_EXTCALL(glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, ib->b.buffer_heap->buffer_object));
++        else
++            GL_EXTCALL(glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, ib->buffer_object));
+     }
+@@ -4413,2 +4417,3 @@ static void state_cb(struct wined3d_context *context, const struct wined3d_state
+     unsigned int i, base, count;
++    struct wined3d_bo_address bo_addr;
+ 
+@@ -4425,4 +4430,11 @@ static void state_cb(struct wined3d_context *context, const struct wined3d_state
+         buffer = state->cb[shader_type][i];
+-        GL_EXTCALL(glBindBufferBase(GL_UNIFORM_BUFFER, base + i,
+-                buffer ? wined3d_buffer_gl(buffer)->buffer_object : 0));
++        if (buffer)
++        {
++            wined3d_buffer_get_memory(buffer, &bo_addr, buffer->locations);
++            GL_EXTCALL(glBindBufferRange(GL_UNIFORM_BUFFER, base + i, bo_addr.buffer_object, bo_addr.addr, bo_addr.length));
++        }
++        else
++        {
++            GL_EXTCALL(glBindBufferBase(GL_UNIFORM_BUFFER, base + i, 0));
++        }
+     }
+diff --git a/dlls/wined3d/texture.c b/dlls/wined3d/texture.c
+index 42bae136a53..24f29ecfe83 100644
+--- a/dlls/wined3d/texture.c
++++ b/dlls/wined3d/texture.c
+@@ -2569,2 +2569,8 @@ static HRESULT texture_resource_sub_resource_map(struct wined3d_resource *resour
+         struct wined3d_map_desc *map_desc, const struct wined3d_box *box, DWORD flags)
++{
++    return E_NOTIMPL;
++}
++
++static HRESULT texture_resource_sub_resource_map_cs(struct wined3d_resource *resource, unsigned int sub_resource_idx,
++        struct wined3d_map_desc *map_desc, const struct wined3d_box *box, DWORD flags)
+ {
+@@ -2699,2 +2705,7 @@ static HRESULT texture_resource_sub_resource_map(struct wined3d_resource *resour
+ static HRESULT texture_resource_sub_resource_unmap(struct wined3d_resource *resource, unsigned int sub_resource_idx)
++{
++    return E_NOTIMPL;
++}
++
++static HRESULT texture_resource_sub_resource_unmap_cs(struct wined3d_resource *resource, unsigned int sub_resource_idx)
+ {
+@@ -2750,2 +2761,4 @@ static const struct wined3d_resource_ops texture_resource_ops =
+     texture_resource_sub_resource_unmap,
++    texture_resource_sub_resource_map_cs,
++    texture_resource_sub_resource_unmap_cs,
+ };
+diff --git a/dlls/wined3d/utils.c b/dlls/wined3d/utils.c
+index 6e60c5ae3db..257719570f4 100644
+--- a/dlls/wined3d/utils.c
++++ b/dlls/wined3d/utils.c
+@@ -6366,2 +6366,3 @@ const char *wined3d_debug_location(DWORD location)
+     LOCATION_TO_STR(WINED3D_LOCATION_RB_RESOLVED);
++    LOCATION_TO_STR(WINED3D_LOCATION_PERSISTENT_MAP);
+ #undef LOCATION_TO_STR
+diff --git a/dlls/wined3d/wined3d_private.h b/dlls/wined3d/wined3d_private.h
+index a88a2345619..2cf735e1486 100644
+--- a/dlls/wined3d/wined3d_private.h
++++ b/dlls/wined3d/wined3d_private.h
+@@ -1465,2 +1465,3 @@ struct wined3d_bo_address
+     BYTE *addr;
++    GLsizeiptr length;
+ };
+@@ -3104,2 +3105,5 @@ struct wined3d_resource_ops
+     HRESULT (*resource_sub_resource_unmap)(struct wined3d_resource *resource, unsigned int sub_resource_idx);
++    HRESULT (*resource_sub_resource_map_cs)(struct wined3d_resource *resource, unsigned int sub_resource_idx,
++            struct wined3d_map_desc *map_desc, const struct wined3d_box *box, DWORD flags);
++    HRESULT (*resource_sub_resource_unmap_cs)(struct wined3d_resource *resource, unsigned int sub_resource_idx);
+ };
+@@ -3438,2 +3442,3 @@ void wined3d_texture_gl_set_compatible_renderbuffer(struct wined3d_texture_gl *t
+ #define WINED3D_LOCATION_RB_RESOLVED    0x00000100
++#define WINED3D_LOCATION_PERSISTENT_MAP 0x00000200
+ 
+@@ -3740,2 +3745,3 @@ void wined3d_cs_emit_update_sub_resource(struct wined3d_cs *cs, struct wined3d_r
+         unsigned int slice_pitch) DECLSPEC_HIDDEN;
++void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer *buffer, struct wined3d_map_range map_range) DECLSPEC_HIDDEN;
+ void wined3d_cs_init_object(struct wined3d_cs *cs,
+@@ -3849,2 +3855,7 @@ struct wined3d_buffer
+     UINT conversion_stride;                                 /* 0 if no shifted conversion */
++
++    /* persistent mapped buffer */
++    struct wined3d_buffer_heap *buffer_heap;
++    struct wined3d_map_range cs_persistent_map;
++    struct wined3d_map_range mt_persistent_map; // TODO: make struct list?
+ };
+-- 
+2.19.1
+
diff --git a/patches/0003-wined3d-Use-ARB_multi_bind-to-speed-up-UBO-updates.patch b/patches/0003-wined3d-Use-ARB_multi_bind-to-speed-up-UBO-updates.patch
new file mode 100644
index 000000000..6841d8bcc
--- /dev/null
+++ b/patches/0003-wined3d-Use-ARB_multi_bind-to-speed-up-UBO-updates.patch
@@ -0,0 +1,117 @@
+From 01a900ee2aa41888a97cb9160917e11183a24068 Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Mon, 5 Mar 2018 20:28:34 -0800
+Subject: [PATCH 03/11] wined3d: Use ARB_multi_bind to speed up UBO updates.
+
+More frequent UBO remaps as a result of the persistent buffer allocator
+causes glBindBufferRange to be a bottleneck. Using ARB_multi_bind
+massively reduces state change overhead.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/adapter_gl.c |  4 ++++
+ dlls/wined3d/directx.c    |  3 +++
+ dlls/wined3d/state.c      | 46 +++++++++++++++++++++++++++++++++------
+ dlls/wined3d/wined3d_gl.h |  1 +
+ 4 files changed, 47 insertions(+), 7 deletions(-)
+
+diff --git a/dlls/wined3d/adapter_gl.c b/dlls/wined3d/adapter_gl.c
+index 99df19cc317..355f35e32f9 100644
+--- a/dlls/wined3d/adapter_gl.c
++++ b/dlls/wined3d/adapter_gl.c
+@@ -98,2 +98,3 @@ static const struct wined3d_extension_map gl_extension_map[] =
+     {"GL_ARB_map_buffer_range",             ARB_MAP_BUFFER_RANGE          },
++    {"GL_ARB_multi_bind",                   ARB_MULTI_BIND                },
+     {"GL_ARB_multisample",                  ARB_MULTISAMPLE               },
+@@ -2151,2 +2152,4 @@ static void load_gl_funcs(struct wined3d_gl_info *gl_info)
+     USE_GL_FUNC(glMapBufferRange)
++    /* GL_ARB_multi_bind */
++    USE_GL_FUNC(glBindBuffersRange)
+     /* GL_ARB_multisample */
+@@ -3329,2 +3332,3 @@ static BOOL wined3d_adapter_init_gl_caps(struct wined3d_adapter *adapter,
+         {ARB_QUERY_BUFFER_OBJECT,          MAKEDWORD_VERSION(4, 4)},
++        {ARB_MULTI_BIND,                   MAKEDWORD_VERSION(4, 4)},
+ 
+diff --git a/dlls/wined3d/directx.c b/dlls/wined3d/directx.c
+index 56aeb3171f9..391fafd1841 100644
+--- a/dlls/wined3d/directx.c
++++ b/dlls/wined3d/directx.c
+@@ -1688,2 +1688,4 @@ static void load_gl_funcs(struct wined3d_gl_info *gl_info)
+     USE_GL_FUNC(glMapBufferRange)
++    /* GL_ARB_multi_bind */
++    USE_GL_FUNC(glBindBuffersRange)
+     /* GL_ARB_multisample */
+@@ -2845,2 +2847,3 @@ static BOOL wined3d_adapter_init_gl_caps(struct wined3d_adapter *adapter,
+         {ARB_CLEAR_TEXTURE,                MAKEDWORD_VERSION(4, 4)},
++        {ARB_MULTI_BIND,                   MAKEDWORD_VERSION(4, 4)},
+ 
+diff --git a/dlls/wined3d/state.c b/dlls/wined3d/state.c
+index 3d2608d96f3..189c85a05d3 100644
+--- a/dlls/wined3d/state.c
++++ b/dlls/wined3d/state.c
+@@ -4427,15 +4427,47 @@ static void state_cb(struct wined3d_context *context, const struct wined3d_state
+     wined3d_gl_limits_get_uniform_block_range(&gl_info->limits, shader_type, &base, &count);
+-    for (i = 0; i < count; ++i)
++
++    if (gl_info->supported[ARB_MULTI_BIND])
+     {
+-        buffer = state->cb[shader_type][i];
+-        if (buffer)
++        GLuint buffer_objects[count];
++        GLsizeiptr buffer_offsets[count];
++        GLsizeiptr buffer_sizes[count];
++
++        for (i = 0; i < count; ++i)
+         {
+-            wined3d_buffer_get_memory(buffer, &bo_addr, buffer->locations);
+-            GL_EXTCALL(glBindBufferRange(GL_UNIFORM_BUFFER, base + i, bo_addr.buffer_object, bo_addr.addr, bo_addr.length));
++            buffer = state->cb[shader_type][i];
++            if (buffer)
++            {
++                wined3d_buffer_get_memory(buffer, &bo_addr, buffer->locations);
++                buffer_objects[i] = bo_addr.buffer_object;
++                buffer_offsets[i] = bo_addr.addr;
++                buffer_sizes[i] = bo_addr.length;
++            }
++            else
++            {
++                buffer_objects[i] = buffer_offsets[i] = 0;
++                // The ARB_multi_bind spec states that an error may be thrown if
++                // `size` is less than or equal to zero, Thus, we specify a size for
++                // unused buffers anyway.
++                buffer_sizes[i] = 1;
++            }
+         }
+-        else
++        GL_EXTCALL(glBindBuffersRange(GL_UNIFORM_BUFFER, base, count, buffer_objects, buffer_offsets, buffer_sizes));
++    }
++    else
++    {
++        for (i = 0; i < count; ++i)
+         {
+-            GL_EXTCALL(glBindBufferBase(GL_UNIFORM_BUFFER, base + i, 0));
++            buffer = state->cb[shader_type][i];
++            if (buffer)
++            {
++                wined3d_buffer_get_memory(buffer, &bo_addr, buffer->locations);
++                GL_EXTCALL(glBindBufferRange(GL_UNIFORM_BUFFER, base + i, bo_addr.buffer_object, bo_addr.addr, bo_addr.length));
++            }
++            else
++            {
++                GL_EXTCALL(glBindBufferBase(GL_UNIFORM_BUFFER, base + i, 0));
++            }
+         }
+     }
++
+     checkGLcall("bind constant buffers");
+diff --git a/dlls/wined3d/wined3d_gl.h b/dlls/wined3d/wined3d_gl.h
+index a02073c28af..11f380ceb4d 100644
+--- a/dlls/wined3d/wined3d_gl.h
++++ b/dlls/wined3d/wined3d_gl.h
+@@ -84,2 +84,3 @@ enum wined3d_gl_extension
+     ARB_MAP_BUFFER_RANGE,
++    ARB_MULTI_BIND,
+     ARB_MULTISAMPLE,
+-- 
+2.19.1
+
diff --git a/patches/0004-wined3d-Use-GL_CLIENT_STORAGE_BIT-for-persistent-map.patch b/patches/0004-wined3d-Use-GL_CLIENT_STORAGE_BIT-for-persistent-map.patch
new file mode 100644
index 000000000..d783c1ec9
--- /dev/null
+++ b/patches/0004-wined3d-Use-GL_CLIENT_STORAGE_BIT-for-persistent-map.patch
@@ -0,0 +1,23 @@
+From 9eccd01e1dbcfd6ddcc56e15248f517ad87c3332 Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Tue, 6 Mar 2018 02:07:31 -0800
+Subject: [PATCH 04/11] wined3d: Use GL_CLIENT_STORAGE_BIT for persistent
+ mappings.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer_heap.c | 2 +-
+ 1 file changed, 1 insertion(+), 1 deletion(-)
+
+diff --git a/dlls/wined3d/buffer_heap.c b/dlls/wined3d/buffer_heap.c
+index b133bd68933..75f84b00882 100644
+--- a/dlls/wined3d/buffer_heap.c
++++ b/dlls/wined3d/buffer_heap.c
+@@ -171,3 +171,3 @@ HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr s
+     }
+-    storage_flags = access_flags;
++    storage_flags = GL_CLIENT_STORAGE_BIT | access_flags;
+ 
+-- 
+2.19.1
+
diff --git a/patches/0005-wined3d-Disable-persistently-mapped-shader-resource-.patch b/patches/0005-wined3d-Disable-persistently-mapped-shader-resource-.patch
new file mode 100644
index 000000000..77cf90626
--- /dev/null
+++ b/patches/0005-wined3d-Disable-persistently-mapped-shader-resource-.patch
@@ -0,0 +1,27 @@
+From b85a31ce783312ad33023f466a7b84d6291367fc Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Thu, 8 Mar 2018 22:00:33 -0800
+Subject: [PATCH 05/11] wined3d: Disable persistently mapped shader resource
+ buffers.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer.c | 4 ++++
+ 1 file changed, 4 insertions(+)
+
+diff --git a/dlls/wined3d/buffer.c b/dlls/wined3d/buffer.c
+index ef11f0eaa18..7d83c943464 100644
+--- a/dlls/wined3d/buffer.c
++++ b/dlls/wined3d/buffer.c
+@@ -1611,4 +1611,8 @@ static HRESULT wined3d_buffer_init(struct wined3d_buffer *buffer, struct wined3d
+         {
+             WARN_(d3d_perf)("Not creating a persistent mapping for a dynamic buffer because ARB_buffer_storage is unsupported.\n");
+         }
++        else if (desc->bind_flags & WINED3D_BIND_SHADER_RESOURCE)
++        {
++            FIXME_(d3d_perf)("Not using a persistent mapping for shader resource buffer %p (unimplemented)\n", buffer);
++        }
+         else
+-- 
+2.19.1
+
diff --git a/patches/0006-wined3d-Perform-initial-allocation-of-persistent-buf.patch b/patches/0006-wined3d-Perform-initial-allocation-of-persistent-buf.patch
new file mode 100644
index 000000000..b95eda054
--- /dev/null
+++ b/patches/0006-wined3d-Perform-initial-allocation-of-persistent-buf.patch
@@ -0,0 +1,69 @@
+From ab175aade464256f11a52cd98eae163af3cffee3 Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Thu, 8 Mar 2018 22:42:03 -0800
+Subject: [PATCH 06/11] wined3d: Perform initial allocation of persistent
+ buffers asynchronously.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer.c | 30 ++++++++++++++++++++----------
+ 1 file changed, 20 insertions(+), 10 deletions(-)
+
+diff --git a/dlls/wined3d/buffer.c b/dlls/wined3d/buffer.c
+index 7d83c943464..d038885cc1d 100644
+--- a/dlls/wined3d/buffer.c
++++ b/dlls/wined3d/buffer.c
+@@ -277,3 +277,3 @@ fail:
+ /* Context activation is done by the caller. */
+-static BOOL buffer_alloc_persistent_map(struct wined3d_buffer *buffer, struct wined3d_context *context)
++static BOOL buffer_alloc_persistent_map(struct wined3d_buffer *buffer)
+ {
+@@ -692,3 +692,3 @@ static BOOL wined3d_buffer_prepare_location(struct wined3d_buffer *buffer,
+             }
+-            return buffer_alloc_persistent_map(buffer, context);
++            return buffer_alloc_persistent_map(buffer);
+ 
+@@ -1125,3 +1125,3 @@ static HRESULT wined3d_buffer_gl_map(struct wined3d_buffer_gl *buffer_gl,
+ 
+-        FIXME_(d3d_perf)("Fences not used for persistent buffer maps on CS thread, using glFinish.\n");
++        FIXME_(d3d_perf)("Fences not used for persistent buffer maps on CS thread, using glFinish (flags: %x)\n", flags);
+ 
+@@ -1423,4 +1423,16 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+     // which require no GL calls to interface with.
+-    if (buffer->locations & WINED3D_LOCATION_PERSISTENT_MAP)
++    if (flags & WINED3D_BUFFER_PERSISTENT)
+     {
++        // Attempt to load a persistent map without syncing, if possible.
++        if (!(buffer->locations & WINED3D_LOCATION_PERSISTENT_MAP))
++        {
++            wined3d_resource_wait_idle(resource);
++            if (!buffer_alloc_persistent_map(buffer))
++            {
++                ERR_(d3d_perf)("Failed to allocate persistent buffer, falling back to sync path.");
++                return E_FAIL;
++            }
++            wined3d_buffer_validate_location(buffer, WINED3D_LOCATION_PERSISTENT_MAP);
++        }
++
+         map_desc->row_pitch = map_desc->slice_pitch = resource->size;
+@@ -1444,2 +1456,3 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+             wined3d_cs_emit_discard_buffer(resource->device->cs, buffer, map_range);
++
+             return WINED3D_OK;
+@@ -1454,10 +1467,7 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+             resource->map_count++;
++
+             return WINED3D_OK;
+         }
+-        else
+-        {
+-            // TODO(acomminos): Should check mapped ranges to see if the region is writeable even though NOOVERWRITE is specified.
+-            WARN_(d3d_perf)("Mapping persistent buffer %p in sync with CS thread.\n", buffer);
+-            // XXX(acomminos): kill this early return. they're the worst.
+-        }
++
++        WARN_(d3d_perf)("Mapping persistent buffer %p in sync with CS thread.\n", buffer);
+     }
+-- 
+2.19.1
+
diff --git a/patches/0007-wined3d-Avoid-freeing-persistent-buffer-heap-element.patch b/patches/0007-wined3d-Avoid-freeing-persistent-buffer-heap-element.patch
new file mode 100644
index 000000000..477b8f608
--- /dev/null
+++ b/patches/0007-wined3d-Avoid-freeing-persistent-buffer-heap-element.patch
@@ -0,0 +1,260 @@
+From 11856ca314d7be92c74d50a0c7de8067b4996d36 Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Thu, 8 Mar 2018 23:01:50 -0800
+Subject: [PATCH 07/11] wined3d: Avoid freeing persistent buffer heap elements
+ during use.
+
+Using HeapFree is expensive, especially when we don't have our buffers
+for long.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer.c          | 29 +++++++++--------
+ dlls/wined3d/buffer_heap.c     | 57 ++++++++++++++--------------------
+ dlls/wined3d/context.c         |  4 +--
+ dlls/wined3d/cs.c              |  6 ++--
+ dlls/wined3d/wined3d_private.h | 25 ++++++++++-----
+ 5 files changed, 61 insertions(+), 60 deletions(-)
+
+diff --git a/dlls/wined3d/buffer.c b/dlls/wined3d/buffer.c
+index d038885cc1d..5e3df085a19 100644
+--- a/dlls/wined3d/buffer.c
++++ b/dlls/wined3d/buffer.c
+@@ -281,3 +281,3 @@ static BOOL buffer_alloc_persistent_map(struct wined3d_buffer *buffer)
+     struct wined3d_buffer_heap *heap;
+-    struct wined3d_map_range map_range;
++    struct wined3d_buffer_heap_element *elem;
+     HRESULT hr;
+@@ -297,3 +297,3 @@ static BOOL buffer_alloc_persistent_map(struct wined3d_buffer *buffer)
+     buffer->buffer_heap = heap;
+-    if (FAILED(hr = wined3d_buffer_heap_alloc(heap, resource->size, &map_range)))
++    if (FAILED(hr = wined3d_buffer_heap_alloc(heap, resource->size, &elem)))
+     {
+@@ -301,4 +301,4 @@ static BOOL buffer_alloc_persistent_map(struct wined3d_buffer *buffer)
+     }
+-    buffer->cs_persistent_map = map_range;
+-    buffer->mt_persistent_map = map_range;
++    buffer->cs_persistent_map = elem;
++    buffer->mt_persistent_map = elem;
+     return TRUE;
+@@ -758,3 +758,3 @@ BOOL wined3d_buffer_load_location(struct wined3d_buffer *buffer,
+             memcpy(buffer->buffer_heap->map_ptr +
+-                   buffer->cs_persistent_map.offset,
++                   buffer->cs_persistent_map->range.offset,
+                    buffer->resource.heap_memory, buffer->resource.size);
+@@ -806,3 +806,3 @@ DWORD wined3d_buffer_get_memory(struct wined3d_buffer *buffer,
+         data->buffer_object = buffer->buffer_heap->buffer_object;
+-        data->addr = buffer->cs_persistent_map.offset;
++        data->addr = buffer->cs_persistent_map->range.offset;
+         // Note that the size of the underlying buffer allocation may be larger
+@@ -810,3 +810,3 @@ DWORD wined3d_buffer_get_memory(struct wined3d_buffer *buffer,
+         // aligned (e.g. for uniform buffer offsets).
+-        data->length = buffer->cs_persistent_map.size;
++        data->length = buffer->cs_persistent_map->range.size;
+         return WINED3D_LOCATION_PERSISTENT_MAP;
+@@ -1131,3 +1131,3 @@ static HRESULT wined3d_buffer_gl_map(struct wined3d_buffer_gl *buffer_gl,
+         base = buffer_gl->b.buffer_heap->map_ptr
+-             + buffer_gl->b.cs_persistent_map.offset;
++             + buffer_gl->b.cs_persistent_map->range.offset;
+         *data = base + offset;
+@@ -1441,4 +1441,4 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+             HRESULT hr;
+-            struct wined3d_map_range map_range;
+-            if (FAILED(hr = wined3d_buffer_heap_alloc(buffer->buffer_heap, resource->size, &map_range)))
++            struct wined3d_buffer_heap_element *mt_elem;
++            if (FAILED(hr = wined3d_buffer_heap_alloc(buffer->buffer_heap, resource->size, &mt_elem)))
+             {
+@@ -1447,6 +1447,6 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+             }
+-            map_desc->data = buffer->buffer_heap->map_ptr + map_range.offset + offset;
++            map_desc->data = buffer->buffer_heap->map_ptr + mt_elem->range.offset + offset;
+             resource->map_count++;
+ 
+-            buffer->mt_persistent_map = map_range;
++            buffer->mt_persistent_map = mt_elem;
+ 
+@@ -1455,4 +1455,3 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+             // must be called before the buffer can be reused.
+-            wined3d_cs_emit_discard_buffer(resource->device->cs, buffer, map_range);
+-
++            wined3d_cs_emit_discard_buffer(resource->device->cs, buffer, mt_elem);
+             return WINED3D_OK;
+@@ -1464,3 +1463,3 @@ static HRESULT buffer_resource_sub_resource_map(struct wined3d_resource *resourc
+             // DISCARDed one hasn't reached the command stream yet.
+-            struct wined3d_map_range map_range = buffer->mt_persistent_map;
++            struct wined3d_map_range map_range = buffer->mt_persistent_map->range;
+             map_desc->data = buffer->buffer_heap->map_ptr + map_range.offset + offset;
+diff --git a/dlls/wined3d/buffer_heap.c b/dlls/wined3d/buffer_heap.c
+index 75f84b00882..80670c515f7 100644
+--- a/dlls/wined3d/buffer_heap.c
++++ b/dlls/wined3d/buffer_heap.c
+@@ -27,14 +27,2 @@ WINE_DECLARE_DEBUG_CHANNEL(d3d_perf);
+ 
+-struct wined3d_buffer_heap_element
+-{
+-    struct wined3d_map_range range;
+-
+-    // rbtree data
+-    struct wine_rb_entry entry;
+-
+-    // Binned free list positions
+-    struct wined3d_buffer_heap_element *next;
+-    struct wined3d_buffer_heap_element *prev;
+-};
+-
+ struct wined3d_buffer_heap_fenced_element
+@@ -84,2 +72,7 @@ static void element_insert_free_bin(struct wined3d_buffer_heap *heap, struct win
+ {
++    if (elem->prev || elem->next)
++    {
++        ERR("Element %p in already in a free list (for some reason).\n", elem);
++    }
++
+     int bin = element_bin(elem);
+@@ -208,3 +201,3 @@ HRESULT wined3d_buffer_heap_destroy(struct wined3d_buffer_heap *heap, struct win
+ 
+-HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr size, struct wined3d_map_range *out_range)
++HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr size, struct wined3d_buffer_heap_element **out_elem)
+ {
+@@ -235,9 +228,11 @@ HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr s
+ 
+-            out_range->offset = elem->range.offset;
+-            out_range->size = size;
++            // Take the element from the free list, transferring ownership to
++            // the caller.
++            element_remove_free(heap, elem);
++            // Resize the element so that we can free the remainder.
++            elem->range.size = size;
+ 
+-            TRACE_(d3d_perf)("Allocated %d (requested %d) at %p from bin %d (initial %d)\n", size, initial_size, elem->range.offset, i, initial_bin);
++            *out_elem = elem;
+ 
+-            // Remove the element from its current free bin to move it to the correct list.
+-            element_remove_free(heap, elem);
++            TRACE_(d3d_perf)("Allocated %d (requested %d) at %p from bin %d (initial %d)\n", size, initial_size, elem->range.offset, i, initial_bin);
+ 
+@@ -245,10 +240,8 @@ HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr s
+             {
++                struct wined3d_buffer_heap_element *remaining_elem;
++
+                 TRACE_(d3d_perf)("Imperfect fit allocated, fragmenting remainder of %lld at %p.\n", remaining_range.size, remaining_range.offset);
+ 
+-                elem->range = remaining_range;
+-                element_insert_free_bin(heap, elem);
+-            }
+-            else
+-            {
+-                HeapFree(GetProcessHeap(), 0, elem);
++                remaining_elem = element_new(remaining_range.offset, remaining_range.size);
++                element_insert_free_bin(heap, remaining_elem);
+             }
+@@ -267,3 +260,3 @@ HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr s
+         if (num_coalesced > 0)
+-            return wined3d_buffer_heap_alloc(heap, size, out_range);
++            return wined3d_buffer_heap_alloc(heap, size, out_elem);
+     }
+@@ -275,9 +268,4 @@ HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr s
+ 
+-HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3d_map_range range)
++HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3d_buffer_heap_element *elem)
+ {
+-    struct wined3d_buffer_heap_element *elem = element_new(range.offset, range.size);
+-
+-    if (!elem)
+-        return E_OUTOFMEMORY;
+-
+     EnterCriticalSection(&heap->temp_lock);
+@@ -285,2 +273,6 @@ HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3
+     // Only insert the element into a free bin, coalescing will occur later.
++    //
++    // Note that the reason that we pass around wined3d_buffer_heap_element
++    // instead of a range is to avoid frequent HeapAlloc/HeapFree operations
++    // when we're reusing buffers.
+     element_insert_free_bin(heap, elem);
+@@ -292,5 +284,4 @@ HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3
+ 
+-HRESULT wined3d_buffer_heap_free_fenced(struct wined3d_buffer_heap *heap, struct wined3d_device *device, struct wined3d_map_range range)
++HRESULT wined3d_buffer_heap_free_fenced(struct wined3d_buffer_heap *heap, struct wined3d_device *device, struct wined3d_buffer_heap_element *elem)
+ {
+-    struct wined3d_buffer_heap_element *elem = element_new(range.offset, range.size);
+     int bin_index = element_bin(elem);
+diff --git a/dlls/wined3d/context.c b/dlls/wined3d/context.c
+index 27f173b4e10..6e1ccf8602f 100644
+--- a/dlls/wined3d/context.c
++++ b/dlls/wined3d/context.c
+@@ -4905,5 +4905,5 @@ void draw_primitive(struct wined3d_device *device, const struct wined3d_state *s
+         struct wined3d_buffer *index_buffer = state->index_buffer;
+-        if (index_buffer->locations & WINED3D_LOCATION_PERSISTENT_MAP)
++        if (index_buffer->cs_persistent_map)
+         {
+-            idx_data = index_buffer->cs_persistent_map.offset;
++            idx_data = index_buffer->cs_persistent_map->range.offset;
+         }
+diff --git a/dlls/wined3d/cs.c b/dlls/wined3d/cs.c
+index 0f5dd607c95..f79ad0d2aae 100644
+--- a/dlls/wined3d/cs.c
++++ b/dlls/wined3d/cs.c
+@@ -446,3 +446,3 @@ struct wined3d_cs_discard_buffer
+     struct wined3d_buffer *buffer;
+-    struct wined3d_map_range map_range;
++    struct wined3d_buffer_heap_element *map_range;
+ };
+@@ -2530,3 +2530,3 @@ static void wined3d_cs_exec_discard_buffer(struct wined3d_cs *cs, const void *da
+ 
+-void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer *buffer, struct wined3d_map_range map_range)
++void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer *buffer, struct wined3d_buffer_heap_element *elem)
+ {
+@@ -2537,3 +2537,3 @@ void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer
+     op->buffer = buffer;
+-    op->map_range = map_range;
++    op->map_range = elem;
+ 
+diff --git a/dlls/wined3d/wined3d_private.h b/dlls/wined3d/wined3d_private.h
+index 2cf735e1486..9eec2ed94e4 100644
+--- a/dlls/wined3d/wined3d_private.h
++++ b/dlls/wined3d/wined3d_private.h
+@@ -3601,2 +3601,14 @@ struct wined3d_map_range
+ 
++struct wined3d_buffer_heap_element
++{
++    struct wined3d_map_range range;
++
++    // rbtree data
++    struct wine_rb_entry entry;
++
++    // Binned free list positions
++    struct wined3d_buffer_heap_element *next;
++    struct wined3d_buffer_heap_element *prev;
++};
++
+ enum wined3d_cs_queue_id
+@@ -3745,3 +3757,3 @@ void wined3d_cs_emit_update_sub_resource(struct wined3d_cs *cs, struct wined3d_r
+         unsigned int slice_pitch) DECLSPEC_HIDDEN;
+-void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer *buffer, struct wined3d_map_range map_range) DECLSPEC_HIDDEN;
++void wined3d_cs_emit_discard_buffer(struct wined3d_cs *cs, struct wined3d_buffer *buffer, struct wined3d_buffer_heap_element *map_range) DECLSPEC_HIDDEN;
+ void wined3d_cs_init_object(struct wined3d_cs *cs,
+@@ -3779,3 +3791,2 @@ enum wined3d_buffer_conversion_type
+ 
+-struct wined3d_buffer_heap_element;
+ struct wined3d_buffer_heap_fenced_element;
+@@ -3818,7 +3829,7 @@ HRESULT wined3d_buffer_heap_destroy(struct wined3d_buffer_heap *heap, struct win
+ // Attempts to coalesce blocks under memory pressure.
+-HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr size, struct wined3d_map_range* out_range) DECLSPEC_HIDDEN;
++HRESULT wined3d_buffer_heap_alloc(struct wined3d_buffer_heap *heap, GLsizeiptr size, struct wined3d_buffer_heap_element** out_elem) DECLSPEC_HIDDEN;
+ // Immediately frees a heap-allocated buffer segment.
+-HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3d_map_range range) DECLSPEC_HIDDEN;
++HRESULT wined3d_buffer_heap_free(struct wined3d_buffer_heap *heap, struct wined3d_buffer_heap_element *elem) DECLSPEC_HIDDEN;
+ // Enqueues a buffer segment to return to the heap once its fence has been signaled.
+-HRESULT wined3d_buffer_heap_free_fenced(struct wined3d_buffer_heap *heap, struct wined3d_device *device, struct wined3d_map_range range) DECLSPEC_HIDDEN;
++HRESULT wined3d_buffer_heap_free_fenced(struct wined3d_buffer_heap *heap, struct wined3d_device *device, struct wined3d_buffer_heap_element *elem) DECLSPEC_HIDDEN;
+ // Issues a fence for the current set of pending fenced buffers.
+@@ -3858,4 +3869,4 @@ struct wined3d_buffer
+     struct wined3d_buffer_heap *buffer_heap;
+-    struct wined3d_map_range cs_persistent_map;
+-    struct wined3d_map_range mt_persistent_map; // TODO: make struct list?
++    struct wined3d_buffer_heap_element *cs_persistent_map;
++    struct wined3d_buffer_heap_element *mt_persistent_map;
+ };
+-- 
+2.19.1
+
diff --git a/patches/0008-wined3d-Add-DISABLE_PBA-envvar-some-PBA-cleanup.patch b/patches/0008-wined3d-Add-DISABLE_PBA-envvar-some-PBA-cleanup.patch
new file mode 100644
index 000000000..9b997e843
--- /dev/null
+++ b/patches/0008-wined3d-Add-DISABLE_PBA-envvar-some-PBA-cleanup.patch
@@ -0,0 +1,170 @@
+From 688694bdb285bac3e2fd5e48715550bf1159eadf Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Thu, 15 Mar 2018 21:07:21 -0700
+Subject: [PATCH 08/11] wined3d: Add DISABLE_PBA envvar, some PBA cleanup.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer.c          |  4 ++--
+ dlls/wined3d/buffer_heap.c     | 34 +++++++++++++++++++++++-------
+ dlls/wined3d/device.c          | 38 +++++++++++++++++++++++-----------
+ dlls/wined3d/query.c           |  2 +-
+ dlls/wined3d/wined3d_private.h |  6 ++----
+ 5 files changed, 57 insertions(+), 27 deletions(-)
+
+diff --git a/dlls/wined3d/buffer.c b/dlls/wined3d/buffer.c
+index 5e3df085a19..f60318e5019 100644
+--- a/dlls/wined3d/buffer.c
++++ b/dlls/wined3d/buffer.c
+@@ -1616,5 +1616,5 @@ static HRESULT wined3d_buffer_init(struct wined3d_buffer *buffer, struct wined3d
+     {
+-        if (!gl_info->supported[ARB_BUFFER_STORAGE])
++        if (!device->use_pba)
+         {
+-            WARN_(d3d_perf)("Not creating a persistent mapping for a dynamic buffer because ARB_buffer_storage is unsupported.\n");
++            WARN_(d3d_perf)("Not creating a persistent mapping for dynamic buffer %p because the PBA is disabled.\n", buffer);
+         }
+diff --git a/dlls/wined3d/buffer_heap.c b/dlls/wined3d/buffer_heap.c
+index 80670c515f7..899aad96126 100644
+--- a/dlls/wined3d/buffer_heap.c
++++ b/dlls/wined3d/buffer_heap.c
+@@ -27,2 +27,5 @@ WINE_DECLARE_DEBUG_CHANNEL(d3d_perf);
+ 
++// Arbitrary binding to use when binding the persistent buffer.
++#define BIND_TARGET GL_ARRAY_BUFFER
++
+ struct wined3d_buffer_heap_fenced_element
+@@ -142,3 +145,2 @@ HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr s
+     const struct wined3d_gl_info *gl_info = context->gl_info;
+-    const GLenum buffer_target = GL_ARRAY_BUFFER;
+     GLbitfield access_flags;
+@@ -164,13 +166,14 @@ HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr s
+     }
++
+     storage_flags = GL_CLIENT_STORAGE_BIT | access_flags;
+ 
+-    // TODO(acomminos): where should we be checking for errors here?
+     GL_EXTCALL(glGenBuffers(1, &object->buffer_object));
++    checkGLcall("glGenBuffers");
+ 
+-    context_bind_bo(context, buffer_target, object->buffer_object);
++    context_bind_bo(context, BIND_TARGET, object->buffer_object);
+ 
+-    // TODO(acomminos): assert glBufferStorage supported?
+-    GL_EXTCALL(glBufferStorage(buffer_target, size, NULL, storage_flags));
++    GL_EXTCALL(glBufferStorage(BIND_TARGET, size, NULL, storage_flags));
++    checkGLcall("glBufferStorage");
+ 
+-    if (!(object->map_ptr = GL_EXTCALL(glMapBufferRange(buffer_target, 0, size, access_flags))))
++    if (!(object->map_ptr = GL_EXTCALL(glMapBufferRange(BIND_TARGET, 0, size, access_flags))))
+     {
+@@ -179,3 +182,3 @@ HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr s
+     }
+-    context_bind_bo(context, buffer_target, 0);
++    context_bind_bo(context, BIND_TARGET, 0);
+ 
+@@ -197,3 +200,18 @@ HRESULT wined3d_buffer_heap_destroy(struct wined3d_buffer_heap *heap, struct win
+ {
+-    FIXME("Unimplemented, leaking buffer");
++    const struct wined3d_gl_info *gl_info = context->gl_info;
++
++    context_bind_bo(context, BIND_TARGET, heap->buffer_object);
++    GL_EXTCALL(glUnmapBuffer(BIND_TARGET));
++    checkGLcall("glUnmapBuffer");
++    context_bind_bo(context, BIND_TARGET, 0);
++
++    GL_EXTCALL(glDeleteBuffers(1, &heap->buffer_object));
++    checkGLcall("glDeleteBuffers");
++
++    DeleteCriticalSection(&heap->temp_lock);
++
++    // TODO(acomminos): cleanup free lists, fenced list, etc.
++
++    HeapFree(GetProcessHeap(), 0, heap);
++
+     return WINED3D_OK;
+diff --git a/dlls/wined3d/device.c b/dlls/wined3d/device.c
+index 302f4868ca8..fcce1bdb450 100644
+--- a/dlls/wined3d/device.c
++++ b/dlls/wined3d/device.c
+@@ -845,12 +845,23 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+     const struct wined3d_gl_info *gl_info = &device->adapter->gl_info;
+-    // TODO(acomminos): kill this magic number. perhaps base on vram.
+-    GLsizeiptr geo_heap_size = 512 * 1024 * 1024;
+-    // We choose a constant buffer size of 128MB, the same as NVIDIA claims to
+-    // use in their Direct3D driver for discarded constant buffers.
+-    GLsizeiptr cb_heap_size = 128 * 1024 * 1024;
+-    GLint ub_alignment;
+-    HRESULT hr;
++    BOOL use_pba = FALSE;
++    char *env_pba_disable;
+ 
+-    if (gl_info->supported[ARB_BUFFER_STORAGE])
++    if (!gl_info->supported[ARB_BUFFER_STORAGE])
++    {
++        FIXME("Not using PBA, ARB_buffer_storage unsupported.\n");
++    }
++    else if ((env_pba_disable = getenv("PBA_DISABLE")) && *env_pba_disable != '0')
+     {
++        FIXME("Not using PBA, envvar 'PBA_DISABLE' set.\n");
++    }
++    else
++    {
++        // TODO(acomminos): kill this magic number. perhaps base on vram.
++        GLsizeiptr geo_heap_size = 512 * 1024 * 1024;
++        // We choose a constant buffer size of 128MB, the same as NVIDIA claims to
++        // use in their Direct3D driver for discarded constant buffers.
++        GLsizeiptr cb_heap_size = 128 * 1024 * 1024;
++        GLint ub_alignment;
++        HRESULT hr;
++
+         gl_info->gl_ops.gl.p_glGetIntegerv(GL_UNIFORM_BUFFER_OFFSET_ALIGNMENT, &ub_alignment);
+@@ -863,2 +874,3 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+             ERR("Failed to create write-only persistent buffer heap, hr %#x.\n", hr);
++            goto fail;
+         }
+@@ -868,2 +880,3 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+             ERR("Failed to create persistent buffer heap for constant buffers, hr %#x.\n", hr);
++            goto fail;
+         }
+@@ -871,7 +884,8 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+         FIXME("Initialized PBA (geo_heap_size: %ld, cb_heap_size: %ld, ub_align: %d)\n", geo_heap_size, cb_heap_size, ub_alignment);
++
++        use_pba = TRUE;
+     }
+-    else
+-    {
+-        FIXME("Not using PBA, ARB_buffer_storage unsupported.\n");
+-    }
++
++fail:
++    device->use_pba = use_pba;
+ }
+diff --git a/dlls/wined3d/query.c b/dlls/wined3d/query.c
+index cefdedee4f1..4239fc08b3d 100644
+--- a/dlls/wined3d/query.c
++++ b/dlls/wined3d/query.c
+@@ -181,3 +181,3 @@ static BOOL wined3d_fence_supported(const struct wined3d_gl_info *gl_info)
+ 
+-enum wined3d_fence_result wined3d_fence_test(const struct wined3d_fence *fence,
++static enum wined3d_fence_result wined3d_fence_test(const struct wined3d_fence *fence,
+         const struct wined3d_device *device, DWORD flags)
+diff --git a/dlls/wined3d/wined3d_private.h b/dlls/wined3d/wined3d_private.h
+index 9eec2ed94e4..a30c83a6986 100644
+--- a/dlls/wined3d/wined3d_private.h
++++ b/dlls/wined3d/wined3d_private.h
+@@ -1710,5 +1710,2 @@ enum wined3d_fence_result wined3d_fence_wait(const struct wined3d_fence *fence,
+         const struct wined3d_device *device) DECLSPEC_HIDDEN;
+-// XXX(acomminos): really expose this?
+-enum wined3d_fence_result wined3d_fence_test(const struct wined3d_fence *fence,
+-        const struct wined3d_device *device, DWORD flags) DECLSPEC_HIDDEN;
+ 
+@@ -2994,3 +2991,4 @@ struct wined3d_device
+     BYTE filter_messages : 1;
+-    BYTE padding : 3;
++    BYTE use_pba : 1;                   /* A flag to use the persistent buffer allocator for dynamic buffers. */
++    BYTE padding : 2;
+ 
+-- 
+2.19.1
+
diff --git a/patches/0009-wined3d-Add-quirk-to-use-GL_CLIENT_STORAGE_BIT-for-m.patch b/patches/0009-wined3d-Add-quirk-to-use-GL_CLIENT_STORAGE_BIT-for-m.patch
new file mode 100644
index 000000000..a65e8a766
--- /dev/null
+++ b/patches/0009-wined3d-Add-quirk-to-use-GL_CLIENT_STORAGE_BIT-for-m.patch
@@ -0,0 +1,2741 @@
+From 746558c55dd2cb38af9276b28c4d90ed95d511e3 Mon Sep 17 00:00:00 2001
+From: Andrew Comminos <andrew@comminos.com>
+Date: Thu, 15 Mar 2018 21:22:06 -0700
+Subject: [PATCH 09/11] wined3d: Add quirk to use GL_CLIENT_STORAGE_BIT for
+ mesa.
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/adapter_gl.c      |   19 +
+ dlls/wined3d/buffer_heap.c     |   15 +-
+ dlls/wined3d/directx.c         | 2652 --------------------------------
+ dlls/wined3d/wined3d_private.h |    1 +
+ 4 files changed, 34 insertions(+), 2653 deletions(-)
+
+diff --git a/dlls/wined3d/adapter_gl.c b/dlls/wined3d/adapter_gl.c
+index 355f35e32f9..bbdb5dc4448 100644
+--- a/dlls/wined3d/adapter_gl.c
++++ b/dlls/wined3d/adapter_gl.c
+@@ -835,2 +835,9 @@ static BOOL match_broken_viewport_subpixel_bits(const struct wined3d_gl_info *gl
+ 
++static BOOL match_mesa(const struct wined3d_gl_info *gl_info, struct wined3d_caps_gl_ctx *ctx,
++        const char *gl_renderer, enum wined3d_gl_vendor gl_vendor,
++        enum wined3d_pci_vendor card_vendor, enum wined3d_pci_device device)
++{
++    return gl_vendor == GL_VENDOR_MESA;
++}
++
+ static void quirk_apple_glsl_constants(struct wined3d_gl_info *gl_info)
+@@ -989,2 +996,9 @@ static void quirk_broken_viewport_subpixel_bits(struct wined3d_gl_info *gl_info)
+ 
++static void quirk_use_client_storage_bit(struct wined3d_gl_info *gl_info)
++{
++    // Using ARB_buffer_storage on Mesa requires the GL_CLIENT_STORAGE_BIT to be
++    // set to use GTT for immutable buffers on radeon (see PIPE_USAGE_STREAM).
++    gl_info->quirks |= WINED3D_QUIRK_USE_CLIENT_STORAGE_BIT;
++}
++
+ static const struct wined3d_gpu_description *query_gpu_description(const struct wined3d_gl_info *gl_info,
+@@ -1133,2 +1147,7 @@ static void fixup_extensions(struct wined3d_gl_info *gl_info, struct wined3d_cap
+         },
++        {
++            match_mesa,
++            quirk_use_client_storage_bit,
++            "Use GL_CLIENT_STORAGE_BIT for persistent buffers on mesa",
++        },
+     };
+diff --git a/dlls/wined3d/buffer_heap.c b/dlls/wined3d/buffer_heap.c
+index 899aad96126..9e8f2d799df 100644
+--- a/dlls/wined3d/buffer_heap.c
++++ b/dlls/wined3d/buffer_heap.c
+@@ -167,3 +167,16 @@ HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr s
+ 
+-    storage_flags = GL_CLIENT_STORAGE_BIT | access_flags;
++    storage_flags = access_flags;
++    // FIXME(acomminos): So, about GL_CLIENT_STORAGE_BIT:
++    // - On NVIDIA, DMA CACHED memory is used when this flag is set. SYSTEM HEAP
++    //   memory is used without it, which (in my testing) is much faster.
++    // - On Mesa, GTT is used when this flag is set. This is what we want- we
++    //   upload to VRAM occur otherwise, which is unusably slow (on radeon).
++    //
++    // Thus, we're only going to set this on mesa for now.
++    // Hints are awful anyway.
++    if (gl_info->quirks & WINED3D_QUIRK_USE_CLIENT_STORAGE_BIT)
++    {
++        FIXME_(d3d_perf)("PBA: using GL_CLIENT_STORAGE_BIT quirk");
++        storage_flags |= GL_CLIENT_STORAGE_BIT;
++    }
+ 
+diff --git a/dlls/wined3d/directx.c b/dlls/wined3d/directx.c
+index 391fafd1841..e65db79decd 100644
+--- a/dlls/wined3d/directx.c
++++ b/dlls/wined3d/directx.c
+@@ -45,3 +45,2 @@ static const GUID IID_D3DDEVICE_D3DUID = { 0xaeb2cdd4, 0x6e41, 0x43ea, { 0x94,0x
+ 
+-
+ /**********************************************************
+@@ -583,2653 +582,2 @@ void wined3d_driver_info_init(struct wined3d_driver_info *driver_info,
+     if (driver_model < DRIVER_MODEL_NT6X && driver_info->vram_bytes > LONG_MAX)
+-<<<<<<< HEAD
+-=======
+-    {
+-        TRACE("Limiting amount of video memory to %#lx bytes for OS version older than Vista.\n", LONG_MAX);
+-        driver_info->vram_bytes = LONG_MAX;
+-    }
+-
+-    /* Try to obtain driver version information for the current Windows version. This fails in
+-     * some cases:
+-     * - the gpu is not available on the currently selected OS version:
+-     *   - Geforce GTX480 on Win98. When running applications in compatibility mode on Windows,
+-     *     version information for the current Windows version is returned instead of faked info.
+-     *     We do the same and assume the default Windows version to emulate is WinXP.
+-     *
+-     *   - Videocard is a Riva TNT but winver is set to win7 (there are no drivers for this beast)
+-     *     For now return the XP driver info. Perhaps later on we should return VESA.
+-     *
+-     * - the gpu is not in our database (can happen when the user overrides the vendor_id / device_id)
+-     *   This could be an indication that our database is not up to date, so this should be fixed.
+-     */
+-    if ((version_info = get_driver_version_info(driver, driver_model))
+-            || (version_info = get_driver_version_info(driver, DRIVER_MODEL_GENERIC)))
+-    {
+-        driver_info->name = version_info->driver_name;
+-        driver_info->version_high = MAKEDWORD_VERSION(driver_os_version, version_info->version);
+-        driver_info->version_low = MAKEDWORD_VERSION(version_info->subversion, version_info->build);
+-    }
+-    else
+-    {
+-        ERR("No driver version info found for device %04x:%04x, driver model %#x.\n",
+-                driver_info->vendor, driver_info->device, driver_model);
+-        driver_info->name = "Display";
+-        driver_info->version_high = MAKEDWORD_VERSION(driver_os_version, 15);
+-        driver_info->version_low = MAKEDWORD_VERSION(8, 6); /* Nvidia RIVA TNT, arbitrary */
+-    }
+-
+-    TRACE("Reporting (fake) driver version 0x%08x-0x%08x.\n",
+-            driver_info->version_high, driver_info->version_low);
+-}
+-
+-/* Context activation is done by the caller. */
+-static void fixup_extensions(struct wined3d_gl_info *gl_info, struct wined3d_caps_gl_ctx *ctx,
+-        const char *gl_renderer, enum wined3d_gl_vendor gl_vendor,
+-        enum wined3d_pci_vendor card_vendor, enum wined3d_pci_device device)
+-{
+-    unsigned int i;
+-
+-    for (i = 0; i < ARRAY_SIZE(quirk_table); ++i)
+-    {
+-        if (!quirk_table[i].match(gl_info, ctx, gl_renderer, gl_vendor, card_vendor, device)) continue;
+-        TRACE("Applying driver quirk \"%s\".\n", quirk_table[i].description);
+-        quirk_table[i].apply(gl_info);
+-    }
+-
+-    /* Find out if PBOs work as they are supposed to. */
+-    test_pbo_functionality(gl_info);
+-}
+-
+-static DWORD wined3d_parse_gl_version(const char *gl_version)
+-{
+-    const char *ptr = gl_version;
+-    int major, minor;
+-
+-    major = atoi(ptr);
+-    if (major <= 0)
+-        ERR("Invalid OpenGL major version %d.\n", major);
+-
+-    while (isdigit(*ptr)) ++ptr;
+-    if (*ptr++ != '.')
+-        ERR("Invalid OpenGL version string %s.\n", debugstr_a(gl_version));
+-
+-    minor = atoi(ptr);
+-
+-    TRACE("Found OpenGL version %d.%d.\n", major, minor);
+-
+-    return MAKEDWORD_VERSION(major, minor);
+-}
+-
+-static enum wined3d_gl_vendor wined3d_guess_gl_vendor(const struct wined3d_gl_info *gl_info,
+-        const char *gl_vendor_string, const char *gl_renderer, const char *gl_version)
+-{
+-    /* MacOS has various specialities in the extensions it advertises. Some have to be loaded from
+-     * the opengl 1.2+ core, while other extensions are advertised, but software emulated. So try to
+-     * detect the Apple OpenGL implementation to apply some extension fixups afterwards.
+-     *
+-     * Detecting this isn't really easy. The vendor string doesn't mention Apple. Compile-time checks
+-     * aren't sufficient either because a Linux binary may display on a macos X server via remote X11.
+-     * So try to detect the GL implementation by looking at certain Apple extensions. Some extensions
+-     * like client storage might be supported on other implementations too, but GL_APPLE_flush_render
+-     * is specific to the Mac OS X window management, and GL_APPLE_ycbcr_422 is QuickTime specific. So
+-     * the chance that other implementations support them is rather small since Win32 QuickTime uses
+-     * DirectDraw, not OpenGL. */
+-    if (gl_info->supported[APPLE_FENCE] && gl_info->supported[APPLE_YCBCR_422])
+-        return GL_VENDOR_APPLE;
+-
+-    if (strstr(gl_vendor_string, "NVIDIA"))
+-        return GL_VENDOR_NVIDIA;
+-
+-    if (strstr(gl_vendor_string, "ATI"))
+-        return GL_VENDOR_FGLRX;
+-
+-    if (strstr(gl_vendor_string, "Mesa")
+-            || strstr(gl_vendor_string, "X.Org")
+-            || strstr(gl_vendor_string, "Advanced Micro Devices, Inc.")
+-            || strstr(gl_vendor_string, "DRI R300 Project")
+-            || strstr(gl_vendor_string, "Tungsten Graphics, Inc")
+-            || strstr(gl_vendor_string, "VMware, Inc.")
+-            || strstr(gl_vendor_string, "Intel")
+-            || strstr(gl_renderer, "Mesa")
+-            || strstr(gl_renderer, "Gallium")
+-            || strstr(gl_renderer, "Intel")
+-            || strstr(gl_version, "Mesa"))
+-        return GL_VENDOR_MESA;
+-
+-    FIXME("Received unrecognized GL_VENDOR %s. Returning GL_VENDOR_UNKNOWN.\n",
+-            debugstr_a(gl_vendor_string));
+-
+-    return GL_VENDOR_UNKNOWN;
+-}
+-
+-static enum wined3d_pci_vendor wined3d_guess_card_vendor(const char *gl_vendor_string, const char *gl_renderer)
+-{
+-    if (strstr(gl_vendor_string, "NVIDIA")
+-            || strstr(gl_vendor_string, "Nouveau")
+-            || strstr(gl_vendor_string, "nouveau"))
+-        return HW_VENDOR_NVIDIA;
+-
+-    if (strstr(gl_vendor_string, "ATI")
+-            || strstr(gl_vendor_string, "Advanced Micro Devices, Inc.")
+-            || strstr(gl_vendor_string, "X.Org R300 Project")
+-            || strstr(gl_renderer, "AMD")
+-            || strstr(gl_renderer, "FirePro")
+-            || strstr(gl_renderer, "Radeon")
+-            || strstr(gl_renderer, "R100")
+-            || strstr(gl_renderer, "R200")
+-            || strstr(gl_renderer, "R300")
+-            || strstr(gl_renderer, "R600")
+-            || strstr(gl_renderer, "R700"))
+-        return HW_VENDOR_AMD;
+-
+-    if (strstr(gl_vendor_string, "Intel(R)")
+-            /* Intel switched from Intel(R) to IntelÂ® recently, so just match Intel. */
+-            || strstr(gl_renderer, "Intel")
+-            || strstr(gl_renderer, "i915")
+-            || strstr(gl_vendor_string, "Intel Inc."))
+-        return HW_VENDOR_INTEL;
+-
+-    if (strstr(gl_renderer, "SVGA3D"))
+-        return HW_VENDOR_VMWARE;
+-
+-    if (strstr(gl_vendor_string, "Mesa")
+-            || strstr(gl_vendor_string, "Brian Paul")
+-            || strstr(gl_vendor_string, "Tungsten Graphics, Inc")
+-            || strstr(gl_vendor_string, "VMware, Inc."))
+-        return HW_VENDOR_SOFTWARE;
+-
+-    FIXME("Received unrecognized GL_VENDOR %s. Returning HW_VENDOR_NVIDIA.\n", debugstr_a(gl_vendor_string));
+-
+-    return HW_VENDOR_NVIDIA;
+-}
+-
+-static enum wined3d_feature_level feature_level_from_caps(const struct wined3d_gl_info *gl_info,
+-        const struct shader_caps *shader_caps, const struct fragment_caps *fragment_caps)
+-{
+-    unsigned int shader_model;
+-
+-    shader_model = min(shader_caps->vs_version, shader_caps->ps_version);
+-    shader_model = min(shader_model, max(shader_caps->gs_version, 3));
+-    shader_model = min(shader_model, max(shader_caps->hs_version, 4));
+-    shader_model = min(shader_model, max(shader_caps->ds_version, 4));
+-
+-    if (gl_info->supported[WINED3D_GL_VERSION_3_2] && gl_info->supported[ARB_SAMPLER_OBJECTS])
+-    {
+-        if (shader_model >= 5
+-                && gl_info->supported[ARB_DRAW_INDIRECT]
+-                && gl_info->supported[ARB_TEXTURE_COMPRESSION_BPTC])
+-            return WINED3D_FEATURE_LEVEL_11;
+-
+-        if (shader_model == 4)
+-            return WINED3D_FEATURE_LEVEL_10;
+-    }
+-
+-    if (shader_model == 3)
+-        return WINED3D_FEATURE_LEVEL_9_SM3;
+-    if (shader_model == 2)
+-        return WINED3D_FEATURE_LEVEL_9_SM2;
+-    if (shader_model == 1)
+-        return WINED3D_FEATURE_LEVEL_8;
+-
+-    if (fragment_caps->TextureOpCaps & WINED3DTEXOPCAPS_DOTPRODUCT3)
+-        return WINED3D_FEATURE_LEVEL_7;
+-    if (fragment_caps->MaxSimultaneousTextures > 1)
+-        return WINED3D_FEATURE_LEVEL_6;
+-
+-    return WINED3D_FEATURE_LEVEL_5;
+-}
+-
+-static const struct wined3d_renderer_table
+-{
+-    const char *renderer;
+-    enum wined3d_pci_device id;
+-}
+-cards_nvidia_binary[] =
+-{
+-    /* Direct 3D 11 */
+-    {"TITAN V",                     CARD_NVIDIA_TITANV},            /* GeForce 1000 - highend */
+-    {"TITAN X (Pascal)",            CARD_NVIDIA_TITANX_PASCAL},     /* GeForce 1000 - highend */
+-    {"GTX 1080 Ti",                 CARD_NVIDIA_GEFORCE_GTX1080TI}, /* GeForce 1000 - highend */
+-    {"GTX 1080",                    CARD_NVIDIA_GEFORCE_GTX1080},   /* GeForce 1000 - highend */
+-    {"GTX 1070",                    CARD_NVIDIA_GEFORCE_GTX1070},   /* GeForce 1000 - highend */
+-    {"GTX 1060",                    CARD_NVIDIA_GEFORCE_GTX1060},   /* GeForce 1000 - midend high */
+-    {"GTX 1050 Ti",                 CARD_NVIDIA_GEFORCE_GTX1050TI}, /* GeForce 1000 - midend */
+-    {"GTX 1050",                    CARD_NVIDIA_GEFORCE_GTX1050},   /* GeForce 1000 - midend */
+-    {"GTX 980 Ti",                  CARD_NVIDIA_GEFORCE_GTX980TI},  /* GeForce 900 - highend */
+-    {"GTX 980",                     CARD_NVIDIA_GEFORCE_GTX980},    /* GeForce 900 - highend */
+-    {"GTX 970M",                    CARD_NVIDIA_GEFORCE_GTX970M},   /* GeForce 900 - highend mobile*/
+-    {"GTX 970",                     CARD_NVIDIA_GEFORCE_GTX970},    /* GeForce 900 - highend */
+-    {"GTX TITAN X",                 CARD_NVIDIA_GEFORCE_GTXTITANX}, /* Geforce 900 - highend */
+-    {"GTX 960M",                    CARD_NVIDIA_GEFORCE_GTX960M},   /* GeForce 900 - midend high mobile */
+-    {"GTX 960",                     CARD_NVIDIA_GEFORCE_GTX960},    /* GeForce 900 - midend high */
+-    {"GTX 950M",                    CARD_NVIDIA_GEFORCE_GTX950M},   /* GeForce 900 - midend mobile */
+-    {"GTX 950",                     CARD_NVIDIA_GEFORCE_GTX950},    /* GeForce 900 - midend */
+-    {"GeForce 940M",                CARD_NVIDIA_GEFORCE_940M},      /* GeForce 900 - midend mobile */
+-    {"GTX 880M",                    CARD_NVIDIA_GEFORCE_GTX880M},   /* GeForce 800 - mobile */
+-    {"GTX 870M",                    CARD_NVIDIA_GEFORCE_GTX870M},   /* GeForce 800 - mobile */
+-    {"GTX 860M",                    CARD_NVIDIA_GEFORCE_GTX860M},   /* GeForce 800 - mobile */
+-    {"GTX 850M",                    CARD_NVIDIA_GEFORCE_GTX850M},   /* GeForce 800 - mobile */
+-    {"GeForce 845M",                CARD_NVIDIA_GEFORCE_845M},      /* GeForce 800 - mobile */
+-    {"GeForce 840M",                CARD_NVIDIA_GEFORCE_840M},      /* GeForce 800 - mobile */
+-    {"GeForce 830M",                CARD_NVIDIA_GEFORCE_830M},      /* GeForce 800 - mobile */
+-    {"GeForce 820M",                CARD_NVIDIA_GEFORCE_820M},      /* GeForce 800 - mobile */
+-    {"GTX 780 Ti",                  CARD_NVIDIA_GEFORCE_GTX780TI},  /* Geforce 700 - highend */
+-    {"GTX TITAN Black",             CARD_NVIDIA_GEFORCE_GTXTITANB}, /* Geforce 700 - highend */
+-    {"GTX TITAN Z",                 CARD_NVIDIA_GEFORCE_GTXTITANZ}, /* Geforce 700 - highend */
+-    {"GTX TITAN",                   CARD_NVIDIA_GEFORCE_GTXTITAN},  /* Geforce 700 - highend */
+-    {"GTX 780",                     CARD_NVIDIA_GEFORCE_GTX780},    /* Geforce 700 - highend */
+-    {"GTX 770M",                    CARD_NVIDIA_GEFORCE_GTX770M},   /* Geforce 700 - midend high mobile */
+-    {"GTX 770",                     CARD_NVIDIA_GEFORCE_GTX770},    /* Geforce 700 - highend */
+-    {"GTX 765M",                    CARD_NVIDIA_GEFORCE_GTX765M},   /* Geforce 700 - midend high mobile */
+-    {"GTX 760 Ti",                  CARD_NVIDIA_GEFORCE_GTX760TI},  /* Geforce 700 - midend high */
+-    {"GTX 760",                     CARD_NVIDIA_GEFORCE_GTX760},    /* Geforce 700 - midend high  */
+-    {"GTX 750 Ti",                  CARD_NVIDIA_GEFORCE_GTX750TI},  /* Geforce 700 - midend */
+-    {"GTX 750",                     CARD_NVIDIA_GEFORCE_GTX750},    /* Geforce 700 - midend */
+-    {"GT 750M",                     CARD_NVIDIA_GEFORCE_GT750M},    /* Geforce 700 - midend mobile */
+-    {"GT 740M",                     CARD_NVIDIA_GEFORCE_GT740M},    /* Geforce 700 - midend mobile */
+-    {"GT 730M",                     CARD_NVIDIA_GEFORCE_GT730M},    /* Geforce 700 - midend mobile */
+-    {"GT 730",                      CARD_NVIDIA_GEFORCE_GT730},     /* Geforce 700 - lowend */
+-    {"GTX 690",                     CARD_NVIDIA_GEFORCE_GTX690},    /* Geforce 600 - highend */
+-    {"GTX 680",                     CARD_NVIDIA_GEFORCE_GTX680},    /* Geforce 600 - highend */
+-    {"GTX 675MX",                   CARD_NVIDIA_GEFORCE_GTX675MX},  /* Geforce 600 - highend */
+-    {"GTX 670MX",                   CARD_NVIDIA_GEFORCE_GTX670MX},  /* Geforce 600 - highend */
+-    {"GTX 670",                     CARD_NVIDIA_GEFORCE_GTX670},    /* Geforce 600 - midend high */
+-    {"GTX 660 Ti",                  CARD_NVIDIA_GEFORCE_GTX660TI},  /* Geforce 600 - midend high */
+-    {"GTX 660M",                    CARD_NVIDIA_GEFORCE_GTX660M},   /* Geforce 600 - midend high mobile */
+-    {"GTX 660",                     CARD_NVIDIA_GEFORCE_GTX660},    /* Geforce 600 - midend high */
+-    {"GTX 650 Ti",                  CARD_NVIDIA_GEFORCE_GTX650TI},  /* Geforce 600 - lowend */
+-    {"GTX 650",                     CARD_NVIDIA_GEFORCE_GTX650},    /* Geforce 600 - lowend */
+-    {"GT 650M",                     CARD_NVIDIA_GEFORCE_GT650M},    /* Geforce 600 - midend mobile */
+-    {"GT 640M",                     CARD_NVIDIA_GEFORCE_GT640M},    /* Geforce 600 - midend mobile */
+-    {"GT 630M",                     CARD_NVIDIA_GEFORCE_GT630M},    /* Geforce 600 - midend mobile */
+-    {"GT 630",                      CARD_NVIDIA_GEFORCE_GT630},     /* Geforce 600 - lowend */
+-    {"GT 610",                      CARD_NVIDIA_GEFORCE_GT610},     /* Geforce 600 - lowend */
+-    {"GTX 580",                     CARD_NVIDIA_GEFORCE_GTX580},    /* Geforce 500 - highend */
+-    {"GTX 570",                     CARD_NVIDIA_GEFORCE_GTX570},    /* Geforce 500 - midend high */
+-    {"GTX 560 Ti",                  CARD_NVIDIA_GEFORCE_GTX560TI},  /* Geforce 500 - midend */
+-    {"GTX 560M",                    CARD_NVIDIA_GEFORCE_GTX560M},   /* Geforce 500 - midend mobile */
+-    {"GTX 560",                     CARD_NVIDIA_GEFORCE_GTX560},    /* Geforce 500 - midend */
+-    {"GT 555M",                     CARD_NVIDIA_GEFORCE_GT555M},    /* Geforce 500 - midend mobile */
+-    {"GTX 550 Ti",                  CARD_NVIDIA_GEFORCE_GTX550},    /* Geforce 500 - midend */
+-    {"GT 540M",                     CARD_NVIDIA_GEFORCE_GT540M},    /* Geforce 500 - midend mobile */
+-    {"GT 525M",                     CARD_NVIDIA_GEFORCE_GT525M},    /* Geforce 500 - lowend mobile */
+-    {"GT 520",                      CARD_NVIDIA_GEFORCE_GT520},     /* Geforce 500 - lowend */
+-    {"GTX 480",                     CARD_NVIDIA_GEFORCE_GTX480},    /* Geforce 400 - highend */
+-    {"GTX 470",                     CARD_NVIDIA_GEFORCE_GTX470},    /* Geforce 400 - midend high */
+-    /* Direct 3D 10 */
+-    {"GTX 465",                     CARD_NVIDIA_GEFORCE_GTX465},    /* Geforce 400 - midend */
+-    {"GTX 460M",                    CARD_NVIDIA_GEFORCE_GTX460M},   /* Geforce 400 - highend mobile */
+-    {"GTX 460",                     CARD_NVIDIA_GEFORCE_GTX460},    /* Geforce 400 - midend */
+-    {"GTS 450",                     CARD_NVIDIA_GEFORCE_GTS450},    /* Geforce 400 - midend low */
+-    {"GT 440",                      CARD_NVIDIA_GEFORCE_GT440},     /* Geforce 400 - lowend */
+-    {"GT 430",                      CARD_NVIDIA_GEFORCE_GT430},     /* Geforce 400 - lowend */
+-    {"GT 425M",                     CARD_NVIDIA_GEFORCE_GT425M},    /* Geforce 400 - lowend mobile */
+-    {"GT 420",                      CARD_NVIDIA_GEFORCE_GT420},     /* Geforce 400 - lowend */
+-    {"410M",                        CARD_NVIDIA_GEFORCE_410M},      /* Geforce 400 - lowend mobile */
+-    {"GT 330",                      CARD_NVIDIA_GEFORCE_GT330},     /* Geforce 300 - highend */
+-    {"GTS 360M",                    CARD_NVIDIA_GEFORCE_GTS350M},   /* Geforce 300 - highend mobile */
+-    {"GTS 350M",                    CARD_NVIDIA_GEFORCE_GTS350M},   /* Geforce 300 - highend mobile */
+-    {"GT 330M",                     CARD_NVIDIA_GEFORCE_GT325M},    /* Geforce 300 - midend mobile */
+-    {"GT 325M",                     CARD_NVIDIA_GEFORCE_GT325M},    /* Geforce 300 - midend mobile */
+-    {"GT 320M",                     CARD_NVIDIA_GEFORCE_GT320M},    /* Geforce 300 - midend mobile */
+-    {"320M",                        CARD_NVIDIA_GEFORCE_320M},      /* Geforce 300 - midend mobile */
+-    {"315M",                        CARD_NVIDIA_GEFORCE_315M},      /* Geforce 300 - midend mobile */
+-    {"GTX 295",                     CARD_NVIDIA_GEFORCE_GTX280},    /* Geforce 200 - highend */
+-    {"GTX 285",                     CARD_NVIDIA_GEFORCE_GTX280},    /* Geforce 200 - highend */
+-    {"GTX 280",                     CARD_NVIDIA_GEFORCE_GTX280},    /* Geforce 200 - highend */
+-    {"GTX 275",                     CARD_NVIDIA_GEFORCE_GTX275},    /* Geforce 200 - midend high */
+-    {"GTX 260",                     CARD_NVIDIA_GEFORCE_GTX260},    /* Geforce 200 - midend */
+-    {"GTS 250",                     CARD_NVIDIA_GEFORCE_GTS250},    /* Geforce 200 - midend */
+-    {"GT 240",                      CARD_NVIDIA_GEFORCE_GT240},     /* Geforce 200 - midend */
+-    {"GT 220",                      CARD_NVIDIA_GEFORCE_GT220},     /* Geforce 200 - lowend */
+-    {"GeForce 310",                 CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
+-    {"GeForce 305",                 CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
+-    {"GeForce 210",                 CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
+-    {"G 210",                       CARD_NVIDIA_GEFORCE_210},       /* Geforce 200 - lowend */
+-    {"GTS 150",                     CARD_NVIDIA_GEFORCE_9800GT},    /* Geforce 9 - highend / Geforce 200 - midend */
+-    {"9800",                        CARD_NVIDIA_GEFORCE_9800GT},    /* Geforce 9 - highend / Geforce 200 - midend */
+-    {"9700M GT",                    CARD_NVIDIA_GEFORCE_9700MGT},   /* Geforce 9 - midend */
+-    {"GT 140",                      CARD_NVIDIA_GEFORCE_9600GT},    /* Geforce 9 - midend */
+-    {"9600",                        CARD_NVIDIA_GEFORCE_9600GT},    /* Geforce 9 - midend */
+-    {"GT 130",                      CARD_NVIDIA_GEFORCE_9500GT},    /* Geforce 9 - midend low / Geforce 200 - low */
+-    {"GT 120",                      CARD_NVIDIA_GEFORCE_9500GT},    /* Geforce 9 - midend low / Geforce 200 - low */
+-    {"9500",                        CARD_NVIDIA_GEFORCE_9500GT},    /* Geforce 9 - midend low / Geforce 200 - low */
+-    {"9400M",                       CARD_NVIDIA_GEFORCE_9400M},     /* Geforce 9 - lowend */
+-    {"9400",                        CARD_NVIDIA_GEFORCE_9400GT},    /* Geforce 9 - lowend */
+-    {"9300",                        CARD_NVIDIA_GEFORCE_9300},      /* Geforce 9 - lowend low */
+-    {"9200",                        CARD_NVIDIA_GEFORCE_9200},      /* Geforce 9 - lowend low */
+-    {"9100",                        CARD_NVIDIA_GEFORCE_9200},      /* Geforce 9 - lowend low */
+-    {"G 100",                       CARD_NVIDIA_GEFORCE_9200},      /* Geforce 9 - lowend low */
+-    {"8800 GTX",                    CARD_NVIDIA_GEFORCE_8800GTX},   /* Geforce 8 - highend high */
+-    {"8800",                        CARD_NVIDIA_GEFORCE_8800GTS},   /* Geforce 8 - highend */
+-    {"8600M",                       CARD_NVIDIA_GEFORCE_8600MGT},   /* Geforce 8 - midend mobile */
+-    {"8600 M",                      CARD_NVIDIA_GEFORCE_8600MGT},   /* Geforce 8 - midend mobile */
+-    {"8700",                        CARD_NVIDIA_GEFORCE_8600GT},    /* Geforce 8 - midend */
+-    {"8600",                        CARD_NVIDIA_GEFORCE_8600GT},    /* Geforce 8 - midend */
+-    {"8500",                        CARD_NVIDIA_GEFORCE_8500GT},    /* Geforce 8 - mid-lowend */
+-    {"8400",                        CARD_NVIDIA_GEFORCE_8400GS},    /* Geforce 8 - mid-lowend */
+-    {"8300",                        CARD_NVIDIA_GEFORCE_8300GS},    /* Geforce 8 - lowend */
+-    {"8200",                        CARD_NVIDIA_GEFORCE_8200},      /* Geforce 8 - lowend */
+-    {"8100",                        CARD_NVIDIA_GEFORCE_8200},      /* Geforce 8 - lowend */
+-    /* Direct 3D 9 SM3 */
+-    {"Quadro FX 5",                 CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
+-    {"Quadro FX 4",                 CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
+-    {"7950",                        CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
+-    {"7900",                        CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
+-    {"7800",                        CARD_NVIDIA_GEFORCE_7800GT},    /* Geforce 7 - highend */
+-    {"7700",                        CARD_NVIDIA_GEFORCE_7600},      /* Geforce 7 - midend */
+-    {"7600",                        CARD_NVIDIA_GEFORCE_7600},      /* Geforce 7 - midend */
+-    {"7400",                        CARD_NVIDIA_GEFORCE_7400},      /* Geforce 7 - lower medium */
+-    {"7300",                        CARD_NVIDIA_GEFORCE_7300},      /* Geforce 7 - lowend */
+-    {"6800",                        CARD_NVIDIA_GEFORCE_6800},      /* Geforce 6 - highend */
+-    {"6700",                        CARD_NVIDIA_GEFORCE_6600GT},    /* Geforce 6 - midend */
+-    {"6610",                        CARD_NVIDIA_GEFORCE_6600GT},    /* Geforce 6 - midend */
+-    {"6600",                        CARD_NVIDIA_GEFORCE_6600GT},    /* Geforce 6 - midend */
+-    /* Direct 3D 9 SM2 */
+-    {"Quadro FX",                   CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
+-    {"5950",                        CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
+-    {"5900",                        CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
+-    {"5800",                        CARD_NVIDIA_GEFORCEFX_5800},    /* GeforceFX - highend */
+-    {"5750",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
+-    {"5700",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
+-    {"5650",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
+-    {"5600",                        CARD_NVIDIA_GEFORCEFX_5600},    /* GeforceFX - midend */
+-    {"5500",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
+-    {"5300",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
+-    {"5250",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
+-    {"5200",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
+-    {"5100",                        CARD_NVIDIA_GEFORCEFX_5200},    /* GeforceFX - lowend */
+-    /* Direct 3D 8 */
+-    {"Quadro4",                     CARD_NVIDIA_GEFORCE4_TI4200},
+-    {"GeForce4 Ti",                 CARD_NVIDIA_GEFORCE4_TI4200},   /* Geforce4 Ti4200/Ti4400/Ti4600/Ti4800 */
+-    /* Direct 3D 7 */
+-    {"GeForce4 MX",                 CARD_NVIDIA_GEFORCE4_MX},       /* MX420/MX440/MX460/MX4000 */
+-    {"Quadro2 MXR",                 CARD_NVIDIA_GEFORCE2_MX},
+-    {"GeForce2 MX",                 CARD_NVIDIA_GEFORCE2_MX},       /* Geforce2 standard/MX100/MX200/MX400 */
+-    {"Quadro2",                     CARD_NVIDIA_GEFORCE2},
+-    {"GeForce2",                    CARD_NVIDIA_GEFORCE2},          /* Geforce2 GTS/Pro/Ti/Ultra */
+-    /* Direct 3D 6 */
+-    {"TNT2",                        CARD_NVIDIA_RIVA_TNT2},         /* Riva TNT2 standard/M64/Pro/Ultra */
+-},
+-/* See http://developer.amd.com/resources/hardware-drivers/ati-catalyst-pc-vendor-id-1002-li/
+- *
+- * Beware: renderer string do not match exact card model,
+- * eg HD 4800 is returned for multiple cards, even for RV790 based ones. */
+-cards_amd_binary[] =
+-{
+-    {"RX 480",                      CARD_AMD_RADEON_RX_480},
+-    {"RX 460",                      CARD_AMD_RADEON_RX_460},
+-    {"R9 Fury Series",              CARD_AMD_RADEON_R9_FURY},
+-    /* Southern Islands */
+-    {"HD 7900",                     CARD_AMD_RADEON_HD7900},
+-    {"HD 7800",                     CARD_AMD_RADEON_HD7800},
+-    {"HD 7700",                     CARD_AMD_RADEON_HD7700},
+-    /* Northern Islands */
+-    {"HD 6970",                     CARD_AMD_RADEON_HD6900},
+-    {"HD 6900",                     CARD_AMD_RADEON_HD6900},
+-    {"HD 6800",                     CARD_AMD_RADEON_HD6800},
+-    {"HD 6770M",                    CARD_AMD_RADEON_HD6600M},
+-    {"HD 6750M",                    CARD_AMD_RADEON_HD6600M},
+-    {"HD 6700",                     CARD_AMD_RADEON_HD6700},
+-    {"HD 6670",                     CARD_AMD_RADEON_HD6600},
+-    {"HD 6630M",                    CARD_AMD_RADEON_HD6600M},
+-    {"HD 6600M",                    CARD_AMD_RADEON_HD6600M},
+-    {"HD 6600",                     CARD_AMD_RADEON_HD6600},
+-    {"HD 6570",                     CARD_AMD_RADEON_HD6600},
+-    {"HD 6500M",                    CARD_AMD_RADEON_HD6600M},
+-    {"HD 6500",                     CARD_AMD_RADEON_HD6600},
+-    {"HD 6480G",                    CARD_AMD_RADEON_HD6480G},
+-    {"HD 6400",                     CARD_AMD_RADEON_HD6400},
+-    {"HD 6300",                     CARD_AMD_RADEON_HD6300},
+-    {"HD 6200",                     CARD_AMD_RADEON_HD6300},
+-    /* Evergreen */
+-    {"HD 5870",                     CARD_AMD_RADEON_HD5800},    /* Radeon EG CYPRESS PRO */
+-    {"HD 5850",                     CARD_AMD_RADEON_HD5800},    /* Radeon EG CYPRESS XT */
+-    {"HD 5800",                     CARD_AMD_RADEON_HD5800},    /* Radeon EG CYPRESS HD58xx generic renderer string */
+-    {"HD 5770",                     CARD_AMD_RADEON_HD5700},    /* Radeon EG JUNIPER XT */
+-    {"HD 5750",                     CARD_AMD_RADEON_HD5700},    /* Radeon EG JUNIPER LE */
+-    {"HD 5700",                     CARD_AMD_RADEON_HD5700},    /* Radeon EG JUNIPER HD57xx generic renderer string */
+-    {"HD 5670",                     CARD_AMD_RADEON_HD5600},    /* Radeon EG REDWOOD XT */
+-    {"HD 5570",                     CARD_AMD_RADEON_HD5600},    /* Radeon EG REDWOOD PRO mapped to HD5600 series */
+-    {"HD 5550",                     CARD_AMD_RADEON_HD5600},    /* Radeon EG REDWOOD LE mapped to HD5600 series */
+-    {"HD 5450",                     CARD_AMD_RADEON_HD5400},    /* Radeon EG CEDAR PRO */
+-    {"HD 5000",                     CARD_AMD_RADEON_HD5600},    /* Defaulting to HD 5600 */
+-    /* R700 */
+-    {"HD 4890",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV790 */
+-    {"HD 4870",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV770 */
+-    {"HD 4850",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV770 */
+-    {"HD 4830",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV770 */
+-    {"HD 4800",                     CARD_AMD_RADEON_HD4800},    /* Radeon RV7xx HD48xx generic renderer string */
+-    {"HD 4770",                     CARD_AMD_RADEON_HD4700},    /* Radeon RV740 */
+-    {"HD 4700",                     CARD_AMD_RADEON_HD4700},    /* Radeon RV7xx HD47xx generic renderer string */
+-    {"HD 4670",                     CARD_AMD_RADEON_HD4600},    /* Radeon RV730 */
+-    {"HD 4650",                     CARD_AMD_RADEON_HD4600},    /* Radeon RV730 */
+-    {"HD 4600",                     CARD_AMD_RADEON_HD4600},    /* Radeon RV730 */
+-    {"HD 4550",                     CARD_AMD_RADEON_HD4350},    /* Radeon RV710 */
+-    {"HD 4350",                     CARD_AMD_RADEON_HD4350},    /* Radeon RV710 */
+-    /* R600/R700 integrated */
+-    {"HD 4200M",                    CARD_AMD_RADEON_HD4200M},
+-    {"HD 3300",                     CARD_AMD_RADEON_HD3200},
+-    {"HD 3200",                     CARD_AMD_RADEON_HD3200},
+-    {"HD 3100",                     CARD_AMD_RADEON_HD3200},
+-    /* R600 */
+-    {"HD 3870",                     CARD_AMD_RADEON_HD2900},    /* HD2900/HD3800 - highend */
+-    {"HD 3850",                     CARD_AMD_RADEON_HD2900},    /* HD2900/HD3800 - highend */
+-    {"HD 2900",                     CARD_AMD_RADEON_HD2900},    /* HD2900/HD3800 - highend */
+-    {"HD 3830",                     CARD_AMD_RADEON_HD2600},    /* China-only midend */
+-    {"HD 3690",                     CARD_AMD_RADEON_HD2600},    /* HD2600/HD3600 - midend */
+-    {"HD 3650",                     CARD_AMD_RADEON_HD2600},    /* HD2600/HD3600 - midend */
+-    {"HD 2600",                     CARD_AMD_RADEON_HD2600},    /* HD2600/HD3600 - midend */
+-    {"HD 3470",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
+-    {"HD 3450",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
+-    {"HD 3430",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
+-    {"HD 3400",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
+-    {"HD 2400",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
+-    {"HD 2350",                     CARD_AMD_RADEON_HD2350},    /* HD2350/HD2400/HD3400 - lowend */
+-    /* Radeon R5xx */
+-    {"X1950",                       CARD_AMD_RADEON_X1600},
+-    {"X1900",                       CARD_AMD_RADEON_X1600},
+-    {"X1800",                       CARD_AMD_RADEON_X1600},
+-    {"X1650",                       CARD_AMD_RADEON_X1600},
+-    {"X1600",                       CARD_AMD_RADEON_X1600},
+-    /* Radeon R4xx + X1300/X1400/X1450/X1550/X2300/X2500/HD2300 (lowend R5xx)
+-     * Note X2300/X2500/HD2300 are R5xx GPUs with a 2xxx naming but they are still DX9-only */
+-    {"HD 2300",                     CARD_AMD_RADEON_X700},
+-    {"X2500",                       CARD_AMD_RADEON_X700},
+-    {"X2300",                       CARD_AMD_RADEON_X700},
+-    {"X1550",                       CARD_AMD_RADEON_X700},
+-    {"X1450",                       CARD_AMD_RADEON_X700},
+-    {"X1400",                       CARD_AMD_RADEON_X700},
+-    {"X1300",                       CARD_AMD_RADEON_X700},
+-    {"X850",                        CARD_AMD_RADEON_X700},
+-    {"X800",                        CARD_AMD_RADEON_X700},
+-    {"X700",                        CARD_AMD_RADEON_X700},
+-    /* Radeon Xpress Series - onboard, DX9b, Shader 2.0, 300-400 MHz */
+-    {"Radeon Xpress",               CARD_AMD_RADEON_XPRESS_200M},
+-},
+-cards_intel[] =
+-{
+-    /* Skylake */
+-    {"Iris Pro Graphics P580",      CARD_INTEL_IPP580_1},
+-    {"Skylake",                     CARD_INTEL_HD520_1},
+-    /* Broadwell */
+-    {"Iris Pro P6300",              CARD_INTEL_IPP6300},
+-    {"Iris Pro 6200",               CARD_INTEL_IP6200},
+-    {"Iris 6100",                   CARD_INTEL_I6100},
+-    {"Iris(TM) Graphics 6100",      CARD_INTEL_I6100},  /* MacOS */
+-    /* Haswell */
+-    {"Iris Pro 5200",               CARD_INTEL_IP5200_1},
+-    {"Iris 5100",                   CARD_INTEL_I5100_1},
+-    {"HD Graphics 5000",            CARD_INTEL_HD5000}, /* MacOS */
+-    {"Haswell Mobile",              CARD_INTEL_HWM},
+-    {"Iris OpenGL Engine",          CARD_INTEL_HWM},    /* MacOS */
+-    /* Ivybridge */
+-    {"Ivybridge Server",            CARD_INTEL_IVBS},
+-    {"Ivybridge Mobile",            CARD_INTEL_IVBM},
+-    {"Ivybridge Desktop",           CARD_INTEL_IVBD},
+-    {"HD Graphics 4000",            CARD_INTEL_IVBD},   /* MacOS */
+-    /* Sandybridge */
+-    {"Sandybridge Server",          CARD_INTEL_SNBS},
+-    {"Sandybridge Mobile",          CARD_INTEL_SNBM},
+-    {"Sandybridge Desktop",         CARD_INTEL_SNBD},
+-    /* Ironlake */
+-    {"Ironlake Mobile",             CARD_INTEL_ILKM},
+-    {"Ironlake Desktop",            CARD_INTEL_ILKD},
+-    /* G4x */
+-    {"B43",                         CARD_INTEL_B43},
+-    {"G41",                         CARD_INTEL_G41},
+-    {"G45",                         CARD_INTEL_G45},
+-    {"Q45",                         CARD_INTEL_Q45},
+-    {"Integrated Graphics Device",  CARD_INTEL_IGD},
+-    {"GM45",                        CARD_INTEL_GM45},
+-    /* i965 */
+-    {"965GME",                      CARD_INTEL_965GME},
+-    {"965GM",                       CARD_INTEL_965GM},
+-    {"X3100",                       CARD_INTEL_965GM},  /* MacOS */
+-    {"946GZ",                       CARD_INTEL_946GZ},
+-    {"965G",                        CARD_INTEL_965G},
+-    {"965Q",                        CARD_INTEL_965Q},
+-    /* i945 */
+-    {"Pineview M",                  CARD_INTEL_PNVM},
+-    {"Pineview G",                  CARD_INTEL_PNVG},
+-    {"IGD",                         CARD_INTEL_PNVG},
+-    {"Q33",                         CARD_INTEL_Q33},
+-    {"G33",                         CARD_INTEL_G33},
+-    {"Q35",                         CARD_INTEL_Q35},
+-    {"945GME",                      CARD_INTEL_945GME},
+-    {"945GM",                       CARD_INTEL_945GM},
+-    {"GMA 950",                     CARD_INTEL_945GM},  /* MacOS */
+-    {"945G",                        CARD_INTEL_945G},
+-    /* i915 */
+-    {"915GM",                       CARD_INTEL_915GM},
+-    {"E7221G",                      CARD_INTEL_E7221G},
+-    {"915G",                        CARD_INTEL_915G},
+-    /* i8xx */
+-    {"865G",                        CARD_INTEL_865G},
+-    {"845G",                        CARD_INTEL_845G},
+-    {"855GM",                       CARD_INTEL_855GM},
+-    {"830M",                        CARD_INTEL_830M},
+-},
+-/* 20101109 - These are never returned by current Gallium radeon
+- * drivers: R700, RV790, R680, RV535, RV516, R410, RS485, RV360, RV351. */
+-cards_amd_mesa[] =
+-{
+-    /* Polaris 10/11 */
+-    {"POLARIS10",                   CARD_AMD_RADEON_RX_480},
+-    {"POLARIS11",                   CARD_AMD_RADEON_RX_460},
+-    /* Volcanic Islands */
+-    {"FIJI",                        CARD_AMD_RADEON_R9_FURY},
+-    {"TONGA",                       CARD_AMD_RADEON_R9_285},
+-    /* Sea Islands */
+-    {"HAWAII",                      CARD_AMD_RADEON_R9_290},
+-    {"KAVERI",                      CARD_AMD_RADEON_R7    },
+-    {"KABINI",                      CARD_AMD_RADEON_R3    },
+-    {"BONAIRE",                     CARD_AMD_RADEON_HD8770},
+-    /* Southern Islands */
+-    {"OLAND",                       CARD_AMD_RADEON_HD8670},
+-    {"HAINAN",                      CARD_AMD_RADEON_HD8600M},
+-    {"TAHITI",                      CARD_AMD_RADEON_HD7900},
+-    {"PITCAIRN",                    CARD_AMD_RADEON_HD7800},
+-    {"CAPE VERDE",                  CARD_AMD_RADEON_HD7700},
+-    /* Northern Islands */
+-    {"ARUBA",                       CARD_AMD_RADEON_HD7660D},
+-    {"CAYMAN",                      CARD_AMD_RADEON_HD6900},
+-    {"BARTS",                       CARD_AMD_RADEON_HD6800},
+-    {"TURKS",                       CARD_AMD_RADEON_HD6600},
+-    {"SUMO2",                       CARD_AMD_RADEON_HD6410D},   /* SUMO2 first, because we do a strstr(). */
+-    {"SUMO",                        CARD_AMD_RADEON_HD6550D},
+-    {"CAICOS",                      CARD_AMD_RADEON_HD6400},
+-    {"PALM",                        CARD_AMD_RADEON_HD6300},
+-    /* Evergreen */
+-    {"HEMLOCK",                     CARD_AMD_RADEON_HD5900},
+-    {"CYPRESS",                     CARD_AMD_RADEON_HD5800},
+-    {"JUNIPER",                     CARD_AMD_RADEON_HD5700},
+-    {"REDWOOD",                     CARD_AMD_RADEON_HD5600},
+-    {"CEDAR",                       CARD_AMD_RADEON_HD5400},
+-    /* R700 */
+-    {"R700",                        CARD_AMD_RADEON_HD4800},
+-    {"RV790",                       CARD_AMD_RADEON_HD4800},
+-    {"RV770",                       CARD_AMD_RADEON_HD4800},
+-    {"RV740",                       CARD_AMD_RADEON_HD4700},
+-    {"RV730",                       CARD_AMD_RADEON_HD4600},
+-    {"RV710",                       CARD_AMD_RADEON_HD4350},
+-    /* R600/R700 integrated */
+-    {"RS880",                       CARD_AMD_RADEON_HD4200M},
+-    {"RS780",                       CARD_AMD_RADEON_HD3200},
+-    /* R600 */
+-    {"R680",                        CARD_AMD_RADEON_HD2900},
+-    {"R600",                        CARD_AMD_RADEON_HD2900},
+-    {"RV670",                       CARD_AMD_RADEON_HD3850},
+-    {"RV635",                       CARD_AMD_RADEON_HD2600},
+-    {"RV630",                       CARD_AMD_RADEON_HD2600},
+-    {"RV620",                       CARD_AMD_RADEON_HD2350},
+-    {"RV610",                       CARD_AMD_RADEON_HD2350},
+-    /* R500 */
+-    {"R580",                        CARD_AMD_RADEON_X1600},
+-    {"R520",                        CARD_AMD_RADEON_X1600},
+-    {"RV570",                       CARD_AMD_RADEON_X1600},
+-    {"RV560",                       CARD_AMD_RADEON_X1600},
+-    {"RV535",                       CARD_AMD_RADEON_X1600},
+-    {"RV530",                       CARD_AMD_RADEON_X1600},
+-    {"RV516",                       CARD_AMD_RADEON_X700},
+-    {"RV515",                       CARD_AMD_RADEON_X700},
+-    /* R400 */
+-    {"R481",                        CARD_AMD_RADEON_X700},
+-    {"R480",                        CARD_AMD_RADEON_X700},
+-    {"R430",                        CARD_AMD_RADEON_X700},
+-    {"R423",                        CARD_AMD_RADEON_X700},
+-    {"R420",                        CARD_AMD_RADEON_X700},
+-    {"R410",                        CARD_AMD_RADEON_X700},
+-    {"RV410",                       CARD_AMD_RADEON_X700},
+-    /* Radeon Xpress - onboard, DX9b, Shader 2.0, 300-400 MHz */
+-    {"RS740",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RS690",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RS600",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RS485",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RS482",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RS480",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RS400",                       CARD_AMD_RADEON_XPRESS_200M},
+-    {"RC410",                       CARD_AMD_RADEON_XPRESS_200M},
+-    /* R300 */
+-    {"R360",                        CARD_AMD_RADEON_9500},
+-    {"R350",                        CARD_AMD_RADEON_9500},
+-    {"R300",                        CARD_AMD_RADEON_9500},
+-    {"RV380",                       CARD_AMD_RADEON_9500},
+-    {"RV370",                       CARD_AMD_RADEON_9500},
+-    {"RV360",                       CARD_AMD_RADEON_9500},
+-    {"RV351",                       CARD_AMD_RADEON_9500},
+-    {"RV350",                       CARD_AMD_RADEON_9500},
+-},
+-cards_nvidia_mesa[] =
+-{
+-    /* Maxwell */
+-    {"NV124",                       CARD_NVIDIA_GEFORCE_GTX970},
+-    {"NV120",                       CARD_NVIDIA_GEFORCE_GTX980TI},
+-    {"NV118",                       CARD_NVIDIA_GEFORCE_840M},
+-    {"NV117",                       CARD_NVIDIA_GEFORCE_GTX750},
+-    /* Kepler */
+-    {"NV108",                       CARD_NVIDIA_GEFORCE_GT740M},
+-    {"NVF1",                        CARD_NVIDIA_GEFORCE_GTX780TI},
+-    {"NVF0",                        CARD_NVIDIA_GEFORCE_GTX780},
+-    {"NVE6",                        CARD_NVIDIA_GEFORCE_GTX770M},
+-    {"NVE4",                        CARD_NVIDIA_GEFORCE_GTX680},    /* 690 / 675MX / 760TI */
+-    /* Fermi */
+-    {"NVD9",                        CARD_NVIDIA_GEFORCE_GT520},
+-    {"NVD7",                        CARD_NVIDIA_GEFORCE_820M},
+-    {"NVCF",                        CARD_NVIDIA_GEFORCE_GTX550},
+-    {"NVCE",                        CARD_NVIDIA_GEFORCE_GTX560},
+-    {"NVC8",                        CARD_NVIDIA_GEFORCE_GTX570},
+-    {"NVC4",                        CARD_NVIDIA_GEFORCE_GTX460},
+-    {"NVC3",                        CARD_NVIDIA_GEFORCE_GT440},
+-    {"NVC1",                        CARD_NVIDIA_GEFORCE_GT420},
+-    {"NVC0",                        CARD_NVIDIA_GEFORCE_GTX480},
+-    /* Tesla */
+-    {"NVAF",                        CARD_NVIDIA_GEFORCE_GT320M},
+-    {"NVAC",                        CARD_NVIDIA_GEFORCE_8200},
+-    {"NVAA",                        CARD_NVIDIA_GEFORCE_8200},      /* 8100 */
+-    {"NVA8",                        CARD_NVIDIA_GEFORCE_210},
+-    {"NVA5",                        CARD_NVIDIA_GEFORCE_GT220},
+-    {"NVA3",                        CARD_NVIDIA_GEFORCE_GT240},
+-    {"NVA0",                        CARD_NVIDIA_GEFORCE_GTX280},
+-    {"NV98",                        CARD_NVIDIA_GEFORCE_9200},
+-    {"NV96",                        CARD_NVIDIA_GEFORCE_9400GT},
+-    {"NV94",                        CARD_NVIDIA_GEFORCE_9600GT},
+-    {"NV92",                        CARD_NVIDIA_GEFORCE_9800GT},
+-    {"NV86",                        CARD_NVIDIA_GEFORCE_8500GT},
+-    {"NV84",                        CARD_NVIDIA_GEFORCE_8600GT},
+-    {"NV50",                        CARD_NVIDIA_GEFORCE_8800GTX},
+-    /* Curie */
+-    {"NV68",                        CARD_NVIDIA_GEFORCE_6200},      /* 7050 */
+-    {"NV67",                        CARD_NVIDIA_GEFORCE_6200},      /* 7000M */
+-    {"NV63",                        CARD_NVIDIA_GEFORCE_6200},      /* 7100 */
+-    {"NV4E",                        CARD_NVIDIA_GEFORCE_6200},      /* 6100 Go / 6150 Go */
+-    {"NV4C",                        CARD_NVIDIA_GEFORCE_6200},      /* 6150SE */
+-    {"NV4B",                        CARD_NVIDIA_GEFORCE_7600},
+-    {"NV4A",                        CARD_NVIDIA_GEFORCE_6200},
+-    {"NV49",                        CARD_NVIDIA_GEFORCE_7800GT},    /* 7900 */
+-    {"NV47",                        CARD_NVIDIA_GEFORCE_7800GT},
+-    {"NV46",                        CARD_NVIDIA_GEFORCE_7400},
+-    {"NV45",                        CARD_NVIDIA_GEFORCE_6800},
+-    {"NV44",                        CARD_NVIDIA_GEFORCE_6200},
+-    {"NV43",                        CARD_NVIDIA_GEFORCE_6600GT},
+-    {"NV42",                        CARD_NVIDIA_GEFORCE_6800},
+-    {"NV41",                        CARD_NVIDIA_GEFORCE_6800},
+-    {"NV40",                        CARD_NVIDIA_GEFORCE_6800},
+-    /* Rankine */
+-    {"NV38",                        CARD_NVIDIA_GEFORCEFX_5800},    /* FX 5950 Ultra */
+-    {"NV36",                        CARD_NVIDIA_GEFORCEFX_5800},    /* FX 5700/5750 */
+-    {"NV35",                        CARD_NVIDIA_GEFORCEFX_5800},    /* FX 5900 */
+-    {"NV34",                        CARD_NVIDIA_GEFORCEFX_5200},
+-    {"NV31",                        CARD_NVIDIA_GEFORCEFX_5600},
+-    {"NV30",                        CARD_NVIDIA_GEFORCEFX_5800},
+-    /* Kelvin */
+-    {"nv28",                        CARD_NVIDIA_GEFORCE4_TI4200},
+-    {"nv25",                        CARD_NVIDIA_GEFORCE4_TI4200},
+-    {"nv20",                        CARD_NVIDIA_GEFORCE3},
+-    /* Celsius */
+-    {"nv1F",                        CARD_NVIDIA_GEFORCE4_MX},       /* GF4 MX IGP */
+-    {"nv1A",                        CARD_NVIDIA_GEFORCE2},          /* GF2 IGP */
+-    {"nv18",                        CARD_NVIDIA_GEFORCE4_MX},
+-    {"nv17",                        CARD_NVIDIA_GEFORCE4_MX},
+-    {"nv16",                        CARD_NVIDIA_GEFORCE2},
+-    {"nv15",                        CARD_NVIDIA_GEFORCE2},
+-    {"nv11",                        CARD_NVIDIA_GEFORCE2_MX},
+-    {"nv10",                        CARD_NVIDIA_GEFORCE},
+-    /* Fahrenheit */
+-    {"nv05",                        CARD_NVIDIA_RIVA_TNT2},
+-    {"nv04",                        CARD_NVIDIA_RIVA_TNT},
+-    {"nv03",                        CARD_NVIDIA_RIVA_128},
+-},
+-cards_vmware[] =
+-{
+-    {"SVGA3D",                      CARD_VMWARE_SVGA3D},
+-};
+-
+-static const struct gl_vendor_selection
+-{
+-    enum wined3d_gl_vendor gl_vendor;
+-    const char *description;        /* Description of the card selector i.e. Apple OS/X Intel */
+-    const struct wined3d_renderer_table *cards; /* To be used as cards[], pointer to the first member in an array */
+-    size_t cards_size;              /* Number of entries in the array above */
+-}
+-amd_gl_vendor_table[] =
+-{
+-    {GL_VENDOR_APPLE,   "Apple OSX AMD/ATI binary driver",  cards_amd_binary,       ARRAY_SIZE(cards_amd_binary)},
+-    {GL_VENDOR_FGLRX,   "AMD/ATI binary driver",            cards_amd_binary,       ARRAY_SIZE(cards_amd_binary)},
+-    {GL_VENDOR_MESA,    "Mesa AMD/ATI driver",              cards_amd_mesa,         ARRAY_SIZE(cards_amd_mesa)},
+-},
+-nvidia_gl_vendor_table[] =
+-{
+-    {GL_VENDOR_APPLE,   "Apple OSX NVidia binary driver",   cards_nvidia_binary,    ARRAY_SIZE(cards_nvidia_binary)},
+-    {GL_VENDOR_MESA,    "Mesa Nouveau driver",              cards_nvidia_mesa,      ARRAY_SIZE(cards_nvidia_mesa)},
+-    {GL_VENDOR_NVIDIA,  "Nvidia binary driver",             cards_nvidia_binary,    ARRAY_SIZE(cards_nvidia_binary)},
+-},
+-vmware_gl_vendor_table[] =
+-{
+-    {GL_VENDOR_MESA,    "VMware driver",                    cards_vmware,           ARRAY_SIZE(cards_vmware)},
+-},
+-intel_gl_vendor_table[] =
+-{
+-    {GL_VENDOR_APPLE,   "Apple OSX Intel binary driver",    cards_intel,            ARRAY_SIZE(cards_intel)},
+-    {GL_VENDOR_MESA,    "Mesa Intel driver",                cards_intel,            ARRAY_SIZE(cards_intel)},
+-};
+-
+-static const enum wined3d_pci_device
+-card_fallback_nvidia[] =
+-{
+-    CARD_NVIDIA_RIVA_128,           /* D3D5 */
+-    CARD_NVIDIA_RIVA_TNT,           /* D3D6 */
+-    CARD_NVIDIA_GEFORCE,            /* D3D7 */
+-    CARD_NVIDIA_GEFORCE3,           /* D3D8 */
+-    CARD_NVIDIA_GEFORCEFX_5800,     /* D3D9_SM2 */
+-    CARD_NVIDIA_GEFORCE_6800,       /* D3D9_SM3 */
+-    CARD_NVIDIA_GEFORCE_8800GTX,    /* D3D10 */
+-    CARD_NVIDIA_GEFORCE_GTX470,     /* D3D11 */
+-},
+-card_fallback_amd[] =
+-{
+-    CARD_AMD_RAGE_128PRO,           /* D3D5 */
+-    CARD_AMD_RAGE_128PRO,           /* D3D6 */
+-    CARD_AMD_RADEON_7200,           /* D3D7 */
+-    CARD_AMD_RADEON_8500,           /* D3D8 */
+-    CARD_AMD_RADEON_9500,           /* D3D9_SM2 */
+-    CARD_AMD_RADEON_X1600,          /* D3D9_SM3 */
+-    CARD_AMD_RADEON_HD2900,         /* D3D10 */
+-    CARD_AMD_RADEON_HD5600,         /* D3D11 */
+-},
+-card_fallback_intel[] =
+-{
+-    CARD_INTEL_845G,                /* D3D5 */
+-    CARD_INTEL_845G,                /* D3D6 */
+-    CARD_INTEL_845G,                /* D3D7 */
+-    CARD_INTEL_915G,                /* D3D8 */
+-    CARD_INTEL_915G,                /* D3D9_SM2 */
+-    CARD_INTEL_945G,                /* D3D9_SM3 */
+-    CARD_INTEL_G45,                 /* D3D10 */
+-    CARD_INTEL_IVBD,                /* D3D11 */
+-};
+-C_ASSERT(ARRAY_SIZE(card_fallback_nvidia)  == WINED3D_FEATURE_LEVEL_COUNT);
+-C_ASSERT(ARRAY_SIZE(card_fallback_amd)     == WINED3D_FEATURE_LEVEL_COUNT);
+-C_ASSERT(ARRAY_SIZE(card_fallback_intel)   == WINED3D_FEATURE_LEVEL_COUNT);
+-
+-static enum wined3d_pci_device select_card_handler(const struct gl_vendor_selection *table,
+-        unsigned int table_size, enum wined3d_gl_vendor gl_vendor, const char *gl_renderer)
+-{
+-    unsigned int i, j;
+-
+-    for (i = 0; i < table_size; ++i)
+-    {
+-        if (table[i].gl_vendor != gl_vendor)
+-            continue;
+-
+-        TRACE("Applying card selector \"%s\".\n", table[i].description);
+-
+-        for (j = 0; j < table[i].cards_size; ++j)
+-        {
+-            if (strstr(gl_renderer, table[i].cards[j].renderer))
+-                return table[i].cards[j].id;
+-        }
+-        return PCI_DEVICE_NONE;
+-    }
+-    FIXME("Couldn't find a suitable card selector for GL vendor %04x (using GL_RENDERER %s)\n",
+-            gl_vendor, debugstr_a(gl_renderer));
+-
+-    return PCI_DEVICE_NONE;
+-}
+-
+-static const struct
+-{
+-    enum wined3d_pci_vendor card_vendor;
+-    const char *description;        /* Description of the card selector i.e. Apple OS/X Intel */
+-    const struct gl_vendor_selection *gl_vendor_selection;
+-    unsigned int gl_vendor_count;
+-    const enum wined3d_pci_device *card_fallback; /* An array with FEATURE_LEVEL_COUNT elements */
+-}
+-card_vendor_table[] =
+-{
+-    {HW_VENDOR_AMD,         "AMD",      amd_gl_vendor_table,
+-            ARRAY_SIZE(amd_gl_vendor_table),
+-            card_fallback_amd},
+-    {HW_VENDOR_NVIDIA,      "Nvidia",   nvidia_gl_vendor_table,
+-            ARRAY_SIZE(nvidia_gl_vendor_table),
+-            card_fallback_nvidia},
+-    {HW_VENDOR_VMWARE,      "VMware",   vmware_gl_vendor_table,
+-            ARRAY_SIZE(vmware_gl_vendor_table),
+-            card_fallback_amd},
+-    {HW_VENDOR_INTEL,       "Intel",    intel_gl_vendor_table,
+-            ARRAY_SIZE(intel_gl_vendor_table),
+-            card_fallback_intel},
+-};
+-
+-static enum wined3d_pci_device wined3d_guess_card(enum wined3d_feature_level feature_level,
+-        DWORD glsl_version, const char *gl_renderer, enum wined3d_gl_vendor *gl_vendor,
+-        enum wined3d_pci_vendor *card_vendor)
+-{
+-    /* A Direct3D device object contains the PCI id (vendor + device) of the
+-     * videocard which is used for rendering. Various applications use this
+-     * information to get a rough estimation of the features of the card and
+-     * some might use it for enabling 3d effects only on certain types of
+-     * videocards. In some cases games might even use it to work around bugs
+-     * which happen on certain videocards/driver combinations. The problem is
+-     * that OpenGL only exposes a rendering string containing the name of the
+-     * videocard and not the PCI id.
+-     *
+-     * Various games depend on the PCI id, so somehow we need to provide one.
+-     * A simple option is to parse the renderer string and translate this to
+-     * the right PCI id. This is a lot of work because there are more than 200
+-     * GPUs just for Nvidia. Various cards share the same renderer string, so
+-     * the amount of code might be 'small' but there are quite a number of
+-     * exceptions which would make this a pain to maintain. Another way would
+-     * be to query the PCI id from the operating system (assuming this is the
+-     * videocard which is used for rendering which is not always the case).
+-     * This would work but it is not very portable. Second it would not work
+-     * well in, let's say, a remote X situation in which the amount of 3d
+-     * features which can be used is limited.
+-     *
+-     * As said most games only use the PCI id to get an indication of the
+-     * capabilities of the card. It doesn't really matter if the given id is
+-     * the correct one if we return the id of a card with similar 3d features.
+-     *
+-     * The code below checks the OpenGL capabilities of a videocard and matches
+-     * that to a certain level of Direct3D functionality. Once a card passes
+-     * the Direct3D9 check, we know that the card (in case of Nvidia) is at
+-     * least a GeforceFX. To give a better estimate we do a basic check on the
+-     * renderer string but if that won't pass we return a default card. This
+-     * way is better than maintaining a full card database as even without a
+-     * full database we can return a card with similar features. Second the
+-     * size of the database can be made quite small because when you know what
+-     * type of 3d functionality a card has, you know to which GPU family the
+-     * GPU must belong. Because of this you only have to check a small part of
+-     * the renderer string to distinguish between different models from that
+-     * family.
+-     *
+-     * The code also selects a default amount of video memory which we will
+-     * use for an estimation of the amount of free texture memory. In case of
+-     * real D3D the amount of texture memory includes video memory and system
+-     * memory (to be specific AGP memory or in case of PCIE TurboCache /
+-     * HyperMemory). We don't know how much system memory can be addressed by
+-     * the system but we can make a reasonable estimation about the amount of
+-     * video memory. If the value is slightly wrong it doesn't matter as we
+-     * didn't include AGP-like memory which makes the amount of addressable
+-     * memory higher and second OpenGL isn't that critical it moves to system
+-     * memory behind our backs if really needed. Note that the amount of video
+-     * memory can be overruled using a registry setting. */
+-
+-    enum wined3d_pci_device device;
+-    unsigned int i;
+-
+-    for (i = 0; i < ARRAY_SIZE(card_vendor_table); ++i)
+-    {
+-        if (card_vendor_table[i].card_vendor != *card_vendor)
+-            continue;
+-
+-        TRACE("Applying card selector \"%s\".\n", card_vendor_table[i].description);
+-        device = select_card_handler(card_vendor_table[i].gl_vendor_selection,
+-                card_vendor_table[i].gl_vendor_count, *gl_vendor, gl_renderer);
+-        if (device != PCI_DEVICE_NONE)
+-            return device;
+-
+-        TRACE("Unrecognized renderer %s, falling back to default.\n", debugstr_a(gl_renderer));
+-        return card_vendor_table[i].card_fallback[feature_level];
+-    }
+-
+-    FIXME("No card selector available for card vendor %04x (using GL_RENDERER %s).\n",
+-            *card_vendor, debugstr_a(gl_renderer));
+-
+-    /* Default to generic Nvidia hardware based on the supported OpenGL extensions. */
+-    *card_vendor = HW_VENDOR_NVIDIA;
+-    return card_fallback_nvidia[feature_level];
+-}
+-
+-static const struct wined3d_vertex_pipe_ops *select_vertex_implementation(const struct wined3d_gl_info *gl_info,
+-        const struct wined3d_shader_backend_ops *shader_backend_ops)
+-{
+-    if (shader_backend_ops == &glsl_shader_backend && gl_info->supported[ARB_VERTEX_SHADER])
+-        return &glsl_vertex_pipe;
+-    return &ffp_vertex_pipe;
+-}
+-
+-static const struct fragment_pipeline *select_fragment_implementation(const struct wined3d_gl_info *gl_info,
+-        const struct wined3d_shader_backend_ops *shader_backend_ops)
+-{
+-    if (shader_backend_ops == &glsl_shader_backend && gl_info->supported[ARB_FRAGMENT_SHADER])
+-        return &glsl_fragment_pipe;
+-    if (gl_info->supported[ARB_FRAGMENT_PROGRAM])
+-        return &arbfp_fragment_pipeline;
+-    if (gl_info->supported[ATI_FRAGMENT_SHADER])
+-        return &atifs_fragment_pipeline;
+-    if (gl_info->supported[NV_REGISTER_COMBINERS] && gl_info->supported[NV_TEXTURE_SHADER2])
+-        return &nvts_fragment_pipeline;
+-    if (gl_info->supported[NV_REGISTER_COMBINERS])
+-        return &nvrc_fragment_pipeline;
+-    return &ffp_fragment_pipeline;
+-}
+-
+-static const struct wined3d_shader_backend_ops *select_shader_backend(const struct wined3d_gl_info *gl_info)
+-{
+-    BOOL glsl = wined3d_settings.use_glsl && gl_info->glsl_version >= MAKEDWORD_VERSION(1, 20);
+-    if (!gl_info->supported[WINED3D_GL_LEGACY_CONTEXT] && !wined3d_settings.use_glsl)
+-    {
+-        ERR_(winediag)("Ignoring the UseGLSL registry key. "
+-                "GLSL is the only shader backend available on core profile contexts. "
+-                "You need to explicitly set GL version to use legacy contexts.\n");
+-        glsl = TRUE;
+-    }
+-
+-    if (glsl && gl_info->supported[ARB_VERTEX_SHADER] && gl_info->supported[ARB_FRAGMENT_SHADER])
+-        return &glsl_shader_backend;
+-    if (gl_info->supported[ARB_VERTEX_PROGRAM] && gl_info->supported[ARB_FRAGMENT_PROGRAM])
+-        return &arb_program_shader_backend;
+-    if (glsl && (gl_info->supported[ARB_VERTEX_SHADER] || gl_info->supported[ARB_FRAGMENT_SHADER]))
+-        return &glsl_shader_backend;
+-    if (gl_info->supported[ARB_VERTEX_PROGRAM] || gl_info->supported[ARB_FRAGMENT_PROGRAM])
+-        return &arb_program_shader_backend;
+-    return &none_shader_backend;
+-}
+-
+-static void parse_extension_string(struct wined3d_gl_info *gl_info, const char *extensions,
+-        const struct wined3d_extension_map *map, UINT entry_count)
+-{
+-    while (*extensions)
+-    {
+-        const char *start;
+-        size_t len;
+-        UINT i;
+-
+-        while (isspace(*extensions))
+-            ++extensions;
+-        start = extensions;
+-        while (!isspace(*extensions) && *extensions)
+-            ++extensions;
+-
+-        len = extensions - start;
+-        if (!len)
+-            continue;
+-
+-        TRACE("- %s.\n", debugstr_an(start, len));
+-
+-        for (i = 0; i < entry_count; ++i)
+-        {
+-            if (len == strlen(map[i].extension_string)
+-                    && !memcmp(start, map[i].extension_string, len))
+-            {
+-                TRACE(" FOUND: %s support.\n", map[i].extension_string);
+-                gl_info->supported[map[i].extension] = TRUE;
+-                break;
+-            }
+-        }
+-    }
+-}
+-
+-static void enumerate_gl_extensions(struct wined3d_gl_info *gl_info,
+-        const struct wined3d_extension_map *map, unsigned int map_entries_count)
+-{
+-    const char *gl_extension_name;
+-    unsigned int i, j;
+-    GLint extensions_count;
+-
+-    gl_info->gl_ops.gl.p_glGetIntegerv(GL_NUM_EXTENSIONS, &extensions_count);
+-    for (i = 0; i < extensions_count; ++i)
+-    {
+-        gl_extension_name = (const char *)GL_EXTCALL(glGetStringi(GL_EXTENSIONS, i));
+-        TRACE("- %s.\n", debugstr_a(gl_extension_name));
+-        for (j = 0; j < map_entries_count; ++j)
+-        {
+-            if (!strcmp(gl_extension_name, map[j].extension_string))
+-            {
+-                TRACE("FOUND: %s support.\n", map[j].extension_string);
+-                gl_info->supported[map[j].extension] = TRUE;
+-                break;
+-            }
+-        }
+-    }
+-}
+-
+-static void load_gl_funcs(struct wined3d_gl_info *gl_info)
+-{
+-#define USE_GL_FUNC(pfn) gl_info->gl_ops.ext.p_##pfn = (void *)wglGetProcAddress(#pfn);
+-    /* GL_APPLE_fence */
+-    USE_GL_FUNC(glDeleteFencesAPPLE)
+-    USE_GL_FUNC(glFinishFenceAPPLE)
+-    USE_GL_FUNC(glFinishObjectAPPLE)
+-    USE_GL_FUNC(glGenFencesAPPLE)
+-    USE_GL_FUNC(glIsFenceAPPLE)
+-    USE_GL_FUNC(glSetFenceAPPLE)
+-    USE_GL_FUNC(glTestFenceAPPLE)
+-    USE_GL_FUNC(glTestObjectAPPLE)
+-    /* GL_APPLE_flush_buffer_range */
+-    USE_GL_FUNC(glBufferParameteriAPPLE)
+-    USE_GL_FUNC(glFlushMappedBufferRangeAPPLE)
+-    /* GL_ARB_base_instance */
+-    USE_GL_FUNC(glDrawArraysInstancedBaseInstance)
+-    USE_GL_FUNC(glDrawElementsInstancedBaseVertexBaseInstance)
+-    /* GL_ARB_blend_func_extended */
+-    USE_GL_FUNC(glBindFragDataLocationIndexed)
+-    USE_GL_FUNC(glGetFragDataIndex)
+-    /* GL_ARB_buffer_storage */
+-    USE_GL_FUNC(glBufferStorage)
+-    /* GL_ARB_clear_buffer_object */
+-    USE_GL_FUNC(glClearBufferData)
+-    USE_GL_FUNC(glClearBufferSubData)
+-    /* GL_ARB_clear_texture */
+-    USE_GL_FUNC(glClearTexImage)
+-    USE_GL_FUNC(glClearTexSubImage)
+-    /* GL_ARB_clip_control */
+-    USE_GL_FUNC(glClipControl)
+-    /* GL_ARB_color_buffer_float */
+-    USE_GL_FUNC(glClampColorARB)
+-    /* GL_ARB_compute_shader */
+-    USE_GL_FUNC(glDispatchCompute)
+-    USE_GL_FUNC(glDispatchComputeIndirect)
+-    /* GL_ARB_copy_buffer */
+-    USE_GL_FUNC(glCopyBufferSubData)
+-    /* GL_ARB_copy_image */
+-    USE_GL_FUNC(glCopyImageSubData)
+-    /* GL_ARB_debug_output */
+-    USE_GL_FUNC(glDebugMessageCallbackARB)
+-    USE_GL_FUNC(glDebugMessageControlARB)
+-    USE_GL_FUNC(glDebugMessageInsertARB)
+-    USE_GL_FUNC(glGetDebugMessageLogARB)
+-    /* GL_ARB_draw_buffers */
+-    USE_GL_FUNC(glDrawBuffersARB)
+-    /* GL_ARB_draw_elements_base_vertex */
+-    USE_GL_FUNC(glDrawElementsBaseVertex)
+-    USE_GL_FUNC(glDrawElementsInstancedBaseVertex)
+-    USE_GL_FUNC(glDrawRangeElementsBaseVertex)
+-    USE_GL_FUNC(glMultiDrawElementsBaseVertex)
+-    /* GL_ARB_draw_indirect */
+-    USE_GL_FUNC(glDrawArraysIndirect)
+-    USE_GL_FUNC(glDrawElementsIndirect)
+-    /* GL_ARB_draw_instanced */
+-    USE_GL_FUNC(glDrawArraysInstancedARB)
+-    USE_GL_FUNC(glDrawElementsInstancedARB)
+-    /* GL_ARB_ES2_compatibility */
+-    USE_GL_FUNC(glReleaseShaderCompiler)
+-    USE_GL_FUNC(glShaderBinary)
+-    USE_GL_FUNC(glGetShaderPrecisionFormat)
+-    USE_GL_FUNC(glDepthRangef)
+-    USE_GL_FUNC(glClearDepthf)
+-    /* GL_ARB_framebuffer_no_attachments */
+-    USE_GL_FUNC(glFramebufferParameteri)
+-    /* GL_ARB_framebuffer_object */
+-    USE_GL_FUNC(glBindFramebuffer)
+-    USE_GL_FUNC(glBindRenderbuffer)
+-    USE_GL_FUNC(glBlitFramebuffer)
+-    USE_GL_FUNC(glCheckFramebufferStatus)
+-    USE_GL_FUNC(glDeleteFramebuffers)
+-    USE_GL_FUNC(glDeleteRenderbuffers)
+-    USE_GL_FUNC(glFramebufferRenderbuffer)
+-    USE_GL_FUNC(glFramebufferTexture)
+-    USE_GL_FUNC(glFramebufferTexture1D)
+-    USE_GL_FUNC(glFramebufferTexture2D)
+-    USE_GL_FUNC(glFramebufferTexture3D)
+-    USE_GL_FUNC(glFramebufferTextureLayer)
+-    USE_GL_FUNC(glGenFramebuffers)
+-    USE_GL_FUNC(glGenRenderbuffers)
+-    USE_GL_FUNC(glGenerateMipmap)
+-    USE_GL_FUNC(glGetFramebufferAttachmentParameteriv)
+-    USE_GL_FUNC(glGetRenderbufferParameteriv)
+-    USE_GL_FUNC(glIsFramebuffer)
+-    USE_GL_FUNC(glIsRenderbuffer)
+-    USE_GL_FUNC(glRenderbufferStorage)
+-    USE_GL_FUNC(glRenderbufferStorageMultisample)
+-    /* GL_ARB_geometry_shader4 */
+-    USE_GL_FUNC(glFramebufferTextureARB)
+-    USE_GL_FUNC(glFramebufferTextureFaceARB)
+-    USE_GL_FUNC(glFramebufferTextureLayerARB)
+-    USE_GL_FUNC(glProgramParameteriARB)
+-    /* GL_ARB_instanced_arrays */
+-    USE_GL_FUNC(glVertexAttribDivisorARB)
+-    /* GL_ARB_internalformat_query */
+-    USE_GL_FUNC(glGetInternalformativ)
+-    /* GL_ARB_internalformat_query2 */
+-    USE_GL_FUNC(glGetInternalformati64v)
+-    /* GL_ARB_map_buffer_range */
+-    USE_GL_FUNC(glFlushMappedBufferRange)
+-    USE_GL_FUNC(glMapBufferRange)
+-    /* GL_ARB_multi_bind */
+-    USE_GL_FUNC(glBindBuffersRange)
+-    /* GL_ARB_multisample */
+-    USE_GL_FUNC(glSampleCoverageARB)
+-    /* GL_ARB_multitexture */
+-    USE_GL_FUNC(glActiveTextureARB)
+-    USE_GL_FUNC(glClientActiveTextureARB)
+-    USE_GL_FUNC(glMultiTexCoord1fARB)
+-    USE_GL_FUNC(glMultiTexCoord1fvARB)
+-    USE_GL_FUNC(glMultiTexCoord2fARB)
+-    USE_GL_FUNC(glMultiTexCoord2fvARB)
+-    USE_GL_FUNC(glMultiTexCoord2svARB)
+-    USE_GL_FUNC(glMultiTexCoord3fARB)
+-    USE_GL_FUNC(glMultiTexCoord3fvARB)
+-    USE_GL_FUNC(glMultiTexCoord4fARB)
+-    USE_GL_FUNC(glMultiTexCoord4fvARB)
+-    USE_GL_FUNC(glMultiTexCoord4svARB)
+-    /* GL_ARB_occlusion_query */
+-    USE_GL_FUNC(glBeginQueryARB)
+-    USE_GL_FUNC(glDeleteQueriesARB)
+-    USE_GL_FUNC(glEndQueryARB)
+-    USE_GL_FUNC(glGenQueriesARB)
+-    USE_GL_FUNC(glGetQueryivARB)
+-    USE_GL_FUNC(glGetQueryObjectivARB)
+-    USE_GL_FUNC(glGetQueryObjectuivARB)
+-    USE_GL_FUNC(glIsQueryARB)
+-    /* GL_ARB_point_parameters */
+-    USE_GL_FUNC(glPointParameterfARB)
+-    USE_GL_FUNC(glPointParameterfvARB)
+-    /* GL_ARB_provoking_vertex */
+-    USE_GL_FUNC(glProvokingVertex)
+-    /* GL_ARB_sample_shading */
+-    USE_GL_FUNC(glMinSampleShadingARB)
+-    /* GL_ARB_sampler_objects */
+-    USE_GL_FUNC(glGenSamplers)
+-    USE_GL_FUNC(glDeleteSamplers)
+-    USE_GL_FUNC(glIsSampler)
+-    USE_GL_FUNC(glBindSampler)
+-    USE_GL_FUNC(glSamplerParameteri)
+-    USE_GL_FUNC(glSamplerParameterf)
+-    USE_GL_FUNC(glSamplerParameteriv)
+-    USE_GL_FUNC(glSamplerParameterfv)
+-    USE_GL_FUNC(glSamplerParameterIiv)
+-    USE_GL_FUNC(glSamplerParameterIuiv)
+-    USE_GL_FUNC(glGetSamplerParameteriv)
+-    USE_GL_FUNC(glGetSamplerParameterfv)
+-    USE_GL_FUNC(glGetSamplerParameterIiv)
+-    USE_GL_FUNC(glGetSamplerParameterIuiv)
+-    /* GL_ARB_shader_atomic_counters */
+-    USE_GL_FUNC(glGetActiveAtomicCounterBufferiv)
+-    /* GL_ARB_shader_image_load_store */
+-    USE_GL_FUNC(glBindImageTexture)
+-    USE_GL_FUNC(glMemoryBarrier)
+-    /* GL_ARB_shader_objects */
+-    USE_GL_FUNC(glAttachObjectARB)
+-    USE_GL_FUNC(glBindAttribLocationARB)
+-    USE_GL_FUNC(glCompileShaderARB)
+-    USE_GL_FUNC(glCreateProgramObjectARB)
+-    USE_GL_FUNC(glCreateShaderObjectARB)
+-    USE_GL_FUNC(glDeleteObjectARB)
+-    USE_GL_FUNC(glDetachObjectARB)
+-    USE_GL_FUNC(glGetActiveUniformARB)
+-    USE_GL_FUNC(glGetAttachedObjectsARB)
+-    USE_GL_FUNC(glGetAttribLocationARB)
+-    USE_GL_FUNC(glGetHandleARB)
+-    USE_GL_FUNC(glGetInfoLogARB)
+-    USE_GL_FUNC(glGetObjectParameterfvARB)
+-    USE_GL_FUNC(glGetObjectParameterivARB)
+-    USE_GL_FUNC(glGetShaderSourceARB)
+-    USE_GL_FUNC(glGetUniformLocationARB)
+-    USE_GL_FUNC(glGetUniformfvARB)
+-    USE_GL_FUNC(glGetUniformivARB)
+-    USE_GL_FUNC(glLinkProgramARB)
+-    USE_GL_FUNC(glShaderSourceARB)
+-    USE_GL_FUNC(glUniform1fARB)
+-    USE_GL_FUNC(glUniform1fvARB)
+-    USE_GL_FUNC(glUniform1iARB)
+-    USE_GL_FUNC(glUniform1ivARB)
+-    USE_GL_FUNC(glUniform2fARB)
+-    USE_GL_FUNC(glUniform2fvARB)
+-    USE_GL_FUNC(glUniform2iARB)
+-    USE_GL_FUNC(glUniform2ivARB)
+-    USE_GL_FUNC(glUniform3fARB)
+-    USE_GL_FUNC(glUniform3fvARB)
+-    USE_GL_FUNC(glUniform3iARB)
+-    USE_GL_FUNC(glUniform3ivARB)
+-    USE_GL_FUNC(glUniform4fARB)
+-    USE_GL_FUNC(glUniform4fvARB)
+-    USE_GL_FUNC(glUniform4iARB)
+-    USE_GL_FUNC(glUniform4ivARB)
+-    USE_GL_FUNC(glUniformMatrix2fvARB)
+-    USE_GL_FUNC(glUniformMatrix3fvARB)
+-    USE_GL_FUNC(glUniformMatrix4fvARB)
+-    USE_GL_FUNC(glUseProgramObjectARB)
+-    USE_GL_FUNC(glValidateProgramARB)
+-    /* GL_ARB_shader_storage_buffer_object */
+-    USE_GL_FUNC(glShaderStorageBlockBinding)
+-    /* GL_ARB_sync */
+-    USE_GL_FUNC(glClientWaitSync)
+-    USE_GL_FUNC(glDeleteSync)
+-    USE_GL_FUNC(glFenceSync)
+-    USE_GL_FUNC(glGetInteger64v)
+-    USE_GL_FUNC(glGetSynciv)
+-    USE_GL_FUNC(glIsSync)
+-    USE_GL_FUNC(glWaitSync)
+-    /* GL_ARB_tessellation_shader */
+-    USE_GL_FUNC(glPatchParameteri)
+-    USE_GL_FUNC(glPatchParameterfv)
+-    /* GL_ARB_texture_buffer_object */
+-    USE_GL_FUNC(glTexBufferARB)
+-    /* GL_ARB_texture_buffer_range */
+-    USE_GL_FUNC(glTexBufferRange)
+-    /* GL_ARB_texture_compression */
+-    USE_GL_FUNC(glCompressedTexImage2DARB)
+-    USE_GL_FUNC(glCompressedTexImage3DARB)
+-    USE_GL_FUNC(glCompressedTexSubImage2DARB)
+-    USE_GL_FUNC(glCompressedTexSubImage3DARB)
+-    USE_GL_FUNC(glGetCompressedTexImageARB)
+-    /* GL_ARB_texture_multisample */
+-    USE_GL_FUNC(glGetMultisamplefv);
+-    USE_GL_FUNC(glSampleMaski);
+-    USE_GL_FUNC(glTexImage2DMultisample);
+-    USE_GL_FUNC(glTexImage3DMultisample);
+-    /* GL_ARB_texture_storage */
+-    USE_GL_FUNC(glTexStorage1D)
+-    USE_GL_FUNC(glTexStorage2D)
+-    USE_GL_FUNC(glTexStorage3D)
+-    /* GL_ARB_texture_storage_multisample */
+-    USE_GL_FUNC(glTexStorage2DMultisample);
+-    USE_GL_FUNC(glTexStorage3DMultisample);
+-    /* GL_ARB_texture_view */
+-    USE_GL_FUNC(glTextureView)
+-    /* GL_ARB_timer_query */
+-    USE_GL_FUNC(glQueryCounter)
+-    USE_GL_FUNC(glGetQueryObjectui64v)
+-    /* GL_ARB_transform_feedback2 */
+-    USE_GL_FUNC(glBindTransformFeedback);
+-    USE_GL_FUNC(glDeleteTransformFeedbacks);
+-    USE_GL_FUNC(glDrawTransformFeedback);
+-    USE_GL_FUNC(glGenTransformFeedbacks);
+-    USE_GL_FUNC(glIsTransformFeedback);
+-    USE_GL_FUNC(glPauseTransformFeedback);
+-    USE_GL_FUNC(glResumeTransformFeedback);
+-    /* GL_ARB_transform_feedback3 */
+-    USE_GL_FUNC(glBeginQueryIndexed);
+-    USE_GL_FUNC(glDrawTransformFeedbackStream);
+-    USE_GL_FUNC(glEndQueryIndexed);
+-    USE_GL_FUNC(glGetQueryIndexediv);
+-    /* GL_ARB_uniform_buffer_object */
+-    USE_GL_FUNC(glBindBufferBase)
+-    USE_GL_FUNC(glBindBufferRange)
+-    USE_GL_FUNC(glGetActiveUniformBlockName)
+-    USE_GL_FUNC(glGetActiveUniformBlockiv)
+-    USE_GL_FUNC(glGetActiveUniformName)
+-    USE_GL_FUNC(glGetActiveUniformsiv)
+-    USE_GL_FUNC(glGetIntegeri_v)
+-    USE_GL_FUNC(glGetUniformBlockIndex)
+-    USE_GL_FUNC(glGetUniformIndices)
+-    USE_GL_FUNC(glUniformBlockBinding)
+-    /* GL_ARB_vertex_buffer_object */
+-    USE_GL_FUNC(glBindBufferARB)
+-    USE_GL_FUNC(glBufferDataARB)
+-    USE_GL_FUNC(glBufferSubDataARB)
+-    USE_GL_FUNC(glDeleteBuffersARB)
+-    USE_GL_FUNC(glGenBuffersARB)
+-    USE_GL_FUNC(glGetBufferParameterivARB)
+-    USE_GL_FUNC(glGetBufferPointervARB)
+-    USE_GL_FUNC(glGetBufferSubDataARB)
+-    USE_GL_FUNC(glIsBufferARB)
+-    USE_GL_FUNC(glMapBufferARB)
+-    USE_GL_FUNC(glUnmapBufferARB)
+-    /* GL_ARB_vertex_program */
+-    USE_GL_FUNC(glBindProgramARB)
+-    USE_GL_FUNC(glDeleteProgramsARB)
+-    USE_GL_FUNC(glDisableVertexAttribArrayARB)
+-    USE_GL_FUNC(glEnableVertexAttribArrayARB)
+-    USE_GL_FUNC(glGenProgramsARB)
+-    USE_GL_FUNC(glGetProgramivARB)
+-    USE_GL_FUNC(glProgramEnvParameter4fvARB)
+-    USE_GL_FUNC(glProgramLocalParameter4fvARB)
+-    USE_GL_FUNC(glProgramStringARB)
+-    USE_GL_FUNC(glVertexAttrib1dARB)
+-    USE_GL_FUNC(glVertexAttrib1dvARB)
+-    USE_GL_FUNC(glVertexAttrib1fARB)
+-    USE_GL_FUNC(glVertexAttrib1fvARB)
+-    USE_GL_FUNC(glVertexAttrib1sARB)
+-    USE_GL_FUNC(glVertexAttrib1svARB)
+-    USE_GL_FUNC(glVertexAttrib2dARB)
+-    USE_GL_FUNC(glVertexAttrib2dvARB)
+-    USE_GL_FUNC(glVertexAttrib2fARB)
+-    USE_GL_FUNC(glVertexAttrib2fvARB)
+-    USE_GL_FUNC(glVertexAttrib2sARB)
+-    USE_GL_FUNC(glVertexAttrib2svARB)
+-    USE_GL_FUNC(glVertexAttrib3dARB)
+-    USE_GL_FUNC(glVertexAttrib3dvARB)
+-    USE_GL_FUNC(glVertexAttrib3fARB)
+-    USE_GL_FUNC(glVertexAttrib3fvARB)
+-    USE_GL_FUNC(glVertexAttrib3sARB)
+-    USE_GL_FUNC(glVertexAttrib3svARB)
+-    USE_GL_FUNC(glVertexAttrib4NbvARB)
+-    USE_GL_FUNC(glVertexAttrib4NivARB)
+-    USE_GL_FUNC(glVertexAttrib4NsvARB)
+-    USE_GL_FUNC(glVertexAttrib4NubARB)
+-    USE_GL_FUNC(glVertexAttrib4NubvARB)
+-    USE_GL_FUNC(glVertexAttrib4NuivARB)
+-    USE_GL_FUNC(glVertexAttrib4NusvARB)
+-    USE_GL_FUNC(glVertexAttrib4bvARB)
+-    USE_GL_FUNC(glVertexAttrib4dARB)
+-    USE_GL_FUNC(glVertexAttrib4dvARB)
+-    USE_GL_FUNC(glVertexAttrib4fARB)
+-    USE_GL_FUNC(glVertexAttrib4fvARB)
+-    USE_GL_FUNC(glVertexAttrib4ivARB)
+-    USE_GL_FUNC(glVertexAttrib4sARB)
+-    USE_GL_FUNC(glVertexAttrib4svARB)
+-    USE_GL_FUNC(glVertexAttrib4ubvARB)
+-    USE_GL_FUNC(glVertexAttrib4uivARB)
+-    USE_GL_FUNC(glVertexAttrib4usvARB)
+-    USE_GL_FUNC(glVertexAttribPointerARB)
+-    /* GL_ARB_viewport_array */
+-    USE_GL_FUNC(glDepthRangeArrayv)
+-    USE_GL_FUNC(glDepthRangeIndexed)
+-    USE_GL_FUNC(glGetDoublei_v)
+-    USE_GL_FUNC(glGetFloati_v)
+-    USE_GL_FUNC(glScissorArrayv)
+-    USE_GL_FUNC(glScissorIndexed)
+-    USE_GL_FUNC(glScissorIndexedv)
+-    USE_GL_FUNC(glViewportArrayv)
+-    USE_GL_FUNC(glViewportIndexedf)
+-    USE_GL_FUNC(glViewportIndexedfv)
+-    /* GL_ATI_fragment_shader */
+-    USE_GL_FUNC(glAlphaFragmentOp1ATI)
+-    USE_GL_FUNC(glAlphaFragmentOp2ATI)
+-    USE_GL_FUNC(glAlphaFragmentOp3ATI)
+-    USE_GL_FUNC(glBeginFragmentShaderATI)
+-    USE_GL_FUNC(glBindFragmentShaderATI)
+-    USE_GL_FUNC(glColorFragmentOp1ATI)
+-    USE_GL_FUNC(glColorFragmentOp2ATI)
+-    USE_GL_FUNC(glColorFragmentOp3ATI)
+-    USE_GL_FUNC(glDeleteFragmentShaderATI)
+-    USE_GL_FUNC(glEndFragmentShaderATI)
+-    USE_GL_FUNC(glGenFragmentShadersATI)
+-    USE_GL_FUNC(glPassTexCoordATI)
+-    USE_GL_FUNC(glSampleMapATI)
+-    USE_GL_FUNC(glSetFragmentShaderConstantATI)
+-    /* GL_ATI_separate_stencil */
+-    USE_GL_FUNC(glStencilOpSeparateATI)
+-    USE_GL_FUNC(glStencilFuncSeparateATI)
+-    /* GL_EXT_blend_color */
+-    USE_GL_FUNC(glBlendColorEXT)
+-    /* GL_EXT_blend_equation_separate */
+-    USE_GL_FUNC(glBlendFuncSeparateEXT)
+-    /* GL_EXT_blend_func_separate */
+-    USE_GL_FUNC(glBlendEquationSeparateEXT)
+-    /* GL_EXT_blend_minmax */
+-    USE_GL_FUNC(glBlendEquationEXT)
+-    /* GL_EXT_depth_bounds_test */
+-    USE_GL_FUNC(glDepthBoundsEXT)
+-    /* GL_EXT_draw_buffers2 */
+-    USE_GL_FUNC(glColorMaskIndexedEXT)
+-    USE_GL_FUNC(glDisableIndexedEXT)
+-    USE_GL_FUNC(glEnableIndexedEXT)
+-    USE_GL_FUNC(glGetBooleanIndexedvEXT)
+-    USE_GL_FUNC(glGetIntegerIndexedvEXT)
+-    USE_GL_FUNC(glIsEnabledIndexedEXT)
+-    /* GL_EXT_fog_coord */
+-    USE_GL_FUNC(glFogCoordPointerEXT)
+-    USE_GL_FUNC(glFogCoorddEXT)
+-    USE_GL_FUNC(glFogCoorddvEXT)
+-    USE_GL_FUNC(glFogCoordfEXT)
+-    USE_GL_FUNC(glFogCoordfvEXT)
+-    /* GL_EXT_framebuffer_blit */
+-    USE_GL_FUNC(glBlitFramebufferEXT)
+-    /* GL_EXT_framebuffer_multisample */
+-    USE_GL_FUNC(glRenderbufferStorageMultisampleEXT)
+-    /* GL_EXT_framebuffer_object */
+-    USE_GL_FUNC(glBindFramebufferEXT)
+-    USE_GL_FUNC(glBindRenderbufferEXT)
+-    USE_GL_FUNC(glCheckFramebufferStatusEXT)
+-    USE_GL_FUNC(glDeleteFramebuffersEXT)
+-    USE_GL_FUNC(glDeleteRenderbuffersEXT)
+-    USE_GL_FUNC(glFramebufferRenderbufferEXT)
+-    USE_GL_FUNC(glFramebufferTexture1DEXT)
+-    USE_GL_FUNC(glFramebufferTexture2DEXT)
+-    USE_GL_FUNC(glFramebufferTexture3DEXT)
+-    USE_GL_FUNC(glGenFramebuffersEXT)
+-    USE_GL_FUNC(glGenRenderbuffersEXT)
+-    USE_GL_FUNC(glGenerateMipmapEXT)
+-    USE_GL_FUNC(glGetFramebufferAttachmentParameterivEXT)
+-    USE_GL_FUNC(glGetRenderbufferParameterivEXT)
+-    USE_GL_FUNC(glIsFramebufferEXT)
+-    USE_GL_FUNC(glIsRenderbufferEXT)
+-    USE_GL_FUNC(glRenderbufferStorageEXT)
+-    /* GL_EXT_gpu_program_parameters */
+-    USE_GL_FUNC(glProgramEnvParameters4fvEXT)
+-    USE_GL_FUNC(glProgramLocalParameters4fvEXT)
+-    /* GL_EXT_gpu_shader4 */
+-    USE_GL_FUNC(glBindFragDataLocationEXT)
+-    USE_GL_FUNC(glGetFragDataLocationEXT)
+-    USE_GL_FUNC(glGetUniformuivEXT)
+-    USE_GL_FUNC(glGetVertexAttribIivEXT)
+-    USE_GL_FUNC(glGetVertexAttribIuivEXT)
+-    USE_GL_FUNC(glUniform1uiEXT)
+-    USE_GL_FUNC(glUniform1uivEXT)
+-    USE_GL_FUNC(glUniform2uiEXT)
+-    USE_GL_FUNC(glUniform2uivEXT)
+-    USE_GL_FUNC(glUniform3uiEXT)
+-    USE_GL_FUNC(glUniform3uivEXT)
+-    USE_GL_FUNC(glUniform4uiEXT)
+-    USE_GL_FUNC(glUniform4uivEXT)
+-    USE_GL_FUNC(glVertexAttribI1iEXT)
+-    USE_GL_FUNC(glVertexAttribI1ivEXT)
+-    USE_GL_FUNC(glVertexAttribI1uiEXT)
+-    USE_GL_FUNC(glVertexAttribI1uivEXT)
+-    USE_GL_FUNC(glVertexAttribI2iEXT)
+-    USE_GL_FUNC(glVertexAttribI2ivEXT)
+-    USE_GL_FUNC(glVertexAttribI2uiEXT)
+-    USE_GL_FUNC(glVertexAttribI2uivEXT)
+-    USE_GL_FUNC(glVertexAttribI3iEXT)
+-    USE_GL_FUNC(glVertexAttribI3ivEXT)
+-    USE_GL_FUNC(glVertexAttribI3uiEXT)
+-    USE_GL_FUNC(glVertexAttribI3uivEXT)
+-    USE_GL_FUNC(glVertexAttribI4bvEXT)
+-    USE_GL_FUNC(glVertexAttribI4iEXT)
+-    USE_GL_FUNC(glVertexAttribI4ivEXT)
+-    USE_GL_FUNC(glVertexAttribI4svEXT)
+-    USE_GL_FUNC(glVertexAttribI4ubvEXT)
+-    USE_GL_FUNC(glVertexAttribI4uiEXT)
+-    USE_GL_FUNC(glVertexAttribI4uivEXT)
+-    USE_GL_FUNC(glVertexAttribI4usvEXT)
+-    USE_GL_FUNC(glVertexAttribIPointerEXT)
+-    /* GL_EXT_point_parameters */
+-    USE_GL_FUNC(glPointParameterfEXT)
+-    USE_GL_FUNC(glPointParameterfvEXT)
+-    /* GL_EXT_provoking_vertex */
+-    USE_GL_FUNC(glProvokingVertexEXT)
+-    /* GL_EXT_secondary_color */
+-    USE_GL_FUNC(glSecondaryColor3fEXT)
+-    USE_GL_FUNC(glSecondaryColor3fvEXT)
+-    USE_GL_FUNC(glSecondaryColor3ubEXT)
+-    USE_GL_FUNC(glSecondaryColor3ubvEXT)
+-    USE_GL_FUNC(glSecondaryColorPointerEXT)
+-    /* GL_EXT_stencil_two_side */
+-    USE_GL_FUNC(glActiveStencilFaceEXT)
+-    /* GL_EXT_texture3D */
+-    USE_GL_FUNC(glTexImage3D)
+-    USE_GL_FUNC(glTexImage3DEXT)
+-    USE_GL_FUNC(glTexSubImage3D)
+-    USE_GL_FUNC(glTexSubImage3DEXT)
+-    /* GL_NV_fence */
+-    USE_GL_FUNC(glDeleteFencesNV)
+-    USE_GL_FUNC(glFinishFenceNV)
+-    USE_GL_FUNC(glGenFencesNV)
+-    USE_GL_FUNC(glGetFenceivNV)
+-    USE_GL_FUNC(glIsFenceNV)
+-    USE_GL_FUNC(glSetFenceNV)
+-    USE_GL_FUNC(glTestFenceNV)
+-    /* GL_NV_half_float */
+-    USE_GL_FUNC(glColor3hNV)
+-    USE_GL_FUNC(glColor3hvNV)
+-    USE_GL_FUNC(glColor4hNV)
+-    USE_GL_FUNC(glColor4hvNV)
+-    USE_GL_FUNC(glFogCoordhNV)
+-    USE_GL_FUNC(glFogCoordhvNV)
+-    USE_GL_FUNC(glMultiTexCoord1hNV)
+-    USE_GL_FUNC(glMultiTexCoord1hvNV)
+-    USE_GL_FUNC(glMultiTexCoord2hNV)
+-    USE_GL_FUNC(glMultiTexCoord2hvNV)
+-    USE_GL_FUNC(glMultiTexCoord3hNV)
+-    USE_GL_FUNC(glMultiTexCoord3hvNV)
+-    USE_GL_FUNC(glMultiTexCoord4hNV)
+-    USE_GL_FUNC(glMultiTexCoord4hvNV)
+-    USE_GL_FUNC(glNormal3hNV)
+-    USE_GL_FUNC(glNormal3hvNV)
+-    USE_GL_FUNC(glSecondaryColor3hNV)
+-    USE_GL_FUNC(glSecondaryColor3hvNV)
+-    USE_GL_FUNC(glTexCoord1hNV)
+-    USE_GL_FUNC(glTexCoord1hvNV)
+-    USE_GL_FUNC(glTexCoord2hNV)
+-    USE_GL_FUNC(glTexCoord2hvNV)
+-    USE_GL_FUNC(glTexCoord3hNV)
+-    USE_GL_FUNC(glTexCoord3hvNV)
+-    USE_GL_FUNC(glTexCoord4hNV)
+-    USE_GL_FUNC(glTexCoord4hvNV)
+-    USE_GL_FUNC(glVertex2hNV)
+-    USE_GL_FUNC(glVertex2hvNV)
+-    USE_GL_FUNC(glVertex3hNV)
+-    USE_GL_FUNC(glVertex3hvNV)
+-    USE_GL_FUNC(glVertex4hNV)
+-    USE_GL_FUNC(glVertex4hvNV)
+-    USE_GL_FUNC(glVertexAttrib1hNV)
+-    USE_GL_FUNC(glVertexAttrib1hvNV)
+-    USE_GL_FUNC(glVertexAttrib2hNV)
+-    USE_GL_FUNC(glVertexAttrib2hvNV)
+-    USE_GL_FUNC(glVertexAttrib3hNV)
+-    USE_GL_FUNC(glVertexAttrib3hvNV)
+-    USE_GL_FUNC(glVertexAttrib4hNV)
+-    USE_GL_FUNC(glVertexAttrib4hvNV)
+-    USE_GL_FUNC(glVertexAttribs1hvNV)
+-    USE_GL_FUNC(glVertexAttribs2hvNV)
+-    USE_GL_FUNC(glVertexAttribs3hvNV)
+-    USE_GL_FUNC(glVertexAttribs4hvNV)
+-    USE_GL_FUNC(glVertexWeighthNV)
+-    USE_GL_FUNC(glVertexWeighthvNV)
+-    /* GL_NV_point_sprite */
+-    USE_GL_FUNC(glPointParameteriNV)
+-    USE_GL_FUNC(glPointParameterivNV)
+-    /* GL_NV_register_combiners */
+-    USE_GL_FUNC(glCombinerInputNV)
+-    USE_GL_FUNC(glCombinerOutputNV)
+-    USE_GL_FUNC(glCombinerParameterfNV)
+-    USE_GL_FUNC(glCombinerParameterfvNV)
+-    USE_GL_FUNC(glCombinerParameteriNV)
+-    USE_GL_FUNC(glCombinerParameterivNV)
+-    USE_GL_FUNC(glFinalCombinerInputNV)
+-    /* WGL extensions */
+-    USE_GL_FUNC(wglChoosePixelFormatARB)
+-    USE_GL_FUNC(wglGetExtensionsStringARB)
+-    USE_GL_FUNC(wglGetPixelFormatAttribfvARB)
+-    USE_GL_FUNC(wglGetPixelFormatAttribivARB)
+-    USE_GL_FUNC(wglQueryCurrentRendererIntegerWINE)
+-    USE_GL_FUNC(wglQueryCurrentRendererStringWINE)
+-    USE_GL_FUNC(wglQueryRendererIntegerWINE)
+-    USE_GL_FUNC(wglQueryRendererStringWINE)
+-    USE_GL_FUNC(wglSetPixelFormatWINE)
+-    USE_GL_FUNC(wglSwapIntervalEXT)
+-
+-    /* Newer core functions */
+-    USE_GL_FUNC(glActiveTexture)                               /* OpenGL 1.3 */
+-    USE_GL_FUNC(glAttachShader)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glBeginQuery)                                  /* OpenGL 1.5 */
+-    USE_GL_FUNC(glBeginTransformFeedback)                      /* OpenGL 3.0 */
+-    USE_GL_FUNC(glBindAttribLocation)                          /* OpenGL 2.0 */
+-    USE_GL_FUNC(glBindBuffer)                                  /* OpenGL 1.5 */
+-    USE_GL_FUNC(glBindFragDataLocation)                        /* OpenGL 3.0 */
+-    USE_GL_FUNC(glBindVertexArray)                             /* OpenGL 3.0 */
+-    USE_GL_FUNC(glBlendColor)                                  /* OpenGL 1.4 */
+-    USE_GL_FUNC(glBlendEquation)                               /* OpenGL 1.4 */
+-    USE_GL_FUNC(glBlendEquationSeparate)                       /* OpenGL 2.0 */
+-    USE_GL_FUNC(glBlendFuncSeparate)                           /* OpenGL 1.4 */
+-    USE_GL_FUNC(glBufferData)                                  /* OpenGL 1.5 */
+-    USE_GL_FUNC(glBufferSubData)                               /* OpenGL 1.5 */
+-    USE_GL_FUNC(glColorMaski)                                  /* OpenGL 3.0 */
+-    USE_GL_FUNC(glCompileShader)                               /* OpenGL 2.0 */
+-    USE_GL_FUNC(glCompressedTexImage2D)                        /* OpenGL 1.3 */
+-    USE_GL_FUNC(glCompressedTexImage3D)                        /* OpenGL 1.3 */
+-    USE_GL_FUNC(glCompressedTexSubImage2D)                     /* OpenGL 1.3 */
+-    USE_GL_FUNC(glCompressedTexSubImage3D)                     /* OpenGL 1.3 */
+-    USE_GL_FUNC(glCreateProgram)                               /* OpenGL 2.0 */
+-    USE_GL_FUNC(glCreateShader)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glDebugMessageCallback)                        /* OpenGL 4.3 */
+-    USE_GL_FUNC(glDebugMessageControl)                         /* OpenGL 4.3 */
+-    USE_GL_FUNC(glDebugMessageInsert)                          /* OpenGL 4.3 */
+-    USE_GL_FUNC(glDeleteBuffers)                               /* OpenGL 1.5 */
+-    USE_GL_FUNC(glDeleteProgram)                               /* OpenGL 2.0 */
+-    USE_GL_FUNC(glDeleteQueries)                               /* OpenGL 1.5 */
+-    USE_GL_FUNC(glDeleteShader)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glDeleteVertexArrays)                          /* OpenGL 3.0 */
+-    USE_GL_FUNC(glDetachShader)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glDisablei)                                    /* OpenGL 3.0 */
+-    USE_GL_FUNC(glDisableVertexAttribArray)                    /* OpenGL 2.0 */
+-    USE_GL_FUNC(glDrawArraysInstanced)                         /* OpenGL 3.1 */
+-    USE_GL_FUNC(glDrawBuffers)                                 /* OpenGL 2.0 */
+-    USE_GL_FUNC(glDrawElementsInstanced)                       /* OpenGL 3.1 */
+-    USE_GL_FUNC(glEnablei)                                     /* OpenGL 3.0 */
+-    USE_GL_FUNC(glEnableVertexAttribArray)                     /* OpenGL 2.0 */
+-    USE_GL_FUNC(glEndQuery)                                    /* OpenGL 1.5 */
+-    USE_GL_FUNC(glEndTransformFeedback)                        /* OpenGL 3.0 */
+-    USE_GL_FUNC(glFramebufferTexture)                          /* OpenGL 3.2 */
+-    USE_GL_FUNC(glGenBuffers)                                  /* OpenGL 1.5 */
+-    USE_GL_FUNC(glGenQueries)                                  /* OpenGL 1.5 */
+-    USE_GL_FUNC(glGenVertexArrays)                             /* OpenGL 3.0 */
+-    USE_GL_FUNC(glGetActiveUniform)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetAttachedShaders)                          /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetAttribLocation)                           /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetBooleani_v)                               /* OpenGL 3.0 */
+-    USE_GL_FUNC(glGetBufferSubData)                            /* OpenGL 1.5 */
+-    USE_GL_FUNC(glGetCompressedTexImage)                       /* OpenGL 1.3 */
+-    USE_GL_FUNC(glGetDebugMessageLog)                          /* OpenGL 4.3 */
+-    USE_GL_FUNC(glGetIntegeri_v)                               /* OpenGL 3.0 */
+-    USE_GL_FUNC(glGetProgramInfoLog)                           /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetProgramiv)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetQueryiv)                                  /* OpenGL 1.5 */
+-    USE_GL_FUNC(glGetQueryObjectuiv)                           /* OpenGL 1.5 */
+-    USE_GL_FUNC(glGetShaderInfoLog)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetShaderiv)                                 /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetShaderSource)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetStringi)                                  /* OpenGL 3.0 */
+-    USE_GL_FUNC(glGetTextureLevelParameteriv)                  /* OpenGL 4.5 */
+-    USE_GL_FUNC(glGetTextureParameteriv)                       /* OpenGL 4.5 */
+-    USE_GL_FUNC(glGetUniformfv)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetUniformiv)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glGetUniformLocation)                          /* OpenGL 2.0 */
+-    USE_GL_FUNC(glIsEnabledi)                                  /* OpenGL 3.0 */
+-    USE_GL_FUNC(glLinkProgram)                                 /* OpenGL 2.0 */
+-    USE_GL_FUNC(glMapBuffer)                                   /* OpenGL 1.5 */
+-    USE_GL_FUNC(glMinSampleShading)                            /* OpenGL 4.0 */
+-    USE_GL_FUNC(glPointParameteri)                             /* OpenGL 1.4 */
+-    USE_GL_FUNC(glPointParameteriv)                            /* OpenGL 1.4 */
+-    USE_GL_FUNC(glShaderSource)                                /* OpenGL 2.0 */
+-    USE_GL_FUNC(glStencilFuncSeparate)                         /* OpenGL 2.0 */
+-    USE_GL_FUNC(glStencilOpSeparate)                           /* OpenGL 2.0 */
+-    USE_GL_FUNC(glTexBuffer)                                   /* OpenGL 3.1 */
+-    USE_GL_FUNC(glTexImage3D)                                  /* OpenGL 1.2 */
+-    USE_GL_FUNC(glTexSubImage3D)                               /* OpenGL 1.2 */
+-    USE_GL_FUNC(glTransformFeedbackVaryings)                   /* OpenGL 3.0 */
+-    USE_GL_FUNC(glUniform1f)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform1fv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform1i)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform1iv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform2f)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform2fv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform2i)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform2iv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform3f)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform3fv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform3i)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform3iv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform4f)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform4fv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform4i)                                   /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniform4iv)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniformMatrix2fv)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniformMatrix3fv)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUniformMatrix4fv)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glUnmapBuffer)                                 /* OpenGL 1.5 */
+-    USE_GL_FUNC(glUseProgram)                                  /* OpenGL 2.0 */
+-    USE_GL_FUNC(glValidateProgram)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib1f)                              /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib1fv)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib2f)                              /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib2fv)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib3f)                              /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib3fv)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4f)                              /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4fv)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4Nsv)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4Nub)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4Nubv)                           /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4Nusv)                           /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4sv)                             /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttrib4ubv)                            /* OpenGL 2.0 */
+-    USE_GL_FUNC(glVertexAttribDivisor)                         /* OpenGL 3.3 */
+-    USE_GL_FUNC(glVertexAttribIPointer)                        /* OpenGL 3.0 */
+-    USE_GL_FUNC(glVertexAttribPointer)                         /* OpenGL 2.0 */
+-#undef USE_GL_FUNC
+-
+-#ifndef USE_WIN32_OPENGL
+-    /* hack: use the functions directly from the TEB table to bypass the thunks */
+-    /* note that we still need the above wglGetProcAddress calls to initialize the table */
+-    gl_info->gl_ops.ext = ((struct opengl_funcs *)NtCurrentTeb()->glTable)->ext;
+-#endif
+-
+-#define MAP_GL_FUNCTION(core_func, ext_func)                                          \
+-        do                                                                            \
+-        {                                                                             \
+-            if (!gl_info->gl_ops.ext.p_##core_func)                                   \
+-                gl_info->gl_ops.ext.p_##core_func = gl_info->gl_ops.ext.p_##ext_func; \
+-        } while (0)
+-#define MAP_GL_FUNCTION_CAST(core_func, ext_func)                                             \
+-        do                                                                                    \
+-        {                                                                                     \
+-            if (!gl_info->gl_ops.ext.p_##core_func)                                           \
+-                gl_info->gl_ops.ext.p_##core_func = (void *)gl_info->gl_ops.ext.p_##ext_func; \
+-        } while (0)
+-
+-    MAP_GL_FUNCTION(glActiveTexture, glActiveTextureARB);
+-    MAP_GL_FUNCTION(glAttachShader, glAttachObjectARB);
+-    MAP_GL_FUNCTION(glBeginQuery, glBeginQueryARB);
+-    MAP_GL_FUNCTION(glBindAttribLocation, glBindAttribLocationARB);
+-    MAP_GL_FUNCTION(glBindBuffer, glBindBufferARB);
+-    MAP_GL_FUNCTION(glBindFragDataLocation, glBindFragDataLocationEXT);
+-    MAP_GL_FUNCTION(glBlendColor, glBlendColorEXT);
+-    MAP_GL_FUNCTION(glBlendEquation, glBlendEquationEXT);
+-    MAP_GL_FUNCTION(glBlendEquationSeparate, glBlendEquationSeparateEXT);
+-    MAP_GL_FUNCTION(glBlendFuncSeparate, glBlendFuncSeparateEXT);
+-    MAP_GL_FUNCTION(glBufferData, glBufferDataARB);
+-    MAP_GL_FUNCTION(glBufferSubData, glBufferSubDataARB);
+-    MAP_GL_FUNCTION(glColorMaski, glColorMaskIndexedEXT);
+-    MAP_GL_FUNCTION(glCompileShader, glCompileShaderARB);
+-    MAP_GL_FUNCTION(glCompressedTexImage2D, glCompressedTexImage2DARB);
+-    MAP_GL_FUNCTION(glCompressedTexImage3D, glCompressedTexImage3DARB);
+-    MAP_GL_FUNCTION(glCompressedTexSubImage2D, glCompressedTexSubImage2DARB);
+-    MAP_GL_FUNCTION(glCompressedTexSubImage3D, glCompressedTexSubImage3DARB);
+-    MAP_GL_FUNCTION(glCreateProgram, glCreateProgramObjectARB);
+-    MAP_GL_FUNCTION(glCreateShader, glCreateShaderObjectARB);
+-    MAP_GL_FUNCTION(glDebugMessageCallback, glDebugMessageCallbackARB);
+-    MAP_GL_FUNCTION(glDebugMessageControl, glDebugMessageControlARB);
+-    MAP_GL_FUNCTION(glDebugMessageInsert, glDebugMessageInsertARB);
+-    MAP_GL_FUNCTION(glDeleteBuffers, glDeleteBuffersARB);
+-    MAP_GL_FUNCTION(glDeleteProgram, glDeleteObjectARB);
+-    MAP_GL_FUNCTION(glDeleteQueries, glDeleteQueriesARB);
+-    MAP_GL_FUNCTION(glDeleteShader, glDeleteObjectARB);
+-    MAP_GL_FUNCTION(glDetachShader, glDetachObjectARB);
+-    MAP_GL_FUNCTION(glDisablei, glDisableIndexedEXT);
+-    MAP_GL_FUNCTION(glDisableVertexAttribArray, glDisableVertexAttribArrayARB);
+-    MAP_GL_FUNCTION(glDrawArraysInstanced, glDrawArraysInstancedARB);
+-    MAP_GL_FUNCTION(glDrawBuffers, glDrawBuffersARB);
+-    MAP_GL_FUNCTION(glDrawElementsInstanced, glDrawElementsInstancedARB);
+-    MAP_GL_FUNCTION(glEnablei, glEnableIndexedEXT);
+-    MAP_GL_FUNCTION(glEnableVertexAttribArray, glEnableVertexAttribArrayARB);
+-    MAP_GL_FUNCTION(glEndQuery, glEndQueryARB);
+-    MAP_GL_FUNCTION(glFramebufferTexture, glFramebufferTextureARB);
+-    MAP_GL_FUNCTION(glGenBuffers, glGenBuffersARB);
+-    MAP_GL_FUNCTION(glGenQueries, glGenQueriesARB);
+-    MAP_GL_FUNCTION(glGetActiveUniform, glGetActiveUniformARB);
+-    MAP_GL_FUNCTION(glGetAttachedShaders, glGetAttachedObjectsARB);
+-    MAP_GL_FUNCTION(glGetAttribLocation, glGetAttribLocationARB);
+-    MAP_GL_FUNCTION(glGetBooleani_v, glGetBooleanIndexedvEXT);
+-    MAP_GL_FUNCTION(glGetBufferSubData, glGetBufferSubDataARB);
+-    MAP_GL_FUNCTION(glGetCompressedTexImage, glGetCompressedTexImageARB);
+-    MAP_GL_FUNCTION(glGetDebugMessageLog, glGetDebugMessageLogARB);
+-    MAP_GL_FUNCTION(glGetIntegeri_v, glGetIntegerIndexedvEXT);
+-    MAP_GL_FUNCTION(glGetProgramInfoLog, glGetInfoLogARB);
+-    MAP_GL_FUNCTION(glGetProgramiv, glGetObjectParameterivARB);
+-    MAP_GL_FUNCTION(glGetQueryiv, glGetQueryivARB);
+-    MAP_GL_FUNCTION(glGetQueryObjectuiv, glGetQueryObjectuivARB);
+-    MAP_GL_FUNCTION(glGetShaderInfoLog, glGetInfoLogARB);
+-    MAP_GL_FUNCTION(glGetShaderiv, glGetObjectParameterivARB);
+-    MAP_GL_FUNCTION(glGetShaderSource, glGetShaderSourceARB);
+-    MAP_GL_FUNCTION(glGetUniformfv, glGetUniformfvARB);
+-    MAP_GL_FUNCTION(glGetUniformiv, glGetUniformivARB);
+-    MAP_GL_FUNCTION(glGetUniformLocation, glGetUniformLocationARB);
+-    MAP_GL_FUNCTION(glIsEnabledi, glIsEnabledIndexedEXT);
+-    MAP_GL_FUNCTION(glLinkProgram, glLinkProgramARB);
+-    MAP_GL_FUNCTION(glMapBuffer, glMapBufferARB);
+-    MAP_GL_FUNCTION(glMinSampleShading, glMinSampleShadingARB);
+-    MAP_GL_FUNCTION_CAST(glShaderSource, glShaderSourceARB);
+-    MAP_GL_FUNCTION(glTexBuffer, glTexBufferARB);
+-    MAP_GL_FUNCTION_CAST(glTexImage3D, glTexImage3DEXT);
+-    MAP_GL_FUNCTION(glTexSubImage3D, glTexSubImage3DEXT);
+-    MAP_GL_FUNCTION(glUniform1f, glUniform1fARB);
+-    MAP_GL_FUNCTION(glUniform1fv, glUniform1fvARB);
+-    MAP_GL_FUNCTION(glUniform1i, glUniform1iARB);
+-    MAP_GL_FUNCTION(glUniform1iv, glUniform1ivARB);
+-    MAP_GL_FUNCTION(glUniform2f, glUniform2fARB);
+-    MAP_GL_FUNCTION(glUniform2fv, glUniform2fvARB);
+-    MAP_GL_FUNCTION(glUniform2i, glUniform2iARB);
+-    MAP_GL_FUNCTION(glUniform2iv, glUniform2ivARB);
+-    MAP_GL_FUNCTION(glUniform3f, glUniform3fARB);
+-    MAP_GL_FUNCTION(glUniform3fv, glUniform3fvARB);
+-    MAP_GL_FUNCTION(glUniform3i, glUniform3iARB);
+-    MAP_GL_FUNCTION(glUniform3iv, glUniform3ivARB);
+-    MAP_GL_FUNCTION(glUniform4f, glUniform4fARB);
+-    MAP_GL_FUNCTION(glUniform4fv, glUniform4fvARB);
+-    MAP_GL_FUNCTION(glUniform4i, glUniform4iARB);
+-    MAP_GL_FUNCTION(glUniform4iv, glUniform4ivARB);
+-    MAP_GL_FUNCTION(glUniformMatrix2fv, glUniformMatrix2fvARB);
+-    MAP_GL_FUNCTION(glUniformMatrix3fv, glUniformMatrix3fvARB);
+-    MAP_GL_FUNCTION(glUniformMatrix4fv, glUniformMatrix4fvARB);
+-    MAP_GL_FUNCTION(glUnmapBuffer, glUnmapBufferARB);
+-    MAP_GL_FUNCTION(glUseProgram, glUseProgramObjectARB);
+-    MAP_GL_FUNCTION(glValidateProgram, glValidateProgramARB);
+-    MAP_GL_FUNCTION(glVertexAttrib1f, glVertexAttrib1fARB);
+-    MAP_GL_FUNCTION(glVertexAttrib1fv, glVertexAttrib1fvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib2f, glVertexAttrib2fARB);
+-    MAP_GL_FUNCTION(glVertexAttrib2fv, glVertexAttrib2fvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib3f, glVertexAttrib3fARB);
+-    MAP_GL_FUNCTION(glVertexAttrib3fv, glVertexAttrib3fvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4f, glVertexAttrib4fARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4fv, glVertexAttrib4fvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4Nsv, glVertexAttrib4NsvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4Nub, glVertexAttrib4NubARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4Nubv, glVertexAttrib4NubvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4Nusv, glVertexAttrib4NusvARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4sv, glVertexAttrib4svARB);
+-    MAP_GL_FUNCTION(glVertexAttrib4ubv, glVertexAttrib4ubvARB);
+-    MAP_GL_FUNCTION(glVertexAttribDivisor, glVertexAttribDivisorARB);
+-    MAP_GL_FUNCTION(glVertexAttribIPointer, glVertexAttribIPointerEXT);
+-    MAP_GL_FUNCTION(glVertexAttribPointer, glVertexAttribPointerARB);
+-#undef MAP_GL_FUNCTION
+-#undef MAP_GL_FUNCTION_CAST
+-}
+-
+-static void wined3d_adapter_init_limits(struct wined3d_gl_info *gl_info)
+-{
+-    unsigned int i, sampler_count;
+-    GLfloat gl_floatv[2];
+-    GLint gl_max;
+-
+-    gl_info->limits.buffers = 1;
+-    gl_info->limits.textures = 0;
+-    gl_info->limits.texture_coords = 0;
+-    for (i = 0; i < WINED3D_SHADER_TYPE_COUNT; ++i)
+-    {
+-        gl_info->limits.uniform_blocks[i] = 0;
+-        gl_info->limits.samplers[i] = 0;
+-    }
+-    gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] = 1;
+-    gl_info->limits.combined_samplers = gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL];
+-    gl_info->limits.graphics_samplers = gl_info->limits.combined_samplers;
+-    gl_info->limits.vertex_attribs = 16;
+-    gl_info->limits.texture_buffer_offset_alignment = 1;
+-    gl_info->limits.glsl_vs_float_constants = 0;
+-    gl_info->limits.glsl_ps_float_constants = 0;
+-    gl_info->limits.arb_vs_float_constants = 0;
+-    gl_info->limits.arb_vs_native_constants = 0;
+-    gl_info->limits.arb_vs_instructions = 0;
+-    gl_info->limits.arb_vs_temps = 0;
+-    gl_info->limits.arb_ps_float_constants = 0;
+-    gl_info->limits.arb_ps_local_constants = 0;
+-    gl_info->limits.arb_ps_instructions = 0;
+-    gl_info->limits.arb_ps_temps = 0;
+-
+-    gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_CLIP_DISTANCES, &gl_max);
+-    gl_info->limits.user_clip_distances = min(MAX_CLIP_DISTANCES, gl_max);
+-    TRACE("Clip plane support - max planes %d.\n", gl_max);
+-
+-    if (gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_LIGHTS, &gl_max);
+-        gl_info->limits.lights = gl_max;
+-        TRACE("Light support - max lights %d.\n", gl_max);
+-    }
+-
+-    gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_SIZE, &gl_max);
+-    gl_info->limits.texture_size = gl_max;
+-    TRACE("Maximum texture size support - max texture size %d.\n", gl_max);
+-
+-    gl_info->gl_ops.gl.p_glGetFloatv(gl_info->supported[WINED3D_GL_LEGACY_CONTEXT]
+-            ? GL_ALIASED_POINT_SIZE_RANGE : GL_POINT_SIZE_RANGE, gl_floatv);
+-    gl_info->limits.pointsize_min = gl_floatv[0];
+-    gl_info->limits.pointsize_max = gl_floatv[1];
+-    TRACE("Maximum point size support - max point size %f.\n", gl_floatv[1]);
+-
+-    if (gl_info->supported[ARB_MAP_BUFFER_ALIGNMENT])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MIN_MAP_BUFFER_ALIGNMENT, &gl_max);
+-        TRACE("Minimum buffer map alignment: %d.\n", gl_max);
+-    }
+-    else
+-    {
+-        WARN_(d3d_perf)("Driver doesn't guarantee a minimum buffer map alignment.\n");
+-    }
+-    if (gl_info->supported[NV_REGISTER_COMBINERS])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_GENERAL_COMBINERS_NV, &gl_max);
+-        gl_info->limits.general_combiners = gl_max;
+-        TRACE("Max general combiners: %d.\n", gl_max);
+-    }
+-    if (gl_info->supported[ARB_DRAW_BUFFERS] && wined3d_settings.offscreen_rendering_mode == ORM_FBO)
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_DRAW_BUFFERS_ARB, &gl_max);
+-        gl_info->limits.buffers = min(MAX_RENDER_TARGET_VIEWS, gl_max);
+-        TRACE("Max draw buffers: %u.\n", gl_max);
+-    }
+-    if (gl_info->supported[ARB_MULTITEXTURE])
+-    {
+-        if (gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
+-        {
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_UNITS_ARB, &gl_max);
+-            gl_info->limits.textures = min(MAX_TEXTURES, gl_max);
+-            TRACE("Max textures: %d.\n", gl_info->limits.textures);
+-
+-            if (gl_info->supported[ARB_FRAGMENT_PROGRAM])
+-            {
+-                gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_COORDS_ARB, &gl_max);
+-                gl_info->limits.texture_coords = min(MAX_TEXTURES, gl_max);
+-            }
+-            else
+-            {
+-                gl_info->limits.texture_coords = gl_info->limits.textures;
+-            }
+-            TRACE("Max texture coords: %d.\n", gl_info->limits.texture_coords);
+-        }
+-
+-        if (gl_info->supported[ARB_FRAGMENT_PROGRAM] || gl_info->supported[ARB_FRAGMENT_SHADER])
+-        {
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_IMAGE_UNITS, &gl_max);
+-            gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] = gl_max;
+-        }
+-        else
+-        {
+-            gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] = gl_info->limits.textures;
+-        }
+-        TRACE("Max fragment samplers: %d.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL]);
+-
+-        if (gl_info->supported[ARB_VERTEX_SHADER])
+-        {
+-            unsigned int vertex_sampler_count;
+-
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_TEXTURE_IMAGE_UNITS_ARB, &gl_max);
+-            vertex_sampler_count = gl_info->limits.samplers[WINED3D_SHADER_TYPE_VERTEX] = gl_max;
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS_ARB, &gl_max);
+-            gl_info->limits.combined_samplers = gl_max;
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_ATTRIBS_ARB, &gl_max);
+-            gl_info->limits.vertex_attribs = gl_max;
+-
+-            /* Loading GLSL sampler uniforms is much simpler if we can assume that the sampler setup
+-             * is known at shader link time. In a vertex shader + pixel shader combination this isn't
+-             * an issue because then the sampler setup only depends on the two shaders. If a pixel
+-             * shader is used with fixed function vertex processing we're fine too because fixed function
+-             * vertex processing doesn't use any samplers. If fixed function fragment processing is
+-             * used we have to make sure that all vertex sampler setups are valid together with all
+-             * possible fixed function fragment processing setups. This is true if vsamplers + MAX_TEXTURES
+-             * <= max_samplers. This is true on all d3d9 cards that support vtf(gf 6 and gf7 cards).
+-             * dx9 radeon cards do not support vertex texture fetch. DX10 cards have 128 samplers, and
+-             * dx9 is limited to 8 fixed function texture stages and 4 vertex samplers. DX10 does not have
+-             * a fixed function pipeline anymore.
+-             *
+-             * So this is just a check to check that our assumption holds true. If not, write a warning
+-             * and reduce the number of vertex samplers or probably disable vertex texture fetch. */
+-            if (vertex_sampler_count && gl_info->limits.combined_samplers < 12
+-                    && MAX_TEXTURES + vertex_sampler_count > gl_info->limits.combined_samplers)
+-            {
+-                FIXME("OpenGL implementation supports %u vertex samplers and %u total samplers.\n",
+-                        vertex_sampler_count, gl_info->limits.combined_samplers);
+-                FIXME("Expected vertex samplers + MAX_TEXTURES(=8) > combined_samplers.\n");
+-                if (gl_info->limits.combined_samplers > MAX_TEXTURES)
+-                    vertex_sampler_count = gl_info->limits.combined_samplers - MAX_TEXTURES;
+-                else
+-                    vertex_sampler_count = 0;
+-                gl_info->limits.samplers[WINED3D_SHADER_TYPE_VERTEX] = vertex_sampler_count;
+-            }
+-        }
+-        else
+-        {
+-            gl_info->limits.combined_samplers = gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL];
+-        }
+-        TRACE("Max vertex samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_VERTEX]);
+-        TRACE("Max combined samplers: %u.\n", gl_info->limits.combined_samplers);
+-        TRACE("Max vertex attributes: %u.\n", gl_info->limits.vertex_attribs);
+-    }
+-    else
+-    {
+-        gl_info->limits.textures = 1;
+-        gl_info->limits.texture_coords = 1;
+-    }
+-
+-    if (gl_info->supported[EXT_TEXTURE3D])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_3D_TEXTURE_SIZE_EXT, &gl_max);
+-        gl_info->limits.texture3d_size = gl_max;
+-        TRACE("Max texture3D size: %d.\n", gl_info->limits.texture3d_size);
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_FILTER_ANISOTROPIC])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TEXTURE_MAX_ANISOTROPY, &gl_max);
+-        gl_info->limits.anisotropy = gl_max;
+-        TRACE("Max anisotropy: %d.\n", gl_info->limits.anisotropy);
+-    }
+-    if (gl_info->supported[ARB_FRAGMENT_PROGRAM])
+-    {
+-        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_ENV_PARAMETERS_ARB, &gl_max));
+-        gl_info->limits.arb_ps_float_constants = gl_max;
+-        TRACE("Max ARB_FRAGMENT_PROGRAM float constants: %d.\n", gl_info->limits.arb_ps_float_constants);
+-        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_PARAMETERS_ARB, &gl_max));
+-        gl_info->limits.arb_ps_native_constants = gl_max;
+-        TRACE("Max ARB_FRAGMENT_PROGRAM native float constants: %d.\n",
+-                gl_info->limits.arb_ps_native_constants);
+-        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_TEMPORARIES_ARB, &gl_max));
+-        gl_info->limits.arb_ps_temps = gl_max;
+-        TRACE("Max ARB_FRAGMENT_PROGRAM native temporaries: %d.\n", gl_info->limits.arb_ps_temps);
+-        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_INSTRUCTIONS_ARB, &gl_max));
+-        gl_info->limits.arb_ps_instructions = gl_max;
+-        TRACE("Max ARB_FRAGMENT_PROGRAM native instructions: %d.\n", gl_info->limits.arb_ps_instructions);
+-        GL_EXTCALL(glGetProgramivARB(GL_FRAGMENT_PROGRAM_ARB, GL_MAX_PROGRAM_LOCAL_PARAMETERS_ARB, &gl_max));
+-        gl_info->limits.arb_ps_local_constants = gl_max;
+-        TRACE("Max ARB_FRAGMENT_PROGRAM local parameters: %d.\n", gl_info->limits.arb_ps_instructions);
+-    }
+-    if (gl_info->supported[ARB_VERTEX_PROGRAM])
+-    {
+-        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_ENV_PARAMETERS_ARB, &gl_max));
+-        gl_info->limits.arb_vs_float_constants = gl_max;
+-        TRACE("Max ARB_VERTEX_PROGRAM float constants: %d.\n", gl_info->limits.arb_vs_float_constants);
+-        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_PARAMETERS_ARB, &gl_max));
+-        gl_info->limits.arb_vs_native_constants = gl_max;
+-        TRACE("Max ARB_VERTEX_PROGRAM native float constants: %d.\n",
+-                gl_info->limits.arb_vs_native_constants);
+-        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_TEMPORARIES_ARB, &gl_max));
+-        gl_info->limits.arb_vs_temps = gl_max;
+-        TRACE("Max ARB_VERTEX_PROGRAM native temporaries: %d.\n", gl_info->limits.arb_vs_temps);
+-        GL_EXTCALL(glGetProgramivARB(GL_VERTEX_PROGRAM_ARB, GL_MAX_PROGRAM_NATIVE_INSTRUCTIONS_ARB, &gl_max));
+-        gl_info->limits.arb_vs_instructions = gl_max;
+-        TRACE("Max ARB_VERTEX_PROGRAM native instructions: %d.\n", gl_info->limits.arb_vs_instructions);
+-    }
+-    if (gl_info->supported[ARB_VERTEX_SHADER])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_UNIFORM_COMPONENTS_ARB, &gl_max);
+-        gl_info->limits.glsl_vs_float_constants = gl_max / 4;
+-        TRACE("Max ARB_VERTEX_SHADER float constants: %u.\n", gl_info->limits.glsl_vs_float_constants);
+-
+-        if (gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
+-        {
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_UNIFORM_BLOCKS, &gl_max);
+-            gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_VERTEX] = min(gl_max, WINED3D_MAX_CBS);
+-            TRACE("Max vertex uniform blocks: %u (%d).\n",
+-                    gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_VERTEX], gl_max);
+-        }
+-    }
+-    if (gl_info->supported[ARB_TESSELLATION_SHADER])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_CONTROL_UNIFORM_BLOCKS, &gl_max);
+-        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_HULL] = min(gl_max, WINED3D_MAX_CBS);
+-        TRACE("Max hull uniform blocks: %u (%d).\n",
+-                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_HULL], gl_max);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_CONTROL_TEXTURE_IMAGE_UNITS, &gl_max);
+-        gl_info->limits.samplers[WINED3D_SHADER_TYPE_HULL] = gl_max;
+-        TRACE("Max hull samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_HULL]);
+-
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_EVALUATION_UNIFORM_BLOCKS, &gl_max);
+-        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_DOMAIN] = min(gl_max, WINED3D_MAX_CBS);
+-        TRACE("Max domain uniform blocks: %u (%d).\n",
+-                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_DOMAIN], gl_max);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_TESS_EVALUATION_TEXTURE_IMAGE_UNITS, &gl_max);
+-        gl_info->limits.samplers[WINED3D_SHADER_TYPE_DOMAIN] = gl_max;
+-        TRACE("Max domain samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_DOMAIN]);
+-    }
+-    if (gl_info->supported[WINED3D_GL_VERSION_3_2] && gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_GEOMETRY_UNIFORM_BLOCKS, &gl_max);
+-        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_GEOMETRY] = min(gl_max, WINED3D_MAX_CBS);
+-        TRACE("Max geometry uniform blocks: %u (%d).\n",
+-                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_GEOMETRY], gl_max);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_GEOMETRY_TEXTURE_IMAGE_UNITS, &gl_max);
+-        gl_info->limits.samplers[WINED3D_SHADER_TYPE_GEOMETRY] = gl_max;
+-        TRACE("Max geometry samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_GEOMETRY]);
+-    }
+-    if (gl_info->supported[ARB_FRAGMENT_SHADER])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAGMENT_UNIFORM_COMPONENTS_ARB, &gl_max);
+-        gl_info->limits.glsl_ps_float_constants = gl_max / 4;
+-        TRACE("Max ARB_FRAGMENT_SHADER float constants: %u.\n", gl_info->limits.glsl_ps_float_constants);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VARYING_FLOATS_ARB, &gl_max);
+-        gl_info->limits.glsl_varyings = gl_max;
+-        TRACE("Max GLSL varyings: %u (%u 4 component varyings).\n", gl_max, gl_max / 4);
+-
+-        if (gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
+-        {
+-            gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAGMENT_UNIFORM_BLOCKS, &gl_max);
+-            gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_PIXEL] = min(gl_max, WINED3D_MAX_CBS);
+-            TRACE("Max fragment uniform blocks: %u (%d).\n",
+-                    gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_PIXEL], gl_max);
+-        }
+-    }
+-    if (gl_info->supported[ARB_COMPUTE_SHADER])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMPUTE_UNIFORM_BLOCKS, &gl_max);
+-        gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_COMPUTE] = min(gl_max, WINED3D_MAX_CBS);
+-        TRACE("Max compute uniform blocks: %u (%d).\n",
+-                gl_info->limits.uniform_blocks[WINED3D_SHADER_TYPE_COMPUTE], gl_max);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMPUTE_TEXTURE_IMAGE_UNITS, &gl_max);
+-        gl_info->limits.samplers[WINED3D_SHADER_TYPE_COMPUTE] = gl_max;
+-        TRACE("Max compute samplers: %u.\n", gl_info->limits.samplers[WINED3D_SHADER_TYPE_COMPUTE]);
+-    }
+-    if (gl_info->supported[ARB_UNIFORM_BUFFER_OBJECT])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMBINED_UNIFORM_BLOCKS, &gl_max);
+-        TRACE("Max combined uniform blocks: %d.\n", gl_max);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_UNIFORM_BUFFER_BINDINGS, &gl_max);
+-        TRACE("Max uniform buffer bindings: %d.\n", gl_max);
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_BUFFER_RANGE])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_TEXTURE_BUFFER_OFFSET_ALIGNMENT, &gl_max);
+-        gl_info->limits.texture_buffer_offset_alignment = gl_max;
+-        TRACE("Minimum required texture buffer offset alignment %d.\n", gl_max);
+-    }
+-    if (gl_info->supported[ARB_SHADER_ATOMIC_COUNTERS])
+-    {
+-        GLint max_fragment_buffers, max_combined_buffers, max_bindings;
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAGMENT_ATOMIC_COUNTER_BUFFERS, &max_fragment_buffers);
+-        TRACE("Max fragment atomic counter buffers: %d.\n", max_fragment_buffers);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_COMBINED_ATOMIC_COUNTER_BUFFERS, &max_combined_buffers);
+-        TRACE("Max combined atomic counter buffers: %d.\n", max_combined_buffers);
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_ATOMIC_COUNTER_BUFFER_BINDINGS, &max_bindings);
+-        TRACE("Max atomic counter buffer bindings: %d.\n", max_bindings);
+-        if (max_fragment_buffers < MAX_UNORDERED_ACCESS_VIEWS
+-                || max_combined_buffers < MAX_UNORDERED_ACCESS_VIEWS
+-                || max_bindings < MAX_UNORDERED_ACCESS_VIEWS)
+-        {
+-            WARN("Disabling ARB_shader_atomic_counters.\n");
+-            gl_info->supported[ARB_SHADER_ATOMIC_COUNTERS] = FALSE;
+-        }
+-    }
+-    if (gl_info->supported[ARB_TRANSFORM_FEEDBACK3])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_VERTEX_STREAMS, &gl_max);
+-        TRACE("Max vertex streams: %d.\n", gl_max);
+-    }
+-
+-    if (gl_info->supported[NV_LIGHT_MAX_EXPONENT])
+-        gl_info->gl_ops.gl.p_glGetFloatv(GL_MAX_SHININESS_NV, &gl_info->limits.shininess);
+-    else
+-        gl_info->limits.shininess = 128.0f;
+-
+-    if (gl_info->supported[ARB_FRAMEBUFFER_OBJECT] || gl_info->supported[EXT_FRAMEBUFFER_MULTISAMPLE])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_SAMPLES, &gl_max);
+-        gl_info->limits.samples = gl_max;
+-    }
+-
+-    if (gl_info->supported[ARB_FRAMEBUFFER_NO_ATTACHMENTS])
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAMEBUFFER_WIDTH, &gl_max);
+-        gl_info->limits.framebuffer_width = gl_max;
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_MAX_FRAMEBUFFER_HEIGHT, &gl_max);
+-        gl_info->limits.framebuffer_height = gl_max;
+-    }
+-    else
+-    {
+-        gl_info->limits.framebuffer_width = gl_info->limits.texture_size;
+-        gl_info->limits.framebuffer_height = gl_info->limits.texture_size;
+-    }
+-
+-    gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL] =
+-            min(gl_info->limits.samplers[WINED3D_SHADER_TYPE_PIXEL], MAX_GL_FRAGMENT_SAMPLERS);
+-    sampler_count = 0;
+-    for (i = 0; i < WINED3D_SHADER_TYPE_GRAPHICS_COUNT; ++i)
+-        sampler_count += gl_info->limits.samplers[i];
+-    if (gl_info->supported[WINED3D_GL_VERSION_3_2] && gl_info->limits.combined_samplers < sampler_count)
+-    {
+-        /* The minimum value for GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS in OpenGL
+-         * 3.2 is 48 (16 per stage). When tessellation shaders are supported
+-         * the minimum value is increased to 80. */
+-        WARN("Graphics pipeline sampler count %u is greater than combined sampler count %u.\n",
+-                sampler_count, gl_info->limits.combined_samplers);
+-        for (i = 0; i < WINED3D_SHADER_TYPE_GRAPHICS_COUNT; ++i)
+-            gl_info->limits.samplers[i] = min(gl_info->limits.samplers[i], 16);
+-    }
+-
+-    /* A majority of OpenGL implementations allow us to statically partition
+-     * the set of texture bindings into six separate sets. */
+-    gl_info->limits.graphics_samplers = gl_info->limits.combined_samplers;
+-    sampler_count = 0;
+-    for (i = 0; i < WINED3D_SHADER_TYPE_COUNT; ++i)
+-        sampler_count += gl_info->limits.samplers[i];
+-    if (gl_info->limits.combined_samplers >= sampler_count)
+-        gl_info->limits.graphics_samplers -= gl_info->limits.samplers[WINED3D_SHADER_TYPE_COMPUTE];
+-}
+-
+-/* Context activation is done by the caller. */
+-static BOOL wined3d_adapter_init_gl_caps(struct wined3d_adapter *adapter,
+-        struct wined3d_caps_gl_ctx *caps_gl_ctx, DWORD wined3d_creation_flags)
+-{
+-    static const struct
+-    {
+-        enum wined3d_gl_extension extension;
+-        DWORD min_gl_version;
+-    }
+-    core_extensions[] =
+-    {
+-        {EXT_TEXTURE3D,                    MAKEDWORD_VERSION(1, 2)},
+-        {ARB_MULTISAMPLE,                  MAKEDWORD_VERSION(1, 3)},
+-        {ARB_MULTITEXTURE,                 MAKEDWORD_VERSION(1, 3)},
+-        {ARB_TEXTURE_BORDER_CLAMP,         MAKEDWORD_VERSION(1, 3)},
+-        {ARB_TEXTURE_COMPRESSION,          MAKEDWORD_VERSION(1, 3)},
+-        {ARB_TEXTURE_CUBE_MAP,             MAKEDWORD_VERSION(1, 3)},
+-        {ARB_DEPTH_TEXTURE,                MAKEDWORD_VERSION(1, 4)},
+-        {ARB_POINT_PARAMETERS,             MAKEDWORD_VERSION(1, 4)},
+-        {ARB_SHADOW,                       MAKEDWORD_VERSION(1, 4)},
+-        {ARB_TEXTURE_MIRRORED_REPEAT,      MAKEDWORD_VERSION(1, 4)},
+-        {EXT_BLEND_COLOR,                  MAKEDWORD_VERSION(1, 4)},
+-        {EXT_BLEND_FUNC_SEPARATE,          MAKEDWORD_VERSION(1, 4)},
+-        {EXT_BLEND_MINMAX,                 MAKEDWORD_VERSION(1, 4)},
+-        {EXT_BLEND_SUBTRACT,               MAKEDWORD_VERSION(1, 4)},
+-        {EXT_STENCIL_WRAP,                 MAKEDWORD_VERSION(1, 4)},
+-        {NV_POINT_SPRITE,                  MAKEDWORD_VERSION(1, 4)},
+-        {ARB_OCCLUSION_QUERY,              MAKEDWORD_VERSION(1, 5)},
+-        {ARB_VERTEX_BUFFER_OBJECT,         MAKEDWORD_VERSION(1, 5)},
+-        {ARB_DRAW_BUFFERS,                 MAKEDWORD_VERSION(2, 0)},
+-        {ARB_FRAGMENT_SHADER,              MAKEDWORD_VERSION(2, 0)},
+-        {ARB_SHADING_LANGUAGE_100,         MAKEDWORD_VERSION(2, 0)},
+-        {ARB_TEXTURE_NON_POWER_OF_TWO,     MAKEDWORD_VERSION(2, 0)},
+-        {ARB_VERTEX_SHADER,                MAKEDWORD_VERSION(2, 0)},
+-        {EXT_BLEND_EQUATION_SEPARATE,      MAKEDWORD_VERSION(2, 0)},
+-        {ARB_PIXEL_BUFFER_OBJECT,          MAKEDWORD_VERSION(2, 1)},
+-        {EXT_TEXTURE_SRGB,                 MAKEDWORD_VERSION(2, 1)},
+-        {ARB_COLOR_BUFFER_FLOAT,           MAKEDWORD_VERSION(3, 0)},
+-        {ARB_DEPTH_BUFFER_FLOAT,           MAKEDWORD_VERSION(3, 0)},
+-        {ARB_FRAMEBUFFER_OBJECT,           MAKEDWORD_VERSION(3, 0)},
+-        {ARB_FRAMEBUFFER_SRGB,             MAKEDWORD_VERSION(3, 0)},
+-        {ARB_HALF_FLOAT_PIXEL,             MAKEDWORD_VERSION(3, 0)},
+-        {ARB_HALF_FLOAT_VERTEX,            MAKEDWORD_VERSION(3, 0)},
+-        {ARB_MAP_BUFFER_RANGE,             MAKEDWORD_VERSION(3, 0)},
+-        {ARB_TEXTURE_COMPRESSION_RGTC,     MAKEDWORD_VERSION(3, 0)},
+-        {ARB_TEXTURE_FLOAT,                MAKEDWORD_VERSION(3, 0)},
+-        {ARB_TEXTURE_RG,                   MAKEDWORD_VERSION(3, 0)},
+-        {EXT_DRAW_BUFFERS2,                MAKEDWORD_VERSION(3, 0)},
+-        {EXT_PACKED_FLOAT,                 MAKEDWORD_VERSION(3, 0)},
+-        {EXT_TEXTURE_ARRAY,                MAKEDWORD_VERSION(3, 0)},
+-        {EXT_TEXTURE_INTEGER,              MAKEDWORD_VERSION(3, 0)},
+-        {EXT_TEXTURE_SHARED_EXPONENT,      MAKEDWORD_VERSION(3, 0)},
+-        /* We don't want to enable EXT_GPU_SHADER4: even though similar
+-         * functionality is available in core GL 3.0 / GLSL 1.30, it's different
+-         * enough that reusing the same flag for the new features hurts more
+-         * than it helps. */
+-        /* EXT_framebuffer_object, EXT_framebuffer_blit,
+-         * EXT_framebuffer_multisample and EXT_packed_depth_stencil
+-         * are integrated into ARB_framebuffer_object. */
+-
+-        {ARB_COPY_BUFFER,                  MAKEDWORD_VERSION(3, 1)},
+-        {ARB_DRAW_INSTANCED,               MAKEDWORD_VERSION(3, 1)},
+-        {ARB_TEXTURE_BUFFER_OBJECT,        MAKEDWORD_VERSION(3, 1)},
+-        {ARB_UNIFORM_BUFFER_OBJECT,        MAKEDWORD_VERSION(3, 1)},
+-        {EXT_TEXTURE_SNORM,                MAKEDWORD_VERSION(3, 1)},
+-        /* We don't need or want GL_ARB_texture_rectangle (core in 3.1). */
+-
+-        {ARB_DEPTH_CLAMP,                  MAKEDWORD_VERSION(3, 2)},
+-        {ARB_DRAW_ELEMENTS_BASE_VERTEX,    MAKEDWORD_VERSION(3, 2)},
+-        /* ARB_geometry_shader4 exposes a somewhat different API compared to 3.2
+-         * core geometry shaders so it's not really correct to expose the
+-         * extension for core-only support. */
+-        {ARB_FRAGMENT_COORD_CONVENTIONS,   MAKEDWORD_VERSION(3, 2)},
+-        {ARB_PROVOKING_VERTEX,             MAKEDWORD_VERSION(3, 2)},
+-        {ARB_SEAMLESS_CUBE_MAP,            MAKEDWORD_VERSION(3, 2)},
+-        {ARB_SYNC,                         MAKEDWORD_VERSION(3, 2)},
+-        {ARB_TEXTURE_MULTISAMPLE,          MAKEDWORD_VERSION(3, 2)},
+-        {ARB_VERTEX_ARRAY_BGRA,            MAKEDWORD_VERSION(3, 2)},
+-
+-        {ARB_BLEND_FUNC_EXTENDED,          MAKEDWORD_VERSION(3, 3)},
+-        {ARB_EXPLICIT_ATTRIB_LOCATION,     MAKEDWORD_VERSION(3, 3)},
+-        {ARB_INSTANCED_ARRAYS,             MAKEDWORD_VERSION(3, 3)},
+-        {ARB_SAMPLER_OBJECTS,              MAKEDWORD_VERSION(3, 3)},
+-        {ARB_SHADER_BIT_ENCODING,          MAKEDWORD_VERSION(3, 3)},
+-        {ARB_TEXTURE_RGB10_A2UI,           MAKEDWORD_VERSION(3, 3)},
+-        {ARB_TEXTURE_SWIZZLE,              MAKEDWORD_VERSION(3, 3)},
+-        {ARB_TIMER_QUERY,                  MAKEDWORD_VERSION(3, 3)},
+-        {ARB_VERTEX_TYPE_2_10_10_10_REV,   MAKEDWORD_VERSION(3, 3)},
+-
+-        {ARB_DRAW_INDIRECT,                MAKEDWORD_VERSION(4, 0)},
+-        {ARB_GPU_SHADER5,                  MAKEDWORD_VERSION(4, 0)},
+-        {ARB_SAMPLE_SHADING,               MAKEDWORD_VERSION(4, 0)},
+-        {ARB_TESSELLATION_SHADER,          MAKEDWORD_VERSION(4, 0)},
+-        {ARB_TEXTURE_CUBE_MAP_ARRAY,       MAKEDWORD_VERSION(4, 0)},
+-        {ARB_TEXTURE_GATHER,               MAKEDWORD_VERSION(4, 0)},
+-        {ARB_TRANSFORM_FEEDBACK2,          MAKEDWORD_VERSION(4, 0)},
+-        {ARB_TRANSFORM_FEEDBACK3,          MAKEDWORD_VERSION(4, 0)},
+-
+-        {ARB_ES2_COMPATIBILITY,            MAKEDWORD_VERSION(4, 1)},
+-        {ARB_VIEWPORT_ARRAY,               MAKEDWORD_VERSION(4, 1)},
+-
+-        {ARB_BASE_INSTANCE,                MAKEDWORD_VERSION(4, 2)},
+-        {ARB_CONSERVATIVE_DEPTH,           MAKEDWORD_VERSION(4, 2)},
+-        {ARB_INTERNALFORMAT_QUERY,         MAKEDWORD_VERSION(4, 2)},
+-        {ARB_MAP_BUFFER_ALIGNMENT,         MAKEDWORD_VERSION(4, 2)},
+-        {ARB_SHADER_ATOMIC_COUNTERS,       MAKEDWORD_VERSION(4, 2)},
+-        {ARB_SHADER_IMAGE_LOAD_STORE,      MAKEDWORD_VERSION(4, 2)},
+-        {ARB_SHADING_LANGUAGE_420PACK,     MAKEDWORD_VERSION(4, 2)},
+-        {ARB_SHADING_LANGUAGE_PACKING,     MAKEDWORD_VERSION(4, 2)},
+-        {ARB_TEXTURE_COMPRESSION_BPTC,     MAKEDWORD_VERSION(4, 2)},
+-        {ARB_TEXTURE_STORAGE,              MAKEDWORD_VERSION(4, 2)},
+-
+-        {ARB_CLEAR_BUFFER_OBJECT,          MAKEDWORD_VERSION(4, 3)},
+-        {ARB_COMPUTE_SHADER,               MAKEDWORD_VERSION(4, 3)},
+-        {ARB_COPY_IMAGE,                   MAKEDWORD_VERSION(4, 3)},
+-        {ARB_DEBUG_OUTPUT,                 MAKEDWORD_VERSION(4, 3)},
+-        {ARB_ES3_COMPATIBILITY,            MAKEDWORD_VERSION(4, 3)},
+-        {ARB_FRAGMENT_LAYER_VIEWPORT,      MAKEDWORD_VERSION(4, 3)},
+-        {ARB_FRAMEBUFFER_NO_ATTACHMENTS,   MAKEDWORD_VERSION(4, 3)},
+-        {ARB_INTERNALFORMAT_QUERY2,        MAKEDWORD_VERSION(4, 3)},
+-        {ARB_SHADER_IMAGE_SIZE,            MAKEDWORD_VERSION(4, 3)},
+-        {ARB_SHADER_STORAGE_BUFFER_OBJECT, MAKEDWORD_VERSION(4, 3)},
+-        {ARB_STENCIL_TEXTURING,            MAKEDWORD_VERSION(4, 3)},
+-        {ARB_TEXTURE_BUFFER_RANGE,         MAKEDWORD_VERSION(4, 3)},
+-        {ARB_TEXTURE_QUERY_LEVELS,         MAKEDWORD_VERSION(4, 3)},
+-        {ARB_TEXTURE_STORAGE_MULTISAMPLE,  MAKEDWORD_VERSION(4, 2)},
+-        {ARB_TEXTURE_VIEW,                 MAKEDWORD_VERSION(4, 3)},
+-
+-        {ARB_CLEAR_TEXTURE,                MAKEDWORD_VERSION(4, 4)},
+-        {ARB_MULTI_BIND,                   MAKEDWORD_VERSION(4, 4)},
+-
+-        {ARB_CLIP_CONTROL,                 MAKEDWORD_VERSION(4, 5)},
+-        {ARB_CULL_DISTANCE,                MAKEDWORD_VERSION(4, 5)},
+-        {ARB_DERIVATIVE_CONTROL,           MAKEDWORD_VERSION(4, 5)},
+-        {ARB_SHADER_TEXTURE_IMAGE_SAMPLES, MAKEDWORD_VERSION(4, 5)},
+-
+-        {ARB_PIPELINE_STATISTICS_QUERY,    MAKEDWORD_VERSION(4, 6)},
+-        {ARB_TEXTURE_FILTER_ANISOTROPIC,   MAKEDWORD_VERSION(4, 6)},
+-    };
+-    struct wined3d_driver_info *driver_info = &adapter->driver_info;
+-    const char *gl_vendor_str, *gl_renderer_str, *gl_version_str;
+-    struct wined3d_d3d_info *d3d_info = &adapter->d3d_info;
+-    struct wined3d_gl_info *gl_info = &adapter->gl_info;
+-    const struct gpu_description *gpu_description;
+-    struct wined3d_vertex_caps vertex_caps;
+-    struct fragment_caps fragment_caps;
+-    struct shader_caps shader_caps;
+-    const char *WGL_Extensions = NULL;
+-    enum wined3d_gl_vendor gl_vendor;
+-    DWORD gl_version, gl_ext_emul_mask;
+-    GLint context_profile = 0;
+-    UINT64 vram_bytes = 0;
+-    unsigned int i, j;
+-    HDC hdc;
+-
+-    TRACE("adapter %p.\n", adapter);
+-
+-    gl_renderer_str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_RENDERER);
+-    TRACE("GL_RENDERER: %s.\n", debugstr_a(gl_renderer_str));
+-    if (!gl_renderer_str)
+-    {
+-        ERR("Received a NULL GL_RENDERER.\n");
+-        return FALSE;
+-    }
+-
+-    gl_vendor_str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_VENDOR);
+-    TRACE("GL_VENDOR: %s.\n", debugstr_a(gl_vendor_str));
+-    if (!gl_vendor_str)
+-    {
+-        ERR("Received a NULL GL_VENDOR.\n");
+-        return FALSE;
+-    }
+-
+-    /* Parse the GL_VERSION field into major and minor information */
+-    gl_version_str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_VERSION);
+-    TRACE("GL_VERSION: %s.\n", debugstr_a(gl_version_str));
+-    if (!gl_version_str)
+-    {
+-        ERR("Received a NULL GL_VERSION.\n");
+-        return FALSE;
+-    }
+-    gl_version = wined3d_parse_gl_version(gl_version_str);
+-
+-    load_gl_funcs(gl_info);
+-
+-    memset(gl_info->supported, 0, sizeof(gl_info->supported));
+-    gl_info->supported[WINED3D_GL_EXT_NONE] = TRUE;
+-
+-    if (gl_version >= MAKEDWORD_VERSION(3, 2))
+-    {
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_CONTEXT_PROFILE_MASK, &context_profile);
+-        checkGLcall("Querying context profile");
+-    }
+-    if (context_profile & GL_CONTEXT_CORE_PROFILE_BIT)
+-        TRACE("Got a core profile context.\n");
+-    else
+-        gl_info->supported[WINED3D_GL_LEGACY_CONTEXT] = TRUE;
+-
+-    TRACE("GL extensions reported:\n");
+-    if (gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
+-    {
+-        const char *gl_extensions = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_EXTENSIONS);
+-
+-        if (!gl_extensions)
+-        {
+-            ERR("Received a NULL GL_EXTENSIONS.\n");
+-            return FALSE;
+-        }
+-        parse_extension_string(gl_info, gl_extensions, gl_extension_map, ARRAY_SIZE(gl_extension_map));
+-    }
+-    else
+-    {
+-        enumerate_gl_extensions(gl_info, gl_extension_map, ARRAY_SIZE(gl_extension_map));
+-    }
+-
+-    hdc = wglGetCurrentDC();
+-    /* Not all GL drivers might offer WGL extensions e.g. VirtualBox. */
+-    if (GL_EXTCALL(wglGetExtensionsStringARB))
+-        WGL_Extensions = (const char *)GL_EXTCALL(wglGetExtensionsStringARB(hdc));
+-    if (!WGL_Extensions)
+-        WARN("WGL extensions not supported.\n");
+-    else
+-        parse_extension_string(gl_info, WGL_Extensions, wgl_extension_map, ARRAY_SIZE(wgl_extension_map));
+-
+-    for (i = 0; i < ARRAY_SIZE(core_extensions); ++i)
+-    {
+-        if (!gl_info->supported[core_extensions[i].extension]
+-                && gl_version >= core_extensions[i].min_gl_version)
+-        {
+-            for (j = 0; j < ARRAY_SIZE(gl_extension_map); ++j)
+-                if (gl_extension_map[j].extension == core_extensions[i].extension)
+-                    break;
+-
+-            if (j < ARRAY_SIZE(gl_extension_map))
+-            {
+-                TRACE("GL CORE: %s support.\n", gl_extension_map[j].extension_string);
+-                gl_info->supported[core_extensions[i].extension] = TRUE;
+-            }
+-            else
+-            {
+-                FIXME("GL extension %u not in the GL extensions map.\n", core_extensions[i].extension);
+-            }
+-        }
+-    }
+-
+-    if (gl_info->supported[EXT_BLEND_MINMAX] || gl_info->supported[EXT_BLEND_SUBTRACT])
+-        gl_info->supported[WINED3D_GL_BLEND_EQUATION] = TRUE;
+-
+-    if (gl_version >= MAKEDWORD_VERSION(2, 0))
+-    {
+-        gl_info->supported[WINED3D_GL_VERSION_2_0] = TRUE;
+-        /* We want to use the core APIs for two-sided stencil in GL 2.0. */
+-        gl_info->supported[EXT_STENCIL_TWO_SIDE] = FALSE;
+-    }
+-    if (gl_version >= MAKEDWORD_VERSION(3, 2))
+-        gl_info->supported[WINED3D_GL_VERSION_3_2] = TRUE;
+-
+-    /* All the points are actually point sprites in core contexts, the APIs from
+-     * ARB_point_sprite are not supported anymore. */
+-    if (!gl_info->supported[WINED3D_GL_LEGACY_CONTEXT])
+-        gl_info->supported[ARB_POINT_SPRITE] = FALSE;
+-
+-    if (gl_info->supported[APPLE_FENCE])
+-    {
+-        /* GL_NV_fence and GL_APPLE_fence provide the same functionality basically.
+-         * The apple extension interacts with some other apple exts. Disable the NV
+-         * extension if the apple one is support to prevent confusion in other parts
+-         * of the code. */
+-        gl_info->supported[NV_FENCE] = FALSE;
+-    }
+-    if (gl_info->supported[APPLE_FLOAT_PIXELS])
+-    {
+-        /* GL_APPLE_float_pixels == GL_ARB_texture_float + GL_ARB_half_float_pixel
+-         *
+-         * The enums are the same:
+-         * GL_RGBA16F_ARB     = GL_RGBA_FLOAT16_APPLE = 0x881a
+-         * GL_RGB16F_ARB      = GL_RGB_FLOAT16_APPLE  = 0x881b
+-         * GL_RGBA32F_ARB     = GL_RGBA_FLOAT32_APPLE = 0x8814
+-         * GL_RGB32F_ARB      = GL_RGB_FLOAT32_APPLE  = 0x8815
+-         * GL_HALF_FLOAT_ARB  = GL_HALF_APPLE         = 0x140b
+-         */
+-        if (!gl_info->supported[ARB_TEXTURE_FLOAT])
+-        {
+-            TRACE(" IMPLIED: GL_ARB_texture_float support (by GL_APPLE_float_pixels).\n");
+-            gl_info->supported[ARB_TEXTURE_FLOAT] = TRUE;
+-        }
+-        if (!gl_info->supported[ARB_HALF_FLOAT_PIXEL])
+-        {
+-            TRACE(" IMPLIED: GL_ARB_half_float_pixel support (by GL_APPLE_float_pixels).\n");
+-            gl_info->supported[ARB_HALF_FLOAT_PIXEL] = TRUE;
+-        }
+-    }
+-    if (gl_info->supported[ARB_MAP_BUFFER_RANGE])
+-    {
+-        /* GL_ARB_map_buffer_range and GL_APPLE_flush_buffer_range provide the same
+-         * functionality. Prefer the ARB extension */
+-        gl_info->supported[APPLE_FLUSH_BUFFER_RANGE] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_CUBE_MAP])
+-    {
+-        TRACE(" IMPLIED: NVIDIA (NV) Texture Gen Reflection support.\n");
+-        gl_info->supported[NV_TEXGEN_REFLECTION] = TRUE;
+-    }
+-    if (!gl_info->supported[ARB_VERTEX_ARRAY_BGRA] && gl_info->supported[EXT_VERTEX_ARRAY_BGRA])
+-    {
+-        TRACE(" IMPLIED: ARB_vertex_array_bgra support (by EXT_vertex_array_bgra).\n");
+-        gl_info->supported[ARB_VERTEX_ARRAY_BGRA] = TRUE;
+-    }
+-    if (!gl_info->supported[EXT_TEXTURE_COMPRESSION_RGTC] && gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC])
+-    {
+-        TRACE(" IMPLIED: EXT_texture_compression_rgtc support (by ARB_texture_compression_rgtc).\n");
+-        gl_info->supported[EXT_TEXTURE_COMPRESSION_RGTC] = TRUE;
+-    }
+-    if (!gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] && gl_info->supported[EXT_TEXTURE_COMPRESSION_RGTC])
+-    {
+-        TRACE(" IMPLIED: ARB_texture_compression_rgtc support (by EXT_texture_compression_rgtc).\n");
+-        gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] = TRUE;
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] && !gl_info->supported[ARB_TEXTURE_RG])
+-    {
+-        TRACE("ARB_texture_rg not supported, disabling ARB_texture_compression_rgtc.\n");
+-        gl_info->supported[ARB_TEXTURE_COMPRESSION_RGTC] = FALSE;
+-    }
+-    if (gl_info->supported[NV_TEXTURE_SHADER2])
+-    {
+-        if (gl_info->supported[NV_REGISTER_COMBINERS])
+-        {
+-            /* Also disable ATI_FRAGMENT_SHADER if register combiners and texture_shader2
+-             * are supported. The nv extensions provide the same functionality as the
+-             * ATI one, and a bit more(signed pixelformats). */
+-            gl_info->supported[ATI_FRAGMENT_SHADER] = FALSE;
+-        }
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_NON_POWER_OF_TWO])
+-    {
+-        /* If we have full NP2 texture support, disable
+-         * GL_ARB_texture_rectangle because we will never use it.
+-         * This saves a few redundant glDisable calls. */
+-        gl_info->supported[ARB_TEXTURE_RECTANGLE] = FALSE;
+-    }
+-    if (gl_info->supported[ATI_FRAGMENT_SHADER])
+-    {
+-        /* Disable NV_register_combiners and fragment shader if this is supported.
+-         * generally the NV extensions are preferred over the ATI ones, and this
+-         * extension is disabled if register_combiners and texture_shader2 are both
+-         * supported. So we reach this place only if we have incomplete NV dxlevel 8
+-         * fragment processing support. */
+-        gl_info->supported[NV_REGISTER_COMBINERS] = FALSE;
+-        gl_info->supported[NV_REGISTER_COMBINERS2] = FALSE;
+-        gl_info->supported[NV_TEXTURE_SHADER] = FALSE;
+-        gl_info->supported[NV_TEXTURE_SHADER2] = FALSE;
+-    }
+-    if (gl_info->supported[NV_HALF_FLOAT])
+-    {
+-        /* GL_ARB_half_float_vertex is a subset of GL_NV_half_float. */
+-        gl_info->supported[ARB_HALF_FLOAT_VERTEX] = TRUE;
+-    }
+-    if (gl_info->supported[ARB_FRAMEBUFFER_SRGB] && !gl_info->supported[EXT_TEXTURE_SRGB_DECODE])
+-    {
+-        /* Current wined3d sRGB infrastructure requires EXT_texture_sRGB_decode
+-         * for GL_ARB_framebuffer_sRGB support (without EXT_texture_sRGB_decode
+-         * we never render to sRGB surfaces). */
+-        TRACE("EXT_texture_sRGB_decode is not supported, disabling ARB_framebuffer_sRGB.\n");
+-        gl_info->supported[ARB_FRAMEBUFFER_SRGB] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_OCCLUSION_QUERY])
+-    {
+-        GLint counter_bits;
+-
+-        GL_EXTCALL(glGetQueryiv(GL_SAMPLES_PASSED, GL_QUERY_COUNTER_BITS, &counter_bits));
+-        TRACE("Occlusion query counter has %d bits.\n", counter_bits);
+-        if (!counter_bits)
+-            gl_info->supported[ARB_OCCLUSION_QUERY] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_TIMER_QUERY])
+-    {
+-        GLint counter_bits;
+-
+-        GL_EXTCALL(glGetQueryiv(GL_TIMESTAMP, GL_QUERY_COUNTER_BITS, &counter_bits));
+-        TRACE("Timestamp query counter has %d bits.\n", counter_bits);
+-        if (!counter_bits)
+-            gl_info->supported[ARB_TIMER_QUERY] = FALSE;
+-    }
+-    if (gl_version >= MAKEDWORD_VERSION(3, 0))
+-    {
+-        GLint counter_bits;
+-
+-        gl_info->supported[WINED3D_GL_PRIMITIVE_QUERY] = TRUE;
+-
+-        GL_EXTCALL(glGetQueryiv(GL_PRIMITIVES_GENERATED, GL_QUERY_COUNTER_BITS, &counter_bits));
+-        TRACE("Primitives query counter has %d bits.\n", counter_bits);
+-        if (!counter_bits)
+-            gl_info->supported[WINED3D_GL_PRIMITIVE_QUERY] = FALSE;
+-
+-        GL_EXTCALL(glGetQueryiv(GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN, GL_QUERY_COUNTER_BITS, &counter_bits));
+-        TRACE("Transform feedback primitives query counter has %d bits.\n", counter_bits);
+-        if (!counter_bits)
+-            gl_info->supported[WINED3D_GL_PRIMITIVE_QUERY] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_VIEWPORT_ARRAY])
+-    {
+-        GLint subpixel_bits;
+-
+-        gl_info->gl_ops.gl.p_glGetIntegerv(GL_VIEWPORT_SUBPIXEL_BITS, &subpixel_bits);
+-        TRACE("Viewport supports %d subpixel bits.\n", subpixel_bits);
+-        if (subpixel_bits < 8 && gl_info->supported[ARB_CLIP_CONTROL])
+-        {
+-            TRACE("Disabling ARB_clip_control because viewport subpixel bits < 8.\n");
+-            gl_info->supported[ARB_CLIP_CONTROL] = FALSE;
+-        }
+-    }
+-    if (gl_info->supported[ARB_CLIP_CONTROL] && !gl_info->supported[ARB_VIEWPORT_ARRAY])
+-    {
+-        /* When using ARB_clip_control we need the float viewport parameters
+-         * introduced by ARB_viewport_array to take care of the shifted pixel
+-         * coordinates. */
+-        TRACE("Disabling ARB_clip_control because ARB_viewport_array is not supported.\n");
+-        gl_info->supported[ARB_CLIP_CONTROL] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_STENCIL_TEXTURING] && !gl_info->supported[ARB_TEXTURE_SWIZZLE])
+-    {
+-        /* The stencil value needs to be placed in the green channel.  */
+-        TRACE("Disabling ARB_stencil_texturing because ARB_texture_swizzle is not supported.\n");
+-        gl_info->supported[ARB_STENCIL_TEXTURING] = FALSE;
+-    }
+-    if (!gl_info->supported[ATI_TEXTURE_MIRROR_ONCE] && gl_info->supported[EXT_TEXTURE_MIRROR_CLAMP])
+-    {
+-        TRACE(" IMPLIED: ATI_texture_mirror_once support (by EXT_texture_mirror_clamp).\n");
+-        gl_info->supported[ATI_TEXTURE_MIRROR_ONCE] = TRUE;
+-    }
+-    if (!gl_info->supported[ARB_TEXTURE_MIRROR_CLAMP_TO_EDGE] && gl_info->supported[ATI_TEXTURE_MIRROR_ONCE])
+-    {
+-        TRACE(" IMPLIED: ARB_texture_mirror_clamp_to_edge support (by ATI_texture_mirror_once).\n");
+-        gl_info->supported[ARB_TEXTURE_MIRROR_CLAMP_TO_EDGE] = TRUE;
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_STORAGE] && gl_info->supported[APPLE_YCBCR_422])
+-    {
+-        /* AFAIK APPLE_ycbcr_422 is only available in legacy contexts so we shouldn't ever hit this. */
+-        ERR("Disabling APPLE_ycbcr_422 because of ARB_texture_storage.\n");
+-        gl_info->supported[APPLE_YCBCR_422] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_DRAW_INDIRECT] && !gl_info->supported[ARB_BASE_INSTANCE])
+-    {
+-        /* If ARB_base_instance is not supported the baseInstance field
+-         * in indirect draw parameters must be 0 or behavior is undefined.
+-         */
+-        WARN("Disabling ARB_draw_indirect because ARB_base_instance is not supported.\n");
+-        gl_info->supported[ARB_DRAW_INDIRECT] = FALSE;
+-    }
+-    if (gl_info->supported[ARB_TEXTURE_MULTISAMPLE] && !wined3d_settings.multisample_textures)
+-        gl_info->supported[ARB_TEXTURE_MULTISAMPLE] = FALSE;
+-    if (gl_info->supported[ARB_TEXTURE_MULTISAMPLE] && !gl_info->supported[ARB_TEXTURE_STORAGE_MULTISAMPLE])
+-    {
+-        WARN("Disabling ARB_texture_multisample because immutable storage is not supported.\n");
+-        gl_info->supported[ARB_TEXTURE_MULTISAMPLE] = FALSE;
+-    }
+-
+-    wined3d_adapter_init_limits(gl_info);
+-
+-    if (gl_info->supported[ARB_VERTEX_PROGRAM] && test_arb_vs_offset_limit(gl_info))
+-        gl_info->quirks |= WINED3D_QUIRK_ARB_VS_OFFSET_LIMIT;
+-
+-    if (gl_info->supported[ARB_SHADING_LANGUAGE_100])
+-    {
+-        const char *str = (const char *)gl_info->gl_ops.gl.p_glGetString(GL_SHADING_LANGUAGE_VERSION_ARB);
+-        unsigned int major, minor;
+-
+-        TRACE("GLSL version string: %s.\n", debugstr_a(str));
+-
+-        /* The format of the GLSL version string is "major.minor[.release] [vendor info]". */
+-        sscanf(str, "%u.%u", &major, &minor);
+-        gl_info->glsl_version = MAKEDWORD_VERSION(major, minor);
+-        if (gl_info->glsl_version >= MAKEDWORD_VERSION(1, 30))
+-            gl_info->supported[WINED3D_GLSL_130] = TRUE;
+-    }
+-
+-    checkGLcall("extension detection");
+-
+-    adapter->shader_backend = select_shader_backend(gl_info);
+-    adapter->vertex_pipe = select_vertex_implementation(gl_info, adapter->shader_backend);
+-    adapter->fragment_pipe = select_fragment_implementation(gl_info, adapter->shader_backend);
+-
+-    adapter->shader_backend->shader_get_caps(gl_info, &shader_caps);
+-    d3d_info->vs_clipping = shader_caps.wined3d_caps & WINED3D_SHADER_CAP_VS_CLIPPING;
+-    d3d_info->limits.vs_version = shader_caps.vs_version;
+-    d3d_info->limits.hs_version = shader_caps.hs_version;
+-    d3d_info->limits.ds_version = shader_caps.ds_version;
+-    d3d_info->limits.gs_version = shader_caps.gs_version;
+-    d3d_info->limits.ps_version = shader_caps.ps_version;
+-    d3d_info->limits.cs_version = shader_caps.cs_version;
+-    d3d_info->limits.vs_uniform_count = shader_caps.vs_uniform_count;
+-    d3d_info->limits.ps_uniform_count = shader_caps.ps_uniform_count;
+-    d3d_info->limits.varying_count = shader_caps.varying_count;
+-    d3d_info->shader_double_precision = shader_caps.wined3d_caps & WINED3D_SHADER_CAP_DOUBLE_PRECISION;
+-
+-    adapter->vertex_pipe->vp_get_caps(gl_info, &vertex_caps);
+-    d3d_info->xyzrhw = vertex_caps.xyzrhw;
+-    d3d_info->ffp_generic_attributes = vertex_caps.ffp_generic_attributes;
+-    d3d_info->limits.ffp_vertex_blend_matrices = vertex_caps.max_vertex_blend_matrices;
+-    d3d_info->limits.active_light_count = vertex_caps.max_active_lights;
+-    d3d_info->emulated_flatshading = vertex_caps.emulated_flatshading;
+-
+-    adapter->fragment_pipe->get_caps(gl_info, &fragment_caps);
+-    d3d_info->limits.ffp_blend_stages = fragment_caps.MaxTextureBlendStages;
+-    d3d_info->limits.ffp_textures = fragment_caps.MaxSimultaneousTextures;
+-    d3d_info->shader_color_key = fragment_caps.wined3d_caps & WINED3D_FRAGMENT_CAP_COLOR_KEY;
+-    d3d_info->wined3d_creation_flags = wined3d_creation_flags;
+-    d3d_info->feature_level = feature_level_from_caps(gl_info, &shader_caps, &fragment_caps);
+-
+-    TRACE("Max texture stages: %u.\n", d3d_info->limits.ffp_blend_stages);
+-
+-    d3d_info->valid_rt_mask = 0;
+-    for (i = 0; i < gl_info->limits.buffers; ++i)
+-        d3d_info->valid_rt_mask |= (1u << i);
+-
+-    if (!d3d_info->shader_color_key)
+     {
+diff --git a/dlls/wined3d/wined3d_private.h b/dlls/wined3d/wined3d_private.h
+index a30c83a6986..7849964a45e 100644
+--- a/dlls/wined3d/wined3d_private.h
++++ b/dlls/wined3d/wined3d_private.h
+@@ -73,2 +73,3 @@
+ #define WINED3D_QUIRK_BROKEN_ARB_FOG            0x00000200
++#define WINED3D_QUIRK_USE_CLIENT_STORAGE_BIT    0x00000400
+ 
+-- 
+2.19.1
+
diff --git a/patches/0010-wined3d-knobs-and-switches.patch b/patches/0010-wined3d-knobs-and-switches.patch
new file mode 100644
index 000000000..357903b78
--- /dev/null
+++ b/patches/0010-wined3d-knobs-and-switches.patch
@@ -0,0 +1,122 @@
+From 83af5a58d44c8b2d452c3908e98d7185759cbbed Mon Sep 17 00:00:00 2001
+From: Firerat <firer4t@googlemail.com>
+Date: Sat, 31 Mar 2018 00:43:33 +0100
+Subject: [PATCH 10/11] wined3d: knobs and switches
+
+patch adds envvars to tweak PBA, for better or for worse.
+
+envvars __PBA_GEO_HEAP and __PBA_CB_HEAP
+  e.g. __PBA_GEO_HEAP=256 __PBA_CB_HEAP=64
+    known to prevent FF XIV 32bit dx9 client crash.
+  will fallback to defaults if heaps are greater than vram
+
+  if vram is less than 640mb ( 512+128 ) the defaults are crudely
+  calculated, geo 3/4 vram and cb 1/8 vram.
+
+  cb can be set at 0, but only intended for pure dx8 or dx9.
+
+envvar __PBA_FORCE_GL_CLIENT_STORAGE_BIT
+  force use of DMA_CACHE instead of SYSTEM_HEAP
+    no effect when using mesa
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/buffer_heap.c |  9 +++++-
+ dlls/wined3d/device.c      | 56 ++++++++++++++++++++++++++++++++++----
+ 2 files changed, 58 insertions(+), 7 deletions(-)
+
+diff --git a/dlls/wined3d/buffer_heap.c b/dlls/wined3d/buffer_heap.c
+index 9e8f2d799df..320b0777824 100644
+--- a/dlls/wined3d/buffer_heap.c
++++ b/dlls/wined3d/buffer_heap.c
+@@ -178,3 +178,10 @@ HRESULT wined3d_buffer_heap_create(struct wined3d_context *context, GLsizeiptr s
+     {
+-        FIXME_(d3d_perf)("PBA: using GL_CLIENT_STORAGE_BIT quirk");
++        FIXME_(d3d_perf)("PBA: using GL_CLIENT_STORAGE_BIT quirk (mesa)\n");
++        storage_flags |= GL_CLIENT_STORAGE_BIT;
++    }
++
++    const char *env_pba_force_gcsb = getenv("__PBA_FORCE_GL_CLIENT_STORAGE_BIT");
++    if (!(gl_info->quirks & WINED3D_QUIRK_USE_CLIENT_STORAGE_BIT) && ((env_pba_force_gcsb) && *env_pba_force_gcsb != '0'))
++    {
++        FIXME_(d3d_perf)("PBA: forcing use of GL_CLIENT_STORAGE_BIT quirk (__PBA_FORCE_GL_CLIENT_STORAGE_BIT=%s)\n",env_pba_force_gcsb);
+         storage_flags |= GL_CLIENT_STORAGE_BIT;
+diff --git a/dlls/wined3d/device.c b/dlls/wined3d/device.c
+index fcce1bdb450..342925e29b5 100644
+--- a/dlls/wined3d/device.c
++++ b/dlls/wined3d/device.c
+@@ -37,2 +37,3 @@
+ WINE_DEFAULT_DEBUG_CHANNEL(d3d);
++WINE_DECLARE_DEBUG_CHANNEL(d3d_perf);
+ WINE_DECLARE_DEBUG_CHANNEL(winediag);
+@@ -850,3 +851,3 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+     {
+-        FIXME("Not using PBA, ARB_buffer_storage unsupported.\n");
++        FIXME_(d3d_perf)("Not using PBA, ARB_buffer_storage unsupported.\n");
+     }
+@@ -858,7 +859,43 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+     {
++        //(Firerat) is it worth initialising an int for vram?
++        unsigned int vram_mb = device->adapter->vram_bytes / 1048576;
++        const char *env_pba_geo_heap = getenv("__PBA_GEO_HEAP");
+         // TODO(acomminos): kill this magic number. perhaps base on vram.
+-        GLsizeiptr geo_heap_size = 512 * 1024 * 1024;
++        unsigned int geo_heap = ( env_pba_geo_heap ? atoi(env_pba_geo_heap) : 512 );
++        const char *env_pba_cb_heap = getenv("__PBA_CB_HEAP");
+         // We choose a constant buffer size of 128MB, the same as NVIDIA claims to
+         // use in their Direct3D driver for discarded constant buffers.
+-        GLsizeiptr cb_heap_size = 128 * 1024 * 1024;
++        unsigned int cb_heap = ( env_pba_cb_heap ? atoi(env_pba_cb_heap) : 128 );
++
++        if (env_pba_geo_heap)
++        {
++            FIXME_(d3d_perf)("geo_heap_size set by envvar __PBA_GEO_HEAP=%s\n",env_pba_geo_heap);
++        }
++        if (env_pba_cb_heap)
++        {
++            FIXME_(d3d_perf)("cb_heap_size set by envvar __PBA_CB_HEAP=%s\n",env_pba_cb_heap);
++        }
++
++        if ( geo_heap + cb_heap > vram_mb )
++        {
++            FIXME_(d3d_perf)("geo_heap + cb_heap ( %dmb + %dmb ) exceeds vram of %dmb. Dropping back to PBA defaults\n", geo_heap, cb_heap, vram_mb);
++            if ( vram_mb <= 640 ) // most users should have plenty of vram, but if not at least try to give them PBA..
++            {
++                //TODO (Firerat) I should probably figure out if using dx10+ ( possible? ), could skip cb_heap if not
++                FIXME_(d3d_perf)("You have low vram(%dmb), making crude guess at reasonable heap sizes for PBA\n", vram_mb);
++                // very crude, using 87.5% of vram
++                geo_heap = vram_mb * 0.75; // 3 quarters of vram
++                cb_heap = vram_mb * 0.125; // 8th of vram, probably too low
++                FIXME_(d3d_perf)("guess expressed as envvars: __PBA_GEO_HEAP=%d __PBA_CB_HEAP=%d\n", geo_heap, cb_heap);
++                //TODO (Firerat) might not be worth messing about here, just fail with note about envvars
++            }
++            else
++            {
++                // should ony get here if user screwed up their pba envvars
++                geo_heap = 512;
++                cb_heap = 128;
++            }
++        }
++        GLsizeiptr geo_heap_size = geo_heap * 1024 * 1024;
++        GLsizeiptr cb_heap_size = cb_heap * 1024 * 1024;
+         GLint ub_alignment;
+@@ -877,6 +914,13 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+ 
+-        if (FAILED(hr = wined3d_buffer_heap_create(context, cb_heap_size, ub_alignment, TRUE, &device->cb_buffer_heap)))
++        if (cb_heap != 0) // assume user doesn't want a cb_heap , e.g. not dx10+
+         {
+-            ERR("Failed to create persistent buffer heap for constant buffers, hr %#x.\n", hr);
+-            goto fail;
++            if (FAILED(hr = wined3d_buffer_heap_create(context, cb_heap_size, ub_alignment, TRUE, &device->cb_buffer_heap)))
++            {
++                ERR("Failed to create persistent buffer heap for constant buffers, hr %#x.\n", hr);
++                goto fail;
++            }
++        }
++        else
++        {
++            FIXME_(d3d_perf)("cb_heap set to 0, this will degrade performance with dx10 and dx11\n");
+         }
+-- 
+2.19.1
+
diff --git a/patches/0011-Check-for-envvar-to-actually-enable-PBA-instead-of-t.patch b/patches/0011-Check-for-envvar-to-actually-enable-PBA-instead-of-t.patch
new file mode 100644
index 000000000..64d0ddf18
--- /dev/null
+++ b/patches/0011-Check-for-envvar-to-actually-enable-PBA-instead-of-t.patch
@@ -0,0 +1,39 @@
+From 32e377986e05485950248c05f6ad2532a783ea89 Mon Sep 17 00:00:00 2001
+From: Tk-Glitch <ti3nou@gmail.com>
+Date: Fri, 14 Sep 2018 01:03:27 +0200
+Subject: [PATCH 11/11] Check for envvar to actually enable PBA instead of the
+ opposite
+
+Signed-off-by: Rob Walker <bob.mt.wya@gmail.com>
+---
+ dlls/wined3d/device.c | 12 ++++++------
+ 1 file changed, 6 insertions(+), 6 deletions(-)
+
+diff --git a/dlls/wined3d/device.c b/dlls/wined3d/device.c
+index 342925e29b5..0baebee1dec 100644
+--- a/dlls/wined3d/device.c
++++ b/dlls/wined3d/device.c
+@@ -847,3 +847,3 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+     BOOL use_pba = FALSE;
+-    char *env_pba_disable;
++    char *env_pba_enable;
+ 
+@@ -853,7 +853,3 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+     }
+-    else if ((env_pba_disable = getenv("PBA_DISABLE")) && *env_pba_disable != '0')
+-    {
+-        FIXME("Not using PBA, envvar 'PBA_DISABLE' set.\n");
+-    }
+-    else
++    else if ((env_pba_enable = getenv("PBA_ENABLE")) && *env_pba_enable != '0')
+     {
+@@ -931,2 +927,6 @@ static void create_buffer_heap(struct wined3d_device *device, struct wined3d_con
+     }
++    else
++    {
++        FIXME("Not using PBA, envvar 'PBA_ENABLE' not set.\n");
++    }
+ 
+-- 
+2.19.1
+
